// ============== ActionPotential.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Global.h"
#include "ActionPotential.h"
#include "Axon.h"
#include "Dendrite.h"

extern long REFACTORY_PERIOD;

ActionPotential::ActionPotential(Process *p): 
	NNComponent(ComponentTypeActionPotential)
{
	owningProcessId = p->id;
	this->id = globalObject->nextComponent(ComponentTypeActionPotential);
}

ActionPotential::~ActionPotential(void)
{
}

ActionPotential *ActionPotential::create(Process *p)
{
	ActionPotential *a = new ActionPotential(p);
	return a;
}

// Compute the offset into the future (in ms) from current position along axon and speed (rate). 
long ActionPotential::computeOffset(float position, float rate) 
{
	long offset = position + (long)((position * rate) * AP_OFFSET_RATE);
	if(offset>MAX_TIMEINTERVAL_OFFSET)
		offset = MAX_TIMEINTERVAL_OFFSET;


	// DSH Hack for experiment
	offset = offset / 50;  // cut the response time down a bit

	//std::cout << "Computed offset "	<< offset << " from position " << position << ", rate " << rate << std::endl;
	return offset;
}


// ============== ActionPotential.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <stdio.h> 
#include "stdafx.h"
#include "Process.h"
#include "NNComponent.h"

class Global;
extern Global *globalObject;

class ActionPotential: public NNComponent
{
private:    
	ActionPotential(Process *p);

public:
	~ActionPotential(void);
	static ActionPotential *create(Process *p);
	static long computeOffset(float position, float rate);
	unsigned long owningProcessId;
};


// ============== Axon.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Axon.h"
#include "TR1Random.h"
#include "Global.h"
#include "Neuron.h"
#include "Synapse.h"
#include "Dendrite.h"
#include "TimedEvent.h"
#include <iostream>

// External globals (if any)
extern long REFACTORY_PERIOD;

Axon::Axon(Neuron *neuron) : Process(ComponentTypeAxon)
{
    this->neuronId = neuron->id;
    setRate(DEFAULT_AXON_RATE,false);
    float dist = DEFAULT_AXON_DISTANCE;
    setDistance(dist);
    this->parentId = this->neuronId;
    neuron->setDirty();
}

Axon::~Axon(void)
{
}

void Axon::toJSON(std::ofstream &outstream)
{
    std::string sep("");
    outstream << "                            { \"_type\": \"Axon\", \"id\": " << id << ", \"neuronId\": " << neuronId << ", \"synapses\": [" << std::endl;
    for (unsigned int i = 0; i < synapses.size(); i++)
    {
        outstream << sep;
        sep = ",";
        Synapse *s = globalObject->synapseDB.getComponent(synapses[i]);
        s->toJSON(outstream);
    }
    outstream << "                            ] } " << std::endl;
}

void Axon::save(void)
{
    globalObject->axonDB.save(this);
}

void Axon::commit(void)
{
    globalObject->axonDB.addToCache(this);
}

Axon *Axon::create(Neuron *neuron)
{
    Axon *a = new Axon(neuron);
    a->id = globalObject->nextComponent(ComponentTypeAxon);
    globalObject->insert(a);
    return a;
}

void Axon::initializeRandom(void)
{
    // Optionally create random synapses if desired
    // Currently no random init logic here
}

void Axon::insertSynapse(long synapseId)
{
    bool found = false;
    size_t synapseCount = synapses.size();
    for(size_t i=0;i<synapseCount;i++)
    {
        if(synapseId == synapses[i])    
            found = true;
    }
    if(!found)
    {
        synapses.push_back(synapseId);
        setDirty();
    }
}

Range Axon::fire(void)
{
    Range range;
    if(globalObject->logEvents) 
    {
        std::stringstream ss;
        ss << "axon_fire: neuron=" << this->neuronId;
        globalObject->writeEventLog(ss.str().c_str());
    }

    long highestOffset = -MAX_TIMEINTERVAL_OFFSET;
    long lowestOffset = MAX_TIMEINTERVAL_OFFSET;
    size_t synapseSize = this->synapses.size();

    for(size_t synapseIndex = 0;synapseIndex < synapseSize; synapseIndex++) 
    {
        long synapseId = this->synapses[synapseIndex];
        Synapse *thisSynapse = globalObject->synapseDB.getComponent(synapseId);

        long dendriteId = thisSynapse->getOwningDendriteId();
        Dendrite *thisDendrite = globalObject->dendriteDB.getComponent(dendriteId);

        float pos = thisSynapse->getPosition();
        float lclRate = thisDendrite->getRate();
        long offset = ActionPotential::computeOffset(pos, lclRate) + REFACTORY_PERIOD;

        if(offset > 0)
        {
            if(lowestOffset > offset) 
                lowestOffset = offset;
            if(highestOffset < offset)
                highestOffset = offset;

            long timeslice = globalObject->getCurrentTimestamp()+ offset;
            TimedEvent::create(timeslice, thisDendrite, thisSynapse->id);

            if(globalObject->logEvents) 
            {
                std::stringstream ss;
                ss << "timed_event: synapse=" << thisSynapse->id << ", dendrite=" << thisDendrite->id << ", neuron=" << thisDendrite->getPostSynapticNeuronId() << ", presynaptic_neuron=" << thisDendrite->getPreSynapticNeuronId() << ", offset=" << offset << ", timeslice=" << timeslice;
                globalObject->writeEventLog(ss.str().c_str());
            }
        } 
    }

    range.low = lowestOffset;
    range.high = highestOffset;
    return range;
}

Tuple *Axon::getImage(void)
{
    long synapseCount = (long)synapses.size();
    float lclDistance = getDistance();
    float lclRate = getRate();

    size_t size = sizeof(parentId) + sizeof(lclDistance) + sizeof(lclRate) + sizeof(neuronId) +
                  sizeof(synapseCount) + (synapseCount * sizeof(long));

    char *image = globalObject->allocClearedMemory(size);
    char *ptr = (char *)image;

    memcpy(ptr, &parentId, sizeof(parentId));
    ptr += sizeof(parentId);
    memcpy(ptr, &lclDistance, sizeof(lclDistance));
    ptr += sizeof(lclDistance);
    memcpy(ptr, &lclRate, sizeof(lclRate));
    ptr += sizeof(lclRate);
    memcpy(ptr, &neuronId, sizeof(neuronId));
    ptr += sizeof(neuronId);
    memcpy(ptr, &synapseCount, sizeof(synapseCount));
    ptr += sizeof(synapseCount);

    for (size_t i = 0; i < (size_t)synapseCount; i++)
    {
        long k = synapses[i];
        memcpy(ptr, &k, sizeof(k));
        ptr += sizeof(k);
    }

    Tuple *tuple = new Tuple();
    tuple->objectPtr = image;
    tuple->value = size;
    return tuple;
}

Axon *Axon::instantiate(long key, size_t len, void *data)
{
    (void)len; 
    long lclsynapseCount = 0;
    long lclneuronId = 0;
    long lclpId = 0;
    float lclDistance = 0;
    float lclRate = 0;

    Axon *axon = new Axon();
    axon->id = key;

    char *ptr = (char *)data;
    memcpy(&lclpId, ptr, sizeof(lclpId));
    ptr += sizeof(lclpId);
    memcpy(&lclDistance, ptr, sizeof(lclDistance));
    ptr += sizeof(lclDistance);
    memcpy(&lclRate, ptr, sizeof(lclRate));
    ptr += sizeof(lclRate);
    memcpy(&lclneuronId, ptr, sizeof(lclneuronId));
    ptr += sizeof(lclneuronId);
    memcpy(&lclsynapseCount, ptr, sizeof(lclsynapseCount));
    ptr += sizeof(lclsynapseCount);

    axon->parentId = lclpId;
    axon->setDistance(lclDistance);
    axon->setRate(lclRate);
    axon->neuronId = lclneuronId;

    if (lclsynapseCount > 1000000 || lclsynapseCount < 0) {
        std::cout << "getImage: Axon " << axon->id << " has " << lclsynapseCount << " synapse\n";
    }
    else
    {
        for (size_t i = 0; i < (size_t)lclsynapseCount; i++)
        {
            long thisKey;
            memcpy(&thisKey, ptr, sizeof(long));
            ptr += sizeof(long);
            axon->synapses.push_back(thisKey);
        }
    }

    axon->setDirty(false);
    return axon;
}

Axon::Axon(void) : Process(ComponentTypeAxon)
{
    // Default constructor if needed
}


// ============== Axon.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <map>
#include <vector>
#include "Process.h"
#include "Synapse.h"
#include "ActionPotential.h"
#include "Range.h"

class Axon: public Process
{
    friend class boost::serialization::access;
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
    {
        ar & boost::serialization::base_object<NNComponent>(*this);
        ar & neuronId;

        for(unsigned int i=0;i<synapses.size();i++)
        {
            ar & synapses[i];
        }
    }

public:
    virtual ~Axon(void);
    static Axon *create(Neuron *neuron);
    void initializeRandom(void);
    Range fire(void);
    Tuple *getImage(void);
    static Axon *instantiate(long key, size_t len, void *data);
    inline std::vector<long> *getSynapses(void) { return &synapses; };
    void insertSynapse(long synapseId); 
    void toJSON(std::ofstream& outstream);

    long neuronId;

private:
    Axon(void);
    Axon(Neuron* neuron);

    void save(void);
    void commit(void);

    std::vector<long> synapses;
};


// ============== Brain.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <filesystem>
#include "Global.h"

#include "Brain.h"

#include "TR1Random.h"

//#include <boost/json.hpp>
#include <boost/property_tree/json_parser.hpp>
#include <boost/foreach.hpp>

#include "nlohmann/json.hpp"

extern bool keepRunning;

extern Global *globalObject;
extern SNNVisualizer *snnVisualizer;
extern int main_process(Brain *brain);
extern int neuron_process(Brain *brain);


using json = nlohmann::json;
namespace fs = std::filesystem;

///////////////////////////
class OrderPreservingJSONSerializer {
public:
    static std::string serialize(const json& j) {
        std::string result = "{";
        bool first = true;
        for (auto it = j.begin(); it != j.end(); ++it) {
            if (!first) {
                result += ", ";
            }
            first = false;
            result += "\"" + it.key() + "\":";
            result += serializeValue(it.value());
        }
        result += "}";
        return result;
    }

private:
    static std::string serializeValue(const json& value) {
        if (value.is_string()) {
            return "\"" + value.get<std::string>() + "\"";
        } else if (value.is_number()) {
            return std::to_string(value.get<double>());
        } else if (value.is_boolean()) {
            return value.get<bool>() ? "true" : "false";
        } else if (value.is_null()) {
            return "null";
        } else if (value.is_object()) {
            return serialize(value);
        } else if (value.is_array()) {
            std::string result = "[";
            bool first = true;
            for (const auto& item : value) {
                if (!first) {
                    result += ", ";
                }
                first = false;
                result += serializeValue(item);
            }
            result += "]";
            return result;
        } else {
            return "unknown";
        }
    }
};

///////////////////////////

Brain::Brain(void):
	NNComponent(ComponentTypeBrain)
{
	current_syncpoint = 0;
	timeAdjust = 0;
	globalObject->startRealTime = boost::posix_time::second_clock::local_time();
}

Brain::~Brain(void)
{
}

// Excite 'num' random neurons into firing
void Brain::excite(int num)
{

	std::stringstream ss;
	LOGSTREAM(ss) << "Excite " << num << " neurons." << std::endl;
	globalObject->log(ss);

	int totalNeurons = globalObject->neuronsSize();
	int base = globalObject->componentBase[ComponentTypeNeuron];


	std::srand(static_cast<unsigned int>(std::time(nullptr)));

	for(int i=0;i< num;i++) {
    	// Generate a random value in the range [0, y)
    	int randomOffset = std::rand() % totalNeurons;
		// Calculate the result in the desired range [x, x + y)
    	int index = base + randomOffset;
		Neuron* neuron = globalObject->neuronDB.getComponent(index);
		neuron->fire();
	}

	LOGSTREAM(ss) << "Excitaton complete." << std::endl;
	globalObject->log(ss);
}


void Brain::validateAndFormatJSON(void) {
    try {
        // Read the JSON file
		std::string inputFilename = std::string(globalObject->getDBPath()) +  globalObject->getModelName() + std::string("/") + std::string("temp.json").c_str();
		std::string outputFilename = std::string(globalObject->getDBPath()) +  globalObject->getModelName() + std::string("/") + std::string("serialized.json").c_str();


        std::ifstream inputFile(inputFilename);
        json inputJSON;
        inputFile >> inputJSON;

        // Write the formatted JSON to the output file
        std::ofstream outputFile(outputFilename);
        outputFile << std::setw(4) << inputJSON << std::endl;
		inputFile.close();
		outputFile.close();
		fs::remove(inputFilename);

        std::cout << "JSON file validated and formatted successfully!" << std::endl;
    } catch (const json::parse_error& e) {
        std::cerr << "Error parsing JSON file: " << e.what() << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "Error: " << e.what() << std::endl;
    }
}


void Brain::exportJSON(void)
{
	std::stringstream ss;
	LOGSTREAM(ss) << "Beginning export to JSON..." << std::endl;
	globalObject->log(ss);


	std::ofstream ofs(std::string(globalObject->getDBPath()) +  globalObject->getModelName() + std::string("/") + std::string("temp.json").c_str());
	toJSON(ofs);
	ofs.close();

	validateAndFormatJSON();

	LOGSTREAM(ss) << "Export to JSON complete..." << std::endl;
	globalObject->log(ss);


}

void Brain::toJSON(std::ofstream& outstream)
{
	outstream << "{ \"_type\": \"Brain\", \"id\": " << id << ", \"regions\": [ " << std::endl;
	std::string sep("");

	for (unsigned int i = 0; i < regions.size(); i++)
	{
		outstream << sep;
		sep = ",";
		Region* r = globalObject->regionDB.getComponent(regions[i]);
		r->toJSON(outstream);
	}
	outstream << "] } " << std::endl;

}

void Brain::save(void)
{
	globalObject->brainDB.save(this);
}


Brain *Brain::create(bool setToDirty, std::string dbPath, std::string modelName)
{
	tr1random = new TR1Random();

	globalObject->setDBPath(dbPath);
	globalObject->setModelName(modelName);

	Brain *brain = new Brain();
	brain->id = globalObject->nextComponent(ComponentTypeBrain);
	globalObject->insert(brain);
	if(setToDirty)
		brain->setDirty();
	brain->timeAdjust = 0;
	return brain;
}

Brain* Brain::loadFromJSON(std::string dbPath, std::string modelName)
{
	tr1random = new TR1Random();
	globalObject->setDBPath(dbPath);
	globalObject->setModelName(modelName);
	globalObject->brainDB.begin();
	// begin loading JSON
	std::string jsonfilename(dbPath +  modelName + std::string("/") + "serialized.json");

	boost::property_tree::ptree pt;
	boost::property_tree::read_json(jsonfilename, pt);
	std::string test("");

	BOOST_FOREACH(boost::property_tree::ptree::value_type &v, pt) {
		boost::property_tree::basic_ptree<std::string, std::string, std::less<std::string>> x = v.second;

	}


	Brain* brain = globalObject->brainDB.getValue();
	globalObject->syncpoint = globalObject->readSyncpoint();

	globalObject->insert(brain);

	return brain;
}

Brain *Brain::load(std::string dbPath, std::string modelName)
{
	tr1random = new TR1Random();
	globalObject->setDBPath(dbPath);
	globalObject->setModelName(modelName);
	//globalObject->brainDB.begin(); 
	long brainId = globalObject->componentBase[ComponentTypeBrain];
	Brain *brain = globalObject->brainDB.getComponent(brainId);
	globalObject->syncpoint = globalObject->readSyncpoint();

	for(size_t i=0;i<CTYPE_COUNT;i++) 
	{
		long thisCount = 0;
		switch (i) {
//	1 = ComponentDB<Brain> brainDB;
			case 1:
				thisCount = (long)globalObject->brainDB.size();
				break;
//	2 = ComponentDB<Region> regionDB;
			case 2:
				thisCount = (long)globalObject->regionDB.size();
				break;
//	3 = ComponentDB<Nucleus> nucleusDB;
			case 3:
				thisCount = (long)globalObject->nucleusDB.size();
				break;
//	4 = ComponentDB<Column> columnDB;
			case 4:
				thisCount = (long)globalObject->columnDB.size();
				break;
//	5 = ComponentDB<Layer> layerDB;
			case 5:
				thisCount = (long)globalObject->layerDB.size();
				break;
//	6 = ComponentDB<Cluster> clusterDB;
			case 6:
				thisCount = (long)globalObject->clusterDB.size();
				break;
//	7 = ComponentDB<Neuron> neuronDB;
			case 7:
				thisCount = (long)globalObject->neuronDB.size();
				break;
//	8 = ComponentDB<Axon> axonDB;
			case 8:
				thisCount = (long)globalObject->axonDB.size();
				break;
//	9 = ComponentDB<Dendrite> dendriteDB;
			case 9:
				thisCount = (long)globalObject->dendriteDB.size();
				break;
//	10 = ComponentDB<Synapse> synapseDB;
			case 10:
				thisCount = (long)globalObject->synapseDB.size();
				break;
			default:
				break;
		}
		if(thisCount>0) 
		{
			globalObject->componentCounter[i] = globalObject->componentBase[i] + thisCount;
		}
	}

	globalObject->insert(brain);

	return brain;
}

/*
void Brain::initializeRandom(void)
{
	std::string dummyStr;
	size_t rnd = (size_t) tr1random->generate(1,3); // Random # of regions
	SpatialDetails sd(1, 2, 3, 4, 5, 6); // Dummy test locations/size
	for(size_t i=0;i<rnd;i++)
	{
		Region *r = Region::create(dummyStr,sd);
		r->initializeRandom();
		regions.push_back(r->id);
	}

}
*/

void Brain::adjustSynapses(void)
{
}

// Accumulate all previous vectors up to MAX_INTERVAL_OFFSET in the past
// and return them in a single vector
void Brain::grabAllVectors(long cts, std::vector<TimedEvent *> *collectedVector)
{
	long start = cts - MAX_TIMEINTERVAL_OFFSET;

	if(start < 0 )
		start = 0;

	for(long i = start;i < cts; i++)
	{
		long intervalOffsetValue = i % MAX_TIMEINTERVAL_BUFFER_SIZE;
		std::vector<TimedEvent *> *teVector = &globalObject->timeIntervalEvents[intervalOffsetValue];
		if(teVector->size()>0) 
		{
			collectedVector->insert(collectedVector->end(), teVector->begin(), teVector->end());
			teVector->clear();
		}
	}
}

void Brain::removePreviousTimedEvents(void)
{

//	long totalEvents = globalObject->getTotalEvents();
//	printf("removePreviousTimedEvents: Total events %ld\r", totalEvents);
	std::vector<TimedEvent *> thisVector;
	std::vector<TimedEvent *> *teVector = &thisVector;

	long cts = globalObject->getCurrentTimestamp();

	long intervalOffsetValue = globalObject->getCurrentTimestamp() % MAX_TIMEINTERVAL_BUFFER_SIZE;

//	std::cout << "removePreviousTimedEvents Locking teVector_mutex[" << intervalOffsetValue << "]" << std::endl;
	boost::mutex::scoped_lock amx(*(globalObject->teVector_mutex[intervalOffsetValue]));

	//std::vector<TimedEvent *> *teVector = &globalObject->timeIntervalEvents[intervalOffsetValue];
	// grab all previous TimeEvent vectors
	grabAllVectors(intervalOffsetValue,teVector);
	std::vector<TimedEvent *> newVector;
	std::vector<TimedEvent *> oldVector;
	for(size_t i = 0;i<teVector->size();i++)
	{
			TimedEvent *te = (*teVector)[i];
			if(te->slice < cts  - MAX_TIMEINTERVAL_OFFSET) { // If aged out (over 4s ago), don't keep it. 
				oldVector.push_back(te); // Save this event
			} 
			else 
			{
				newVector.push_back(te); // Save this event
			}
	}
	teVector->clear(); // Clear out the vector
	// add only new events
	for(size_t i = 0; i< newVector.size();i++)
	{
		TimedEvent *te = newVector[i];
		teVector->push_back(te);
	}

	// remove old events
	size_t numberOfEvents = oldVector.size();
	if(numberOfEvents>0) {
//		std::cout << "\nRemoving " << numberOfEvents << " TimedEvents " << std::endl;
		for(size_t i = 0; i< numberOfEvents;i++)
		{
			TimedEvent *te = oldVector[i];
			delete te;
		}
	}
//	std::cout << "removePreviousTimedEvents UnLocking teVector_mutex[" << intervalOffsetValue << "]" << std::endl;

}

void Brain::step(void)
{

	long begin = globalObject->getCurrentTimestamp();
	long now = begin;

	globalObject->cycle();


	removePreviousTimedEvents();



//	while(begin==now) // wait until time changes
//	{
//		now = globalObject->getCurrentTimestamp();
//	}

//	removeDeadAPs(); // remove dead APs and unfire firing axons

	globalObject->increment();
	
}

/*
void Brain::removeDeadAPs(void)
{
	globalObject->removeDeadAPs();
}
*/

Brain *Brain::instantiate(long key, size_t len, void *data)
{
// 	size_t size = sizeof(float)+sizeof(float)+sizeof(long)+sizeof(long);
	(void)len;
	Brain *brain = new Brain();
	brain->id = key;

	char *ptr = (char*)data;

	long regionCount = 0;
	memcpy(&regionCount,ptr,sizeof(regionCount)); ptr+=sizeof(regionCount);
	for(size_t i=0;i<(size_t)regionCount;i++)
	{
		long rid = 0;
		memcpy(&rid,ptr,sizeof(rid));
		brain->regions.push_back(rid);
		ptr+=sizeof(rid);
	}
	return brain;
}

Tuple *Brain::getImage(void)
{
/* -- persisted values
	size_t regionCount;
	std::vector<long> regions;
*/
	long regionCount = (u_int32_t)regions.size();

	size_t size = sizeof(regionCount)+(regionCount * sizeof(long));

	char *image = globalObject->allocClearedMemory(size);
	char *ptr = (char*)image;


	memcpy(ptr,&regionCount,sizeof(regionCount)); 	ptr+=sizeof(regionCount);

	for(size_t i=0;i<(size_t)regionCount;i++)
	{
		long k = regions[i];
		memcpy(ptr,&k,sizeof(k));
		ptr+=sizeof(k);
	}

	Tuple* tuple = new Tuple();
	tuple->objectPtr = image;
	tuple->value = size;


	return tuple;
}

void Brain::shutdown(void)
{
	globalObject->shutdown();
	delete tr1random;
	delete globalObject;
}

void Brain::add(Region *reg)
{
	long value = reg->id;
	regions.push_back(value);
}


void Brain::syncpoint(void) 
{ 
	current_syncpoint++;
	if(globalObject->syncpoint<current_syncpoint)
	{
		globalObject->flush();
		globalObject->writeSyncpoint(current_syncpoint);
	}
}

bool Brain::restartpoint(void) 
{ 

	if(!keepRunning)
	{
		std::stringstream ss;
		LOGSTREAM(ss) << "Shutdown detected at syncpoint " << current_syncpoint << "..." << std::endl;
		globalObject->log(ss);

		shutdown();
		exit(0);
	}

	bool restart = true;
	if(globalObject->syncpoint>=0)
	{
		if(globalObject->syncpoint>current_syncpoint)
		{
			restart = false;
		}

	}
	if(!restart)
	{
		std::stringstream ss;
		LOGSTREAM(ss) << "Skipping restart syncpoint  " << current_syncpoint << "..." << std::endl;
		globalObject->log(ss);
	}
	return restart; 
}

void Brain::report(void) 
{ 

	std::string rept = getReport();

	globalObject->log((char *)rept.c_str());
}

void Brain::longReport(void)
{

	std::string rept = getLongReport();

	globalObject->log((char*)rept.c_str());
}

std::string Brain::getReport(void)
{ 

	std::stringstream ss;
	std::string returnString;

	size_t layerCacheSize = globalObject->layerDB.cacheSize();
	size_t clusterCacheSize = globalObject->clusterDB.cacheSize();
	size_t columnCacheSize = globalObject->columnDB.cacheSize();
	size_t nucleusCacheSize = globalObject->nucleusDB.cacheSize();
	size_t regionCacheSize = globalObject->regionDB.cacheSize();
	size_t neuronCacheSize = globalObject->neuronDB.cacheSize();
	size_t axonCacheSize = globalObject->axonDB.cacheSize();
	size_t dendriteCacheSize = globalObject->dendriteDB.cacheSize();
	size_t synapseCacheSize = globalObject->synapseDB.cacheSize();

	size_t layerSize = globalObject->layerDB.size();
	size_t clusterSize = globalObject->clusterDB.size();
	size_t columnSize = globalObject->columnDB.size();
	size_t nucleusSize = globalObject->nucleusDB.size();
	size_t regionSize = globalObject->regionDB.size();
	size_t neuronSize = globalObject->neuronDB.size();
	size_t axonSize = globalObject->axonDB.size();
	size_t dendriteSize = globalObject->dendriteDB.size();
	size_t synapseSize = globalObject->synapseDB.size();

	size_t layerSaves = globalObject->layerDB.saves();
	size_t clusterSaves = globalObject->clusterDB.saves();
	size_t columnSaves = globalObject->columnDB.saves();
	size_t nucleusSaves = globalObject->nucleusDB.saves();
	size_t regionSaves = globalObject->regionDB.saves();
	size_t neuronSaves = globalObject->neuronDB.saves();
	size_t axonSaves = globalObject->axonDB.saves();
	size_t dendriteSaves = globalObject->dendriteDB.saves();
	size_t synapseSaves = globalObject->synapseDB.saves();

	size_t layerReimages = globalObject->layerDB.reimages();
	size_t clusterReimages = globalObject->clusterDB.reimages();
	size_t columnReimages = globalObject->columnDB.reimages();
	size_t nucleusReimages = globalObject->nucleusDB.reimages();
	size_t regionReimages = globalObject->regionDB.reimages();
	size_t neuronReimages = globalObject->neuronDB.reimages();
	size_t axonReimages = globalObject->axonDB.reimages();
	size_t dendriteReimages = globalObject->dendriteDB.reimages();
	size_t synapseReimages = globalObject->synapseDB.reimages();

	LOGSTREAM(ss) << "Structure: size/cachesize/saves/re-images/cache misses" << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Region: " << regionSize << "/" << regionCacheSize << "/" << regionSaves << "/" << regionReimages << "/" << globalObject-> regionDB.getCacheMissCount()  << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Nucleus: " << nucleusSize << "/" << nucleusCacheSize  << "/" << nucleusSaves << "/" << nucleusReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Column: " << columnSize << "/" << columnCacheSize  << "/" << columnSaves << "/" << columnReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Layer: " << layerSize << "/" << layerCacheSize  << "/" << layerSaves << "/" << layerReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Cluster: " << clusterSize << "/" << clusterCacheSize  << "/" << clusterSaves << "/" << clusterReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Neuron: " << neuronSize << "/" << neuronCacheSize  << "/" << neuronSaves << "/" << neuronReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Axon: " << axonSize << "/" << axonCacheSize  << "/" << axonSaves << "/" << axonReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Dendrite: " << dendriteSize << "/" << dendriteCacheSize  << "/" << dendriteSaves << "/" << dendriteReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();
	LOGSTREAM(ss) << "Synapse: " << synapseSize << "/" << synapseCacheSize  << "/" << synapseSaves << "/" << synapseReimages << "/" << globalObject->regionDB.getCacheMissCount() << std::endl;
	returnString += ss.str();

	LOGSTREAM(ss) << "---------" << std::endl;
	returnString += ss.str();

//	LOGSTREAM(ss) << "APs: " << globalObject->actionPotentialsSize() << std::endl;
//	returnString += ss.str();

	long startTS = globalObject->getCurrentTimestamp();
	long endTS = startTS +  MAX_TIMEINTERVAL_BUFFER_SIZE;
	std::string sep = "";
	bool found = false;
	long totalAPs = 0;
	long totalOnes = 0;

	for (long x = startTS; x < endTS; x++)
	{
		size_t slot = x % MAX_TIMEINTERVAL_BUFFER_SIZE;

		std::cout << "getReport Locking teVector_mutex[" << slot << "]" << std::endl;
		boost::mutex::scoped_lock amx(*(globalObject->teVector_mutex[slot])); // Dangerous/potential deadlock candidate

		std::vector<TimedEvent *> *teVector = &globalObject->timeIntervalEvents[slot];
		long sz = teVector->size();
		if (sz > 0)
		{

			if (sz == 1)
			{ // just increment the counters; don't display the "1"s because there are so many
				found = true;
				totalAPs++;
				totalOnes++;
			}
			else
			{
				long offset = x - startTS;
				LOGSTREAM(ss) << sep << "AP Offset: " << offset << ":" << sz;
				returnString += ss.str();
				sep = ",";
				found = true;
				totalAPs += sz;
			}
		}
		std::cout << "getReport UnLocking teVector_mutex[" << slot << "]" << std::endl;
	}

	if (!found)
	{
		LOGSTREAM(ss) << "No active APs " << std::endl;
		returnString += ss.str();
	}
	else
	{
		LOGSTREAM(ss) << std::endl;
		returnString += ss.str();
		LOGSTREAM(ss)  <<  "Total APs: " << totalAPs <<  ", " << totalOnes <<  " of which are single AP events." << std::endl;
		returnString += ss.str();
	}

	LOGSTREAM(ss) << "---------" << std::endl;
	returnString += ss.str();

	return returnString;
}

std::string Brain::getLongReport(void)
{

	std::stringstream ss;
	std::string returnString;

	returnString = getReport();
	return returnString;
}

void Brain::startServer(void) 
{ 
	networkServer.start();

	std::thread t1(main_process, this);
    t1.detach(); // Wait for the new thread to finish execution
}

void Brain::stopServer(void)
{
	networkServer.stop();
}

void Brain::startNeuronProcessing(void) 
{ 
	neuronProcessor.start();

}

void Brain::stopNeuronProcessing(void)
{
	neuronProcessor.stop();
}

void Brain::startTimerProcessing(void) 
{ 
	timerProcessor.start();

}

void Brain::stopTimerProcessing(void)
{
	timerProcessor.stop();
}

void Brain::startSNNVisualizer(void) 
{ 
	snnVisualizer.thisBrain = this;
	snnVisualizer.start();
}

void Brain::stopSNNVisualizer(void)
{
	snnVisualizer.stop();
}



// ============== Brain.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include "NNComponent.h"
#include <map>
#include "Region.h"
#include "Server.h"
#include "TimedEvent.h"
#include "NeuronProcessor.h"
#include "TimerProcessor.h"
#include "SNNVisualizer.h"
#include "boost/date_time/posix_time/posix_time.hpp"


class Brain: public NNComponent
{
	Brain(void);
    friend class boost::serialization::access;
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
	{
		ar & boost::serialization::base_object<NNComponent>(*this);
		for(unsigned int i=0;i<regions.size();i++)
		{ 
			ar & regions[i];
		}
	}
public:
	virtual ~Brain(void);
	static Brain *create(bool setToDirty, std::string dbPath, std::string modelName);
	static Brain *load(std::string dbPath, std::string modelName);
	static Brain *loadFromJSON(std::string dbPath, std::string modelName);
//	void initializeRandom(void);
	void shutdown(void);

	static Brain *instantiate(long key, size_t len, void *data);
	Tuple *getImage(void);

	void step(void);
	void adjustSynapses(void);
//	void removeDeadAPs(void);
	void removePreviousTimedEvents(void);

	void add(Region *reg);

	void syncpoint(void);
	bool restartpoint(void);
	void report(void);
	void longReport(void);
	std::string getLongReport(void);
	std::string getReport(void);
	void startServer(void);
	void stopServer(void);
	void save(void);
	void exportJSON(void);
	void toJSON(std::ofstream& outstream);
	void excite(int num);
	void startNeuronProcessing(void);
	void stopNeuronProcessing(void);
	void validateAndFormatJSON(void);
	void startTimerProcessing(void);
	void stopTimerProcessing(void);
	void startSNNVisualizer(void);
	void stopSNNVisualizer(void);
	void grabAllVectors(long cts, std::vector<TimedEvent *> *collectedVector);


	Server networkServer;
	NeuronProcessor neuronProcessor;
	TimerProcessor timerProcessor;
	SNNVisualizer snnVisualizer;

	std::vector<long> regions;
	int current_syncpoint;

	long timeAdjust;


};


// ============== BrainDemoTiny.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Global.h"
#include "TR1Random.h"
#include "BrainDemoTiny.h"
#include "SNNEngine.h"
#include <boost/random/mersenne_twister.hpp>
#include <boost/random/uniform_int_distribution.hpp>


BrainDemoTiny::BrainDemoTiny(void)
{
}

BrainDemoTiny::~BrainDemoTiny(void)
{
}

Brain * BrainDemoTiny::create(bool rebuild) 
{

	Brain *brain; 

	std::stringstream ss;

	if(!rebuild) // if not rebuilding, just return brain
	{
		LOGSTREAM(ss) << " Loading brain" << std::endl;
		globalObject->log(ss);
		brain = Brain::load("../../../database/","BrainDemoTiny");
		globalObject->readCounters();
	} 
	else 
	{
		LOGSTREAM(ss) << " Creating brain" << std::endl;
		globalObject->log(ss);
		brain = Brain::create(true,"../../../database/","BrainDemoTiny");

	}

	/*
	enum ComponentType {ComponentTypeUnknown=0, ComponentTypeBrain, ComponentTypeRegion, ComponentTypeNucleus, ComponentTypeColumn, ComponentTypeLayer, 
					ComponentTypeCluster, ComponentTypeNeuron, ComponentTypeAxon, ComponentTypeDendrite, ComponentTypeSynapse, 
					ComponentTypeActionPotential, ComponentTypeTimedEvent};
	#define CTYPE_COUNT 13
	*/


	SpatialDetails sdregionDigits(-10000, 5000, 5000, 5000, 5000, 5000); // Dummy test locations/size
	SpatialDetails sdnucleusDigits(-10000, 5000, 5000, 5000, 5000, 5000); // Dummy test locations/size

	SpatialDetails sdregionAssociative(5000, 0, -2500, 5000, 5000, 5000); // Dummy test locations/size
	SpatialDetails sdnucleusAssociative(5000, 0, -2500, 5000, 5000, 5000); // Dummy test locations/size

	SpatialDetails sdregionImages(-10000, -5000, -5000, 5000, 5000, 5000); // Dummy test locations/size
	SpatialDetails sdnucleusImages(-10000, -5000, -5000, 5000, 5000, 5000); // Dummy test locations/size

	// Create Thalamus
	LOGSTREAM(ss) << "Create regionDigits region... " << std::endl;
	globalObject->log(ss);

	// Digits - 10 neurons
	Region *regionDigits = 0L;
	if(brain->restartpoint())
	{
		regionDigits = Region::create("regionDigits", sdregionDigits);
	} 
	else 
	{
		long regionId = globalObject->componentBase[ComponentTypeRegion]; 
		regionDigits = globalObject->regionDB.getComponent(regionId);
		globalObject->insert(regionDigits);

		LOGSTREAM(ss) << "regionDigits globalObject->regionDB.getComponent(" << regionId << ") " << std::endl;
		globalObject->log(ss);
	}
	brain->syncpoint();


	// Create Thalamic Nuclei
	ColumnNeuronProfile profile; // default profile for all layers is Pyramidal neurons, 100 neurons per cluster, with 10 clusters

	Nucleus *nucleusDigits = 0L;
	if(brain->restartpoint())
	{
		nucleusDigits = Nucleus::create("nucleusDigits", sdnucleusDigits);
		nucleusDigits->nucleusType = MOTOR_NUCLEUS;
		regionDigits->add(nucleusDigits);
//		regionDigits->addColumns(10,profile); // 10 columns, each with 6 layers, each with 5 clusters, each with 10 neurons
//		regionDigits->addColumns(1,1,10); // 1 column, each with 6 layers, each with 1 clusters, each with 10 neurons
		nucleusDigits->addColumns(1,1,1,10); // 1 column, each with 2 layers, each with 1 clusters, each with 10 neurons


		float minX = nucleusDigits->location.x;
		float maxX = minX + nucleusDigits->area.w;
		float minZ = nucleusDigits->location.z;
		float maxZ = minZ + nucleusDigits->area.d;

		float spaceX = (nucleusDigits->area.w / 10); 

		Column *column = globalObject->columnDB.getComponent(nucleusDigits->columns[0]);
		Layer *layer = globalObject->layerDB.getComponent(column->layers[0]);
		std::vector<long> clusters = layer->clusters;
		int clusterCount = clusters.size();
		float xCoord = minX;
		float zCoord = minZ;
		for (int clusterIndex = 0; clusterIndex < clusterCount; clusterIndex++)
		{
			Cluster *cluster = globalObject->clusterDB.getComponent(clusters[clusterIndex]);
			std::vector<long> neurons = cluster->getNeurons();
			int nCount = neurons.size();
			float thisXCoord = xCoord;
			for (int nIndex = 0; nIndex < nCount; nIndex++)
			{
				Neuron *neuron = globalObject->neuronDB.getComponent(neurons[nIndex]);
				neuron->location.x = xCoord;
				neuron->location.z = zCoord;
				xCoord += spaceX;
			}
		}
	} 
	else 
	{
		long nucleusId = globalObject->componentBase[ComponentTypeNucleus]; 
		nucleusDigits = globalObject->nucleusDB.getComponent(nucleusId);
	}
	brain->syncpoint();

	LOGSTREAM(ss) << "Region " << regionDigits->name << " complete with " << regionDigits->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);

	// Images - 784 neurons
	Region *regionImages = 0L;
	if(brain->restartpoint())
	{
		regionImages = Region::create("regionImages", sdregionImages);
	}
	else
	{
		long regionId = globalObject->componentBase[ComponentTypeRegion] + 1; 
		regionImages = globalObject->regionDB.getComponent(regionId);
		globalObject->insert(regionImages);
	}
	brain->syncpoint();

	Nucleus *nucleusImages = 0L;
	if(brain->restartpoint())
	{
		nucleusImages = Nucleus::create("nucleusImages", sdnucleusImages);
		nucleusImages->nucleusType = SENSORY_NUCLEUS;

		regionImages->add(nucleusImages);
//		nucleusImages->addColumns(1,1,784); // 1 column, each with 6 layers, each with 1 clusters, each with 784 neurons
		nucleusImages->addColumns(1,1,784,8); // 1 column, each with 1 layers, each with 1 clusters, each with 784*8 neurons

		int totalChangedCount = 0;
		float minX = nucleusImages->location.x;
		float maxX = minX + nucleusImages->area.w;
		float minZ = nucleusImages->location.z;
		float maxZ = minZ + nucleusImages->area.d;
		float spaceX = (nucleusImages->area.w / 28) / 4; // 28 groupings of 8 neurons
		float spaceZ = (nucleusImages->area.d / 28) / 2; // 28 groupings of 8 neurons
		Column *column = globalObject->columnDB.getComponent(nucleusImages->columns[0]);
		Layer *layer = globalObject->layerDB.getComponent(column->layers[0]);
		std::vector<long> clusters = layer->clusters;
		int clusterCount = clusters.size();
		float xCoord = minX;
		float zCoord = minZ;
		int row =0;
		for (int clusterIndex = 0; clusterIndex < clusterCount; clusterIndex++)
		{
			Cluster *cluster = globalObject->clusterDB.getComponent(clusters[clusterIndex]);
			std::vector<long> neurons = cluster->getNeurons();
			int nCount = neurons.size();
			float thisXCoord = xCoord;
			for (int nIndex = 0; nIndex < nCount; nIndex++)
			{
				Neuron *neuron = globalObject->neuronDB.getComponent(neurons[nIndex]);

				neuron->location.x = xCoord;
				neuron->location.z = zCoord;
				xCoord += spaceX;
				totalChangedCount++;
			}
			xCoord += spaceX*2;
			if ((clusterIndex+1) % 28*8 == 0)
			{
				xCoord = minX;
				zCoord += spaceZ * 2;
			}

		}

		std::cout << "Total Neurons Adjusted: " << totalChangedCount << std::endl;
	}

	else
	{
		long nucleusId = globalObject->componentBase[ComponentTypeNucleus] + 1; 
		nucleusImages = globalObject->nucleusDB.getComponent(nucleusId);
	} 
	brain->syncpoint();


	// Associative region - 10 neurons
	Region *regionAssociative = 0L;
	if(brain->restartpoint())
	{
		regionAssociative = Region::create("regionAssociative", sdregionAssociative);
	} 
	else 
	{
		long regionId = globalObject->componentBase[ComponentTypeRegion] + 2; 
		regionAssociative = globalObject->regionDB.getComponent(regionId);
		globalObject->insert(regionAssociative);

		LOGSTREAM(ss) << "regionAssociative globalObject->regionDB.getComponent(" << regionId << ") " << std::endl;
		globalObject->log(ss);
	}
	brain->syncpoint();


	Nucleus *nucleusAssociative = 0L;
	if(brain->restartpoint())
	{
		nucleusAssociative = Nucleus::create("nucleusAssociative", sdnucleusAssociative);
		nucleusAssociative->nucleusType = MOTOR_NUCLEUS;
		regionAssociative->add(nucleusAssociative);
//		regionDigits->addColumns(10,profile); // 10 columns, each with 6 layers, each with 5 clusters, each with 10 neurons
//		regionDigits->addColumns(1,1,10); // 1 column, each with 6 layers, each with 1 clusters, each with 10 neurons
		int numNeurons = 10; // 10 neurons in each cluster
		nucleusAssociative->addColumns(5,6,5,numNeurons); // 1 column, each with 2 layers, each with 1 clusters, each with 10 neurons
	} 
	else 
	{
		long nucleusId = globalObject->componentBase[ComponentTypeNucleus]; 
		nucleusAssociative = globalObject->nucleusDB.getComponent(nucleusId);
	}
	brain->syncpoint();

	LOGSTREAM(ss) << "Region " << regionDigits->name << " complete with " << regionDigits->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);


	LOGSTREAM(ss) << "Region " << regionImages->name << " complete with " << regionImages->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << "Region " << regionAssociative->name << " complete with " << regionAssociative->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);

	
	LOGSTREAM(ss) << std::endl << "... " << std::endl << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << formatNumber(globalObject->regionsSize()) << " regions created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->nucleiSize()) << " nuclei created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->columnsSize()) << " columns created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->layersSize()) << " layers created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->clustersSize()) << " clusters created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->neuronsSize()) << " neurons created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->axonsSize()) << " axons created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << std::endl << "... " << std::endl << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << "Attach regions" << std::endl;
	globalObject->log(ss);
// Finally, attach the Regions


	// receiveInputFrom means that the that the source extends dendrites to receive input from the target

	// Digits receiveInputFrom images
	LOGSTREAM(ss) << "    regionDigits->receiveInputFrom(regionImages)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionDigits->receiveInputFrom(regionImages,100.f,EXCITATORY_SYNAPSE);
	}
	brain->syncpoint();

	// Associative receiveInputFrom to images
	LOGSTREAM(ss) << "    regionAssociative->receiveInputFrom(regionImages)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionAssociative->receiveInputFrom(regionImages,100.f,EXCITATORY_SYNAPSE);
	}
	brain->syncpoint();

	// Associative receiveInputFrom to digits
	LOGSTREAM(ss) << "    regionAssociative->receiveInputFrom(regionDigits)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionAssociative->receiveInputFrom(regionDigits,100.f,EXCITATORY_SYNAPSE); // Inhibitory synapses!
	}
	brain->syncpoint();

	// Digits receiveInputFrom to associative
	LOGSTREAM(ss) << "    regionDigits->receiveInputFrom(regionAssociative)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionDigits->receiveInputFrom(regionAssociative,100.f,INHIBITORY_SYNAPSE);	// Inhibitory synapses!
	}
	brain->syncpoint();


	LOGSTREAM(ss) << "------------------------------------------------------" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->dendritesSize()) << " dendrites created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->synapsesSize()) << " synapses created" << std::endl;
	globalObject->log(ss);

	

	if(true)
	{
		long start_neuron = regionDigits->getStartNeuron();
		long end_neuron = regionDigits->getEndNeuron();
		LOGSTREAM(ss) << "          regionDigits " << (end_neuron - start_neuron +1 ) << " neurons [" << start_neuron << " - " << end_neuron << "]" << std::endl;
		globalObject->log(ss);


		start_neuron = regionImages->getStartNeuron();
		end_neuron = regionImages->getEndNeuron();
		LOGSTREAM(ss) << "          regionImages " << (end_neuron - start_neuron + 1) << " neurons [" << start_neuron << " - " << end_neuron << "]" << std::endl;
		globalObject->log(ss);

		start_neuron = regionAssociative->getStartNeuron();
		end_neuron = regionAssociative->getEndNeuron();
		LOGSTREAM(ss) << "          regionAssociative " << (end_neuron - start_neuron + 1) << " neurons [" << start_neuron << " - " << end_neuron << "]" << std::endl;
		globalObject->log(ss);
	}


	unsigned long zeroAxonCount = 0;
	unsigned long zeroDendriteCount = 0;
//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
//	for (itAxon.begin(); itAxon.more(); itAxon.next()) 
	long axonIdStart = globalObject->componentBase[ComponentTypeAxon];
	long axonIdEnd = globalObject->componentCounter[ComponentTypeAxon];

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon *axon = globalObject->axonDB.getComponent(axonId);
		
		if(axon->getSynapses()->size()==0) {
			zeroAxonCount++;
//			std::cout << "BrainDemoHWRecognition.create: Axon " << axon->id << " has no synapses." << std::endl;

		}
		long neuronId = axon->neuronId;
		Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
		if(neuron->getDendrites()->size()==0) {
			zeroDendriteCount++;
//			std::cout << "BrainDemoHWRecognition.create: Axon " << axon->id << " has no synapses." << std::endl;

		}
	}
	LOGSTREAM(ss) << formatNumber(zeroAxonCount) << " axons have no synapses." << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << formatNumber(zeroDendriteCount) << " neurons have no dendrites." << std::endl;
	globalObject->log(ss);

	// Make final Adustments
	//finalAxonAdjustments(ss);

	//finalDendriteAdjustments(ss);

	long nucleusIdStart = globalObject->componentBase[ComponentTypeNucleus];
	long nucleusIdEnd = globalObject->componentCounter[ComponentTypeNucleus];

	for (long nucleusId = nucleusIdStart; nucleusId < nucleusIdEnd; nucleusId++)
	{
		Nucleus *nuc = globalObject->nucleusDB.getComponent(nucleusId);
		std::vector<long> neurons = Server::getNeurons(nuc->name, LayerType::input); // only one layer for now
		long startNeuronId = globalObject->componentBase[ComponentTypeAxon] - 1; // highest possible neuronId
		long endNeuronId = 0;
		for(size_t nIndex = 0; nIndex < neurons.size(); nIndex++)
		{
			long thisNeuronId = neurons[nIndex];

			if(thisNeuronId < startNeuronId)
				startNeuronId = thisNeuronId;

			if(thisNeuronId > endNeuronId)
				endNeuronId = thisNeuronId;

			if(nuc->name.compare("nucleusAssociative")==0) // make associative neurons inhibitory
			{
				Neuron *n = globalObject->neuronDB.getComponent(thisNeuronId);
				n->neuronPolarity = Polarity::INHIBITORY_NEURON;
			}
		}

		LOGSTREAM(ss) << "Nucleus ..." << nuc->name << ": beginning neuron=" << startNeuronId <<", ending neuron=" << endNeuronId << std::endl;
		globalObject->log(ss);
		globalObject->flush();
	}


	LOGSTREAM(ss) << "Flush started..." << std::endl;
	globalObject->log(ss);
	globalObject->flush();
	LOGSTREAM(ss) << "Flush complete..." << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << "SNNEngine ready to accept input..." << std::endl;
	globalObject->log(ss);

	globalObject->logStructure();
//	globalObject->logStructure(regionDigits);
//	globalObject->logStructure(nucleusImages);


	return brain;
}
/*
void BrainDemoTiny::experiments(Nucleus *nucleusImages)
{
	// Set any clusters beyond the first cluster to inhibitory
	size_t colSize = nucleusImages->columns.size();
	for (size_t i = 0; i < colSize; i++)
	{
		long thisColId = nucleusImages->columns[i];
		Column *thisCol = globalObject->columnDB.getComponent(thisColId);
		size_t layerSize = thisCol->layers.size();
		for (size_t j = 0; j < layerSize; j++)
		{
			long thisLayerId = thisCol->layers[j];
			Layer *thisLayer = globalObject->layerDB.getComponent(thisLayerId);
			size_t clusterSize = thisLayer->clusters.size();
			for (size_t k = 0; k < clusterSize; k++)
			{
				if (k != 0) // only change those clusters beyond the first
				{
					long thisClusterId = thisLayer->clusters[k];
					Cluster *thisCluster = globalObject->clusterDB.getComponent(thisClusterId);
					size_t neuronsSize = thisCluster->neurons.size();
					for (size_t m = 0; m < neuronsSize; m++)
					{
						long thisNeuronId = thisCluster->neurons[m];
						Neuron *thisNeuron = globalObject->neuronDB.getComponent(thisNeuronId);
						std::vector<long> *dendrites = thisNeuron->getDendrites();
						size_t dendritesSize = dendrites->size();
						for (size_t n = 0; n < dendritesSize; n++)
						{
							long dendriteId = (*dendrites)[n];
							Dendrite *thisDendrite = globalObject->dendriteDB.getComponent(dendriteId);
							long thisSynapseId = thisDendrite->getSynapseId();
							Synapse *thisSynapse = globalObject->synapseDB.getComponent(thisSynapseId);
							thisSynapse->polarity = INHIBITORY;
						}
					}
				}
			}
		}
	}
}
*/

void BrainDemoTiny::finalDendriteAdjustments(std::stringstream &ss)
{
	LOGSTREAM(ss) << "Making final dendrite adjustments..." << std::endl;
	globalObject->log(ss);

	long neuronIdStart = globalObject->componentBase[ComponentTypeNeuron];
	long neuronIdEnd = globalObject->componentCounter[ComponentTypeNeuron];
	for(long neuronId=neuronIdStart;neuronId<neuronIdEnd;neuronId++)
	{
		Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
		if(neuron->getDendrites()->size()==0) {
			// add dendites by connecting to neurons referenced by our axons 

			std::vector<long> *axons = neuron->getAxons();
			long mainAxonId = (*axons)[0];
			Axon *thisAxon = globalObject->axonDB.getComponent(mainAxonId);
			std::vector<long> *synapses = thisAxon->getSynapses();
			if(synapses->size()>0)
			{
				long synapseId = (*synapses)[0];
				Synapse *thisSynapse = globalObject->synapseDB.getComponent(synapseId);

				long sourceNeuronId = thisSynapse->postSynapticNeuronId; //????
				Neuron *sourceNeuron = globalObject->neuronDB.getComponent(sourceNeuronId);
				neuron->connectFrom(sourceNeuron,thisSynapse->polarity);
			}
		}
	}

	unsigned long zeroDendriteCount = 0;
//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
//	for (itAxon.begin(); itAxon.more(); itAxon.next()) 
	long axonIdStart = globalObject->componentBase[ComponentTypeAxon];
	long axonIdEnd = globalObject->componentCounter[ComponentTypeAxon];

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon *axon = globalObject->axonDB.getComponent(axonId);
		long neuronId = axon->neuronId;
		Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
		if(neuron->getDendrites()->size()==0) {
			zeroDendriteCount++;
//			std::cout << "BrainDemoHWRecognition.create: Axon " << axon->id << " has no synapses." << std::endl;

		}
	}
	LOGSTREAM(ss) << formatNumber(zeroDendriteCount) << " neurons have no dendrites after fixup." << std::endl;
	globalObject->log(ss);

}

void BrainDemoTiny::finalAxonAdjustments(std::stringstream &ss)
{
	LOGSTREAM(ss) << "Making final axon adjustments..." << std::endl;
	globalObject->log(ss);

	unsigned long zeroCount = 0;

	long axonIdStart = globalObject->componentBase[ComponentTypeAxon];
	long axonIdEnd = globalObject->componentCounter[ComponentTypeAxon];

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon* ax = globalObject->axonDB.getComponent(axonId);
		if (ax->getSynapses()->size() == 0)
		{
			zeroCount++;
//			std::cout << "BrainDemoHWRecognition.finalAdjustments: Axon " << ax->id << " has no synapses." << std::endl;
		}
	}

	LOGSTREAM(ss) << formatNumber(zeroCount) << " axons have no synapses before fixup." << std::endl;
	globalObject->log(ss);

	unsigned long added = 0;
	if (zeroCount > 0) {

		float pct = 0;
		float index = 1;
		//std::vector<unsigned long, unsigned long> newSynapses;
		//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
		//	for (itAxon.begin(); itAxon.more(); itAxon.next())
		size_t axonCount = globalObject->axonDB.size();

		for (globalObject->axonDB.begin(); globalObject->axonDB.more(); globalObject->axonDB.next())
		{
			Axon* ax = globalObject->axonDB.getValue();
			if (ax->getSynapses()->size() == 0)
			{
				// An axon with zero synapses found. Create a synapse for this guy to somewhere... anywhere
	//////////////////////////
				long neuronId = ax->neuronId;
				Neuron* neu = globalObject->neuronDB.getComponent(neuronId);				// we have the neuron in question
				long parentClusterId = neu->parentId;
				Cluster* cl = globalObject->clusterDB.getComponent(parentClusterId);			// we have the cluster that this neuron belongs to
				size_t cSize = cl->getNeurons().size();
				for (size_t i = 0; i < cSize; i++)										// Loop through each neuron in this cluster
				{
					long nId = cl->getNeurons()[i];
					if (nId > 0)
					{
						if (nId != neuronId)										// Ignore if we're looking at our own neuron
						{	// Valud neuronId and not equal to current one
							Neuron* neuX = globalObject->neuronDB.getComponent(nId);			// Get the neuron we want to attach to....
							if (neuX != NULL)												// Make sure it's valid
							{
								added++;
								Dendrite* den = Dendrite::create(neuX,neu,-1.0);		 		// Create a new inhibitory dendrite 
                                neuX->dendriteMap.insert(std::make_pair(neu->id, den->id));
								Synapse* s = Synapse::create(den,-1.0);					// Add a synapse to the dendrite -- inhibitory 
								long sid = s->id;
								ax->insertSynapse(sid);								// Attatch this new synapse to our axon
							}
							else
							{
								LOGSTREAM(ss) << "Neuron id " << formatNumber(nId) << " in cluster  " << formatNumber(parentClusterId) << " not found" << std::endl;
								globalObject->log(ss);
							}
						}
					}
					else
					{
						LOGSTREAM(ss) << "Zero neuronId found in cluster  " << formatNumber(parentClusterId) << " not found" << std::endl;
						globalObject->log(ss);
					}
				}
				//////////////////////////
			}
			pct = index / axonCount;
			printf("Pct Complete %f\r", pct * 100.0f);

			index++;
		}
	}

	// Wrap up...

	LOGSTREAM(ss) << formatNumber(added) << " synapses added." << std::endl;
	globalObject->log(ss);


	zeroCount = 0;

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon* ax = globalObject->axonDB.getComponent(axonId);
		if (ax->getSynapses()->size() == 0)
		{
			zeroCount++;
			std::cout << "BrainDemoHWRecognition.wrapip: Axon " << ax->id << " has no synapses." << std::endl;
		}
	}

	LOGSTREAM(ss) << formatNumber(zeroCount) << " axons have no synapses after fixup." << std::endl;
	globalObject->log(ss);


	LOGSTREAM(ss) << "Final axon adjustments complete..." << std::endl;
	globalObject->log(ss);

}



void BrainDemoTiny::step(Brain *brain)
{
	(void)brain;
//	std::cout << "Current timestamp " << globalObject->getCurrentTimestamp() << " Current AP count " << globalObject->actionPotentialsSize() << std::endl;


	std::stringstream ss;
/****
	if(globalObject->actionPotentialsSize()>0) {
		LOGSTREAM(ss) << "Current timestamp " << globalObject->getCurrentTimestamp() << " Current AP count " << globalObject->actionPotentialsSize() << std::endl;
		globalObject->log(ss);
	}
****/

}

std::string BrainDemoTiny::formatNumber(unsigned long long number) {
	std::stringstream ss;
	ss.imbue(std::locale(""));
	ss << std::fixed << number;
	return ss.str();

}

// This kludge is to sprinkle synapses among the clusters within nucleus, and within the neurons within clusters
void BrainDemoTiny::insertSynapses(Nucleus* nuc) {
	for (size_t i = 0; i < nuc->columns.size(); i++) {
		long colId = nuc->columns[i];
		Column* col = globalObject->columnDB.getComponent(colId);
		for (size_t j = 0; j < col->layers.size(); j++) {
			long layerId = col->layers[j];
			Layer *lay = globalObject->layerDB.getComponent(layerId);
			// If inputlayer, polarity is inhibitory, otherwise excitatory
			float polarity = EXCITATORY_SYNAPSE;
			if(j==(size_t)col->inputLayer)
				polarity = EXCITATORY_SYNAPSE;

			for (size_t k = 0; k < lay->clusters.size(); k++) {
				long clusterId = lay->clusters[k];
				Cluster* clu = globalObject->clusterDB.getComponent(clusterId);
				for (size_t l = 0; l < clu->getNeurons().size(); l++) {
					long neuronId = clu->getNeurons()[l];
					Neuron* neu = globalObject->neuronDB.getComponent(neuronId);
					std::vector<long> *axons = neu->getAxons();
					for (size_t m = 0; m < axons->size(); m++) {
						//long axonId = (*axons)[m];
						//Axon* axon = globalObject->axonDB.getComponent(axonId);
						// We know have the axon which we will be attaching synapses to
						// This is a place holder for a more sophisticated algorythm to assign synapses. Perhaps future models with 3D information loaded in (SpatialDetails)
						// can place synapses where axons and dendrites come in close proximity
						//
						// But for now, let's just do random
						//
						// Iterate over neurons in this cluster and associate X% of them, selected at random, with the dendrites of other neurons
						// 
						//int percent = 100; // start with 98%
						//
						//boost::random::mt19937 gen;

						for (size_t ll = 0; ll < clu->getNeurons().size(); ll++) {
							unsigned long neuronId2 = clu->getNeurons()[ll];
							if (neuronId2 != neu->id) { // If not ourself
								Neuron* neu2 = globalObject->neuronDB.getComponent(neuronId2);
								//boost::random::uniform_int_distribution<> dist(0, 100);
								//int value = dist(percent);
								//if (value <= percent) 
								//{
									if(!neu->isConnectedTo(neu2)) 
									{
										neu->connectTo(neu2,polarity);
									}
								//}
							}

						}

					}

				}
			}
		}
	}
}

// This kludge is to sprinkle synapses between nucleus's A and B
void BrainDemoTiny::insertSynapses(Nucleus* nucA, Nucleus* nucB) {
	// null for now
	(void)nucA;
	(void)nucB;
}


Brain* BrainDemoTiny::createFromJSON(void) 
{
	Brain* brain;

	std::stringstream ss;

	LOGSTREAM(ss) << " Loading brain from JSON" << std::endl;
	globalObject->log(ss);
	brain = Brain::loadFromJSON("../../../database/","BrainDemoTiny");
	return brain;
}


int main(int argc, char *argv[])
{
	SNNEngine *engine = new SNNEngine();
	engine->initialize("../../../database/","BrainDemoTiny");
	engine->startEngine();
}



// ============== BrainDemoTiny.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

class BrainDemoTiny
{
public:
	BrainDemoTiny(void);
	~BrainDemoTiny(void);
	static Brain *create(bool rebuild=true);
	static Brain* createFromJSON(void);
	static void step(Brain *brain);
	static std::string formatNumber(unsigned long long number);
	static void insertSynapses(Nucleus *nuc);
	static void insertSynapses(Nucleus* nucA, Nucleus* nucB);
	static void finalDendriteAdjustments(std::stringstream &ss);
	static void finalAxonAdjustments(std::stringstream &ss);
	//static void experiments(Nucleus *nucleus);
};


// ============== BrainUnitTest.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Global.h"
#include "TR1Random.h"
#include "BrainUnitTest.h"
#include "SNNEngine.h"

#include <boost/random/mersenne_twister.hpp>
#include <boost/random/uniform_int_distribution.hpp>


BrainUnitTest::BrainUnitTest(void)
{
}

BrainUnitTest::~BrainUnitTest(void)
{
}

Brain * BrainUnitTest::create(bool rebuild) 
{

	Brain *brain; 

	std::stringstream ss;

	if(!rebuild) // if not rebuilding, just return brain
	{
		LOGSTREAM(ss) << " Loading brain" << std::endl;
		globalObject->log(ss);
		brain = Brain::load("../../../database/","BrainUnitTest");
	} 
	else 
	{
		LOGSTREAM(ss) << " Creating brain" << std::endl;
		globalObject->log(ss);
		brain = Brain::create(true,"../../../database/","BrainUnitTest");
	}


	SpatialDetails sd(25000, 25000, 25000, 50000, 50000, 50000); // Dummy test locations/size


	// Create Thalamus
	LOGSTREAM(ss) << "Create regionDigits region... " << std::endl;
	globalObject->log(ss);

	// Digits - 10 neurons
	Region *regionDigits = 0L;
	if(brain->restartpoint())
	{
		regionDigits = Region::create("regionDigits", sd);
		brain->add(regionDigits);
	} 
	else 
	{
		long regionId = globalObject->componentBase[ComponentTypeRegion]; 
		regionDigits = globalObject->regionDB.getComponent(regionId);
		LOGSTREAM(ss) << "regionDigits globalObject->regionDB.getComponent(" << regionId << ") " << std::endl;
		globalObject->log(ss);
	}
	brain->syncpoint();


	// Create Thalamic Nuclei
	ColumnNeuronProfile profile; // default profile for all layers is Pyramidal neurons, 100 neurons per cluster, with 10 clusters

	Nucleus *nucleusDigits = 0L;
	if(brain->restartpoint())
	{
		nucleusDigits = Nucleus::create("nucleusDigits", sd);
		nucleusDigits->nucleusType = MOTOR_NUCLEUS;
		regionDigits->add(nucleusDigits);
//		regionDigits->addColumns(10,profile); // 10 columns, each with 6 layers, each with 5 clusters, each with 10 neurons
//		regionDigits->addColumns(1,1,10); // 1 column, each with 6 layers, each with 1 clusters, each with 10 neurons
		nucleusDigits->addColumns(1,1,1,10); // 1 column, each with 2 layers, each with 1 clusters, each with 10 neurons
	} 
	else 
	{
		long nucleusId = globalObject->componentBase[ComponentTypeNucleus]; 
		nucleusDigits = globalObject->nucleusDB.getComponent(nucleusId);
	}
	brain->syncpoint();

	LOGSTREAM(ss) << "Region " << regionDigits->name << " complete with " << regionDigits->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);

	// Images - 784 neurons
	Region *regionImages = 0L;
	if(brain->restartpoint())
	{
		regionImages = Region::create("regionImages", sd);
		brain->add(regionImages);
	}
	else
	{
		long regionId = globalObject->componentBase[ComponentTypeRegion] + 1; 
		regionImages = globalObject->regionDB.getComponent(regionId);
	}
	brain->syncpoint();

	Nucleus *nucleusImages = 0L;
	if(brain->restartpoint())
	{
		nucleusImages = Nucleus::create("nucleusImages", sd);
		nucleusImages->nucleusType = SENSORY_NUCLEUS;

		regionImages->add(nucleusImages);
//		nucleusImages->addColumns(1,1,784); // 1 column, each with 6 layers, each with 1 clusters, each with 784 neurons
		nucleusImages->addColumns(1,1,784,8); // 1 column, each with 1 layers, each with 1 clusters, each with 784*8 neurons

		// experiments(nucleusImages);
	}

	else
	{
		long nucleusId = globalObject->componentBase[ComponentTypeNucleus] + 1; 
		nucleusImages = globalObject->nucleusDB.getComponent(nucleusId);
	} 
	brain->syncpoint();


	// Associative region - 10 neurons
	Region *regionAssociative = 0L;
	if(brain->restartpoint())
	{
		regionAssociative = Region::create("regionAssociative", sd);
		brain->add(regionAssociative);
	} 
	else 
	{
		long regionId = globalObject->componentBase[ComponentTypeRegion]; 
		regionAssociative = globalObject->regionDB.getComponent(regionId);
		LOGSTREAM(ss) << "regionAssociative globalObject->regionDB.getComponent(" << regionId << ") " << std::endl;
		globalObject->log(ss);
	}
	brain->syncpoint();


	Nucleus *nucleusAssociative = 0L;
	if(brain->restartpoint())
	{
		nucleusAssociative = Nucleus::create("nucleusAssociative", sd);
		nucleusAssociative->nucleusType = MOTOR_NUCLEUS;
		regionAssociative->add(nucleusAssociative);
//		regionDigits->addColumns(10,profile); // 10 columns, each with 6 layers, each with 5 clusters, each with 10 neurons
//		regionDigits->addColumns(1,1,10); // 1 column, each with 6 layers, each with 1 clusters, each with 10 neurons
		int numNeurons = 100; //(784*8)/2; // Half of images neuron count
		nucleusAssociative->addColumns(1,1,1,numNeurons); // 1 column, each with 2 layers, each with 1 clusters, each with 10 neurons
	} 
	else 
	{
		long nucleusId = globalObject->componentBase[ComponentTypeNucleus]; 
		nucleusAssociative = globalObject->nucleusDB.getComponent(nucleusId);
	}
	brain->syncpoint();

	LOGSTREAM(ss) << "Region " << regionDigits->name << " complete with " << regionDigits->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);


	LOGSTREAM(ss) << "Region " << regionImages->name << " complete with " << regionImages->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << "Region " << regionAssociative->name << " complete with " << regionAssociative->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);

	
	LOGSTREAM(ss) << std::endl << "... " << std::endl << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << formatNumber(globalObject->regionsSize()) << " regions created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->nucleiSize()) << " nuclei created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->columnsSize()) << " columns created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->layersSize()) << " layers created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->clustersSize()) << " clusters created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->neuronsSize()) << " neurons created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->axonsSize()) << " axons created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << std::endl << "... " << std::endl << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << "Attach regions" << std::endl;
	globalObject->log(ss);
// Finally, attach the Regions


	// receiveInputFrom means that the that the source extends dendrites to receive input from the target

	// Digits receiveInputFrom images
	LOGSTREAM(ss) << "    regionDigits->receiveInputFrom(regionImages)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionDigits->receiveInputFrom(regionImages,100.f);
	}
	brain->syncpoint();

	// Digits receiveInputFrom to associative
	LOGSTREAM(ss) << "    regionDigits->receiveInputFrom(regionAssociative)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionDigits->receiveInputFrom(regionAssociative,100.f);
	}
	brain->syncpoint();

	// Associative receiveInputFrom to images
	LOGSTREAM(ss) << "    regionAssociative->receiveInputFrom(regionImages)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionAssociative->receiveInputFrom(regionImages,100.f);
	}
	brain->syncpoint();

	// Associative receiveInputFrom to digits
	LOGSTREAM(ss) << "    regionAssociative->receiveInputFrom(regionDigits)" << std::endl;
	globalObject->log(ss);
	if(brain->restartpoint())
	{
		regionAssociative->receiveInputFrom(regionDigits,100.f);
	}
	brain->syncpoint();

	LOGSTREAM(ss) << "------------------------------------------------------" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->dendritesSize()) << " dendrites created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->synapsesSize()) << " synapses created" << std::endl;
	globalObject->log(ss);

	

	if(true)
	{
		long start_neuron = regionDigits->getStartNeuron();
		long end_neuron = regionDigits->getEndNeuron();
		LOGSTREAM(ss) << "          regionDigits " << (end_neuron - start_neuron +1 ) << " neurons [" << start_neuron << " - " << end_neuron << "]" << std::endl;
		globalObject->log(ss);


		start_neuron = regionImages->getStartNeuron();
		end_neuron = regionImages->getEndNeuron();
		LOGSTREAM(ss) << "          regionImages " << (end_neuron - start_neuron + 1) << " neurons [" << start_neuron << " - " << end_neuron << "]" << std::endl;
		globalObject->log(ss);

		start_neuron = regionAssociative->getStartNeuron();
		end_neuron = regionAssociative->getEndNeuron();
		LOGSTREAM(ss) << "          regionAssociative " << (end_neuron - start_neuron + 1) << " neurons [" << start_neuron << " - " << end_neuron << "]" << std::endl;
		globalObject->log(ss);
	}


	unsigned long zeroAxonCount = 0;
	unsigned long zeroDendriteCount = 0;
//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
//	for (itAxon.begin(); itAxon.more(); itAxon.next()) 
	long axonIdStart = globalObject->componentBase[ComponentTypeAxon];
	long axonIdEnd = globalObject->componentCounter[ComponentTypeAxon];

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon *axon = globalObject->axonDB.getComponent(axonId);
		
		if(axon->getSynapses()->size()==0) {
			zeroAxonCount++;
//			std::cout << "BrainDemoHWRecognition.create: Axon " << axon->id << " has no synapses." << std::endl;

		}
		long neuronId = axon->neuronId;
		Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
		if(neuron->getDendrites()->size()==0) {
			zeroDendriteCount++;
//			std::cout << "BrainDemoHWRecognition.create: Axon " << axon->id << " has no synapses." << std::endl;

		}
	}
	LOGSTREAM(ss) << formatNumber(zeroAxonCount) << " axons have no synapses." << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << formatNumber(zeroDendriteCount) << " neurons have no dendrites." << std::endl;
	globalObject->log(ss);

	// Make final Adustments
	//finalAxonAdjustments(ss);

	//finalDendriteAdjustments(ss);

	long nucleusIdStart = globalObject->componentBase[ComponentTypeNucleus];
	long nucleusIdEnd = globalObject->componentCounter[ComponentTypeNucleus];

	for (long nucleusId = nucleusIdStart; nucleusId < nucleusIdEnd; nucleusId++)
	{
		Nucleus *nuc = globalObject->nucleusDB.getComponent(nucleusId);
		std::vector<long> neurons = Server::getNeurons(nuc->name, LayerType::input); // only one layer for now
		long startNeuronId = globalObject->componentBase[ComponentTypeAxon] - 1; // highest possible neuronId
		long endNeuronId = 0;
		for(size_t nIndex = 0; nIndex < neurons.size(); nIndex++)
		{
			long thisNeuronId = neurons[nIndex];

			if(thisNeuronId < startNeuronId)
				startNeuronId = thisNeuronId;

			if(thisNeuronId > endNeuronId)
				endNeuronId = thisNeuronId;
		}

		LOGSTREAM(ss) << "Nucleus ..." << nuc->name << ": beginning neuron=" << startNeuronId <<", ending neuron=" << endNeuronId << std::endl;
		globalObject->log(ss);
		globalObject->flush();
	}


	LOGSTREAM(ss) << "Flush started..." << std::endl;
	globalObject->log(ss);
	globalObject->flush();
	LOGSTREAM(ss) << "Flush complete..." << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << "SNNEngine ready to accept input..." << std::endl;
	globalObject->log(ss);

	globalObject->logStructure();
//	globalObject->logStructure(regionDigits);
//	globalObject->logStructure(nucleusImages);


	return brain;
}

void BrainUnitTest::experiments(Nucleus *nucleusImages)
{
	// Set any clusters beyond the first cluster to inhibitory
	size_t colSize = nucleusImages->columns.size();
	for (size_t i = 0; i < colSize; i++)
	{
		long thisColId = nucleusImages->columns[i];
		Column *thisCol = globalObject->columnDB.getComponent(thisColId);
		size_t layerSize = thisCol->layers.size();
		for (size_t j = 0; j < layerSize; j++)
		{
			long thisLayerId = thisCol->layers[j];
			Layer *thisLayer = globalObject->layerDB.getComponent(thisLayerId);
			size_t clusterSize = thisLayer->clusters.size();
			for (size_t k = 0; k < clusterSize; k++)
			{
				if (k != 0) // only change those clusters beyond the first
				{
					long thisClusterId = thisLayer->clusters[k];
					Cluster *thisCluster = globalObject->clusterDB.getComponent(thisClusterId);
					size_t neuronsSize = thisCluster->neurons.size();
					for (size_t m = 0; m < neuronsSize; m++)
					{
						long thisNeuronId = thisCluster->neurons[m];
						Neuron *thisNeuron = globalObject->neuronDB.getComponent(thisNeuronId);
						std::vector<long> *dendrites = thisNeuron->getDendrites();
						size_t dendritesSize = dendrites->size();
						for (size_t n = 0; n < dendritesSize; n++)
						{
							long dendriteId = (*dendrites)[n];
							Dendrite *thisDendrite = globalObject->dendriteDB.getComponent(dendriteId);
							long thisSynapseId = thisDendrite->getSynapseId();
							Synapse *thisSynapse = globalObject->synapseDB.getComponent(thisSynapseId);
							thisSynapse->polarity = INHIBITORY;
						}
					}
				}
			}
		}
	}
}

void BrainUnitTest::finalDendriteAdjustments(std::stringstream &ss)
{
	LOGSTREAM(ss) << "Making final dendrite adjustments..." << std::endl;
	globalObject->log(ss);

	long neuronIdStart = globalObject->componentBase[ComponentTypeNeuron];
	long neuronIdEnd = globalObject->componentCounter[ComponentTypeNeuron];
	for(long neuronId=neuronIdStart;neuronId<neuronIdEnd;neuronId++)
	{
		Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
		if(neuron->getDendrites()->size()==0) {
			// add dendites by connecting to neurons referenced by our axons 

			std::vector<long> *axons = neuron->getAxons();
			long mainAxonId = (*axons)[0];
			Axon *thisAxon = globalObject->axonDB.getComponent(mainAxonId);
			std::vector<long> *synapses = thisAxon->getSynapses();
			if(synapses->size()>0)
			{
				long synapseId = (*synapses)[0];
				Synapse *thisSynapse = globalObject->synapseDB.getComponent(synapseId);

				long sourceNeuronId = thisSynapse->postSynapticNeuronId; //????
				Neuron *sourceNeuron = globalObject->neuronDB.getComponent(sourceNeuronId);
				neuron->connectFrom(sourceNeuron,thisSynapse->polarity);
			}
		}
	}

	unsigned long zeroDendriteCount = 0;
//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
//	for (itAxon.begin(); itAxon.more(); itAxon.next()) 
	long axonIdStart = globalObject->componentBase[ComponentTypeAxon];
	long axonIdEnd = globalObject->componentCounter[ComponentTypeAxon];

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon *axon = globalObject->axonDB.getComponent(axonId);
		long neuronId = axon->neuronId;
		Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
		if(neuron->getDendrites()->size()==0) {
			zeroDendriteCount++;
//			std::cout << "BrainDemoHWRecognition.create: Axon " << axon->id << " has no synapses." << std::endl;

		}
	}
	LOGSTREAM(ss) << formatNumber(zeroDendriteCount) << " neurons have no dendrites after fixup." << std::endl;
	globalObject->log(ss);

}

void BrainUnitTest::finalAxonAdjustments(std::stringstream &ss)
{
	LOGSTREAM(ss) << "Making final axon adjustments..." << std::endl;
	globalObject->log(ss);

	unsigned long zeroCount = 0;

	long axonIdStart = globalObject->componentBase[ComponentTypeAxon];
	long axonIdEnd = globalObject->componentCounter[ComponentTypeAxon];

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon* ax = globalObject->axonDB.getComponent(axonId);
		if (ax->getSynapses()->size() == 0)
		{
			zeroCount++;
//			std::cout << "BrainDemoHWRecognition.finalAdjustments: Axon " << ax->id << " has no synapses." << std::endl;
		}
	}

	LOGSTREAM(ss) << formatNumber(zeroCount) << " axons have no synapses before fixup." << std::endl;
	globalObject->log(ss);

	unsigned long added = 0;
	if (zeroCount > 0) {

		float pct = 0;
		float index = 1;
		//std::vector<unsigned long, unsigned long> newSynapses;
		//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
		//	for (itAxon.begin(); itAxon.more(); itAxon.next())
		size_t axonCount = globalObject->axonDB.size();

		for (globalObject->axonDB.begin(); globalObject->axonDB.more(); globalObject->axonDB.next())
		{
			Axon* ax = globalObject->axonDB.getValue();
			if (ax->getSynapses()->size() == 0)
			{
				// An axon with zero synapses found. Create a synapse for this guy to somewhere... anywhere
	//////////////////////////
				long neuronId = ax->neuronId;
				Neuron* neu = globalObject->neuronDB.getComponent(neuronId);				// we have the neuron in question
				long parentClusterId = neu->parentId;
				Cluster* cl = globalObject->clusterDB.getComponent(parentClusterId);			// we have the cluster that this neuron belongs to
				size_t cSize = cl->getNeurons().size();
				for (size_t i = 0; i < cSize; i++)										// Loop through each neuron in this cluster
				{
					long nId = cl->getNeurons()[i];
					if (nId > 0)
					{
						if (nId != neuronId)										// Ignore if we're looking at our own neuron
						{	// Valud neuronId and not equal to current one
							Neuron* neuX = globalObject->neuronDB.getComponent(nId);			// Get the neuron we want to attach to....
							if (neuX != NULL)												// Make sure it's valid
							{
								added++;
								Dendrite* den = Dendrite::create(neuX,neu,-1.0);		 		// Create a new inhibitory dendrite 
                                neuX->dendriteMap.insert(std::make_pair(neu->id, den->id));
								Synapse* s = Synapse::create(den,-1.0);					// Add a synapse to the dendrite -- inhibitory 
								long sid = s->id;
								ax->insertSynapse(sid);								// Attatch this new synapse to our axon
							}
							else
							{
								LOGSTREAM(ss) << "Neuron id " << formatNumber(nId) << " in cluster  " << formatNumber(parentClusterId) << " not found" << std::endl;
								globalObject->log(ss);
							}
						}
					}
					else
					{
						LOGSTREAM(ss) << "Zero neuronId found in cluster  " << formatNumber(parentClusterId) << " not found" << std::endl;
						globalObject->log(ss);
					}
				}
				//////////////////////////
			}
			pct = index / axonCount;
			printf("Pct Complete %f\r", pct * 100.0f);

			index++;
		}
	}

	// Wrap up...

	LOGSTREAM(ss) << formatNumber(added) << " synapses added." << std::endl;
	globalObject->log(ss);


	zeroCount = 0;

	for (long axonId = axonIdStart; axonId < axonIdEnd; axonId++)
	{
		Axon* ax = globalObject->axonDB.getComponent(axonId);
		if (ax->getSynapses()->size() == 0)
		{
			zeroCount++;
			std::cout << "BrainDemoHWRecognition.wrapip: Axon " << ax->id << " has no synapses." << std::endl;
		}
	}

	LOGSTREAM(ss) << formatNumber(zeroCount) << " axons have no synapses after fixup." << std::endl;
	globalObject->log(ss);


	LOGSTREAM(ss) << "Final axon adjustments complete..." << std::endl;
	globalObject->log(ss);

}



void BrainUnitTest::step(Brain *brain)
{
	(void)brain;
//	std::cout << "Current timestamp " << globalObject->getCurrentTimestamp() << " Current AP count " << globalObject->actionPotentialsSize() << std::endl;


	std::stringstream ss;
/****
	if(globalObject->actionPotentialsSize()>0) {
		LOGSTREAM(ss) << "Current timestamp " << globalObject->getCurrentTimestamp() << " Current AP count " << globalObject->actionPotentialsSize() << std::endl;
		globalObject->log(ss);
	}
****/

}

std::string BrainUnitTest::formatNumber(unsigned long long number) {
	std::stringstream ss;
	ss.imbue(std::locale(""));
	ss << std::fixed << number;
	return ss.str();

}

// This kludge is to sprinkle synapses among the clusters within nucleus, and within the neurons within clusters
void BrainUnitTest::insertSynapses(Nucleus* nuc) {
	for (size_t i = 0; i < nuc->columns.size(); i++) {
		long colId = nuc->columns[i];
		Column* col = globalObject->columnDB.getComponent(colId);
		for (size_t j = 0; j < col->layers.size(); j++) {
			long layerId = col->layers[j];
			Layer *lay = globalObject->layerDB.getComponent(layerId);
			// If inputlayer, polarity is inhibitory, otherwise excitatory
			float polarity = EXCITATORY_SYNAPSE;
			if(j==(size_t)col->inputLayer)
				polarity = EXCITATORY_SYNAPSE;

			for (size_t k = 0; k < lay->clusters.size(); k++) {
				long clusterId = lay->clusters[k];
				Cluster* clu = globalObject->clusterDB.getComponent(clusterId);
				for (size_t l = 0; l < clu->getNeurons().size(); l++) {
					long neuronId = clu->getNeurons()[l];
					Neuron* neu = globalObject->neuronDB.getComponent(neuronId);
					std::vector<long> *axons = neu->getAxons();
					for (size_t m = 0; m < axons->size(); m++) {
						//long axonId = (*axons)[m];
						//Axon* axon = globalObject->axonDB.getComponent(axonId);
						// We know have the axon which we will be attaching synapses to
						// This is a place holder for a more sophisticated algorythm to assign synapses. Perhaps future models with 3D information loaded in (SpatialDetails)
						// can place synapses where axons and dendrites come in close proximity
						//
						// But for now, let's just do random
						//
						// Iterate over neurons in this cluster and associate X% of them, selected at random, with the dendrites of other neurons
						// 
						//int percent = 100; // start with 98%
						//
						//boost::random::mt19937 gen;

						for (size_t ll = 0; ll < clu->getNeurons().size(); ll++) {
							unsigned long neuronId2 = clu->getNeurons()[ll];
							if (neuronId2 != neu->id) { // If not ourself
								Neuron* neu2 = globalObject->neuronDB.getComponent(neuronId2);
								//boost::random::uniform_int_distribution<> dist(0, 100);
								//int value = dist(percent);
								//if (value <= percent) 
								//{
									if(!neu->isConnectedTo(neu2)) 
									{
										neu->connectTo(neu2,polarity);
									}
								//}
							}

						}

					}

				}
			}
		}
	}
}

// This kludge is to sprinkle synapses between nucleus's A and B
void BrainUnitTest::insertSynapses(Nucleus* nucA, Nucleus* nucB) {
	// null for now
	(void)nucA;
	(void)nucB;
}


Brain* BrainUnitTest::createFromJSON(void) 
{
	Brain* brain;

	std::stringstream ss;

	LOGSTREAM(ss) << " Loading brain from JSON" << std::endl;
	globalObject->log(ss);
	brain = Brain::loadFromJSON("../../../database/","BrainUnitTest");
	return brain;
}

int BrainUnitTest_main(int argc, char *argv[])
{
	SNNEngine *engine = new SNNEngine();
	engine->initialize("../../../database/","BrainUnitTest");
	engine->startEngine();

}



// ============== BrainUnitTest.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

class BrainUnitTest
{
public:
	BrainUnitTest(void);
	~BrainUnitTest(void);
	static Brain *create(bool rebuild=true);
	static Brain* createFromJSON(void);
	static void step(Brain *brain);
	static std::string formatNumber(unsigned long long number);
	static void insertSynapses(Nucleus *nuc);
	static void insertSynapses(Nucleus* nucA, Nucleus* nucB);
	static void finalDendriteAdjustments(std::stringstream &ss);
	static void finalAxonAdjustments(std::stringstream &ss);
	static void experiments(Nucleus *nucleus);
};


// ============== CachedComponent.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#define ALWAYS_SAVE 1

template <class a_Type> class CachedComponent
{
public:
	CachedComponent(a_Type *component, unsigned long referenceTimestamp)
	{
		this->component = component;
		this->referenceTimestamp = referenceTimestamp;
	}

	virtual ~CachedComponent(void) { }

	a_Type *component;
	unsigned long referenceTimestamp;
};


// ============== Cluster.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Cluster.h"
#include "TR1Random.h"
#include "Global.h"

Cluster::Cluster(unsigned long parentId):
	NNComponent(ComponentTypeCluster)
{
	this->parentId = parentId;

}

Cluster::~Cluster(void)
{
}

void Cluster::toJSON(std::ofstream& outstream)
{
	std::stringstream ss;
	LOGSTREAM(ss) << "Exporting cluster..." << std::endl;
	globalObject->log(ss);

	std::string sep("");
	outstream << "                    { \"_type\": \"Cluster\", \"id\": " << id << ", \"location\": [" << location.x << ", " << location.y << ", " << location.z << "], \"size\": [" << area.h << ", " << area.w << ", " << area.d << "], \"neurons\": [ " << std::endl;
	for (unsigned int i = 0; i < neurons.size(); i++)
	{
		outstream << sep;
		sep = ",";
		Neuron* n = globalObject->neuronDB.getComponent(neurons[i]);
		n->toJSON(outstream);
	}
	outstream << "                    ] } " << std::endl;

}


void Cluster::save(void)
{
	globalObject->clusterDB.save(this);
}

void Cluster::commit(void)
{
	globalObject->clusterDB.addToCache(this);
}


Cluster *Cluster::create(SpatialDetails details, unsigned long parentId)
{
	Cluster *c = new Cluster(parentId);
	c->id = globalObject->nextComponent(ComponentTypeCluster);

	c->location = details.location;
	c->area = details.area;

	globalObject->insert(c);
	return c;
}


void Cluster::receiveInputFrom(Cluster *cluster, float sparsity, float polarity)
{
	Cluster *clusterA = this;
	Cluster *clusterB = cluster;

	size_t aSize = clusterA->neurons.size();
	size_t bSize = clusterB->neurons.size();

	size_t aCount = (size_t)((sparsity * (float)aSize)/100.f);
	size_t bCount = (size_t)((sparsity * (float)bSize)/100.f);


	for(size_t i=0;i<aCount;i++)
	{
		Neuron *neuronA = globalObject->neuronDB.getComponent(clusterA->neurons[i]);
		for(size_t j=0;j<bCount;j++)
		{
			Neuron *neuronB = globalObject->neuronDB.getComponent(clusterB->neurons[j]);
			neuronA->receiveInputFrom(neuronB,polarity);
		}
	}
}

long Cluster::getStartNeuron(void)
{
	size_t nSize = neurons.size();
	if(nSize==0)
		return 0;

	return neurons[0];
}

long Cluster::getEndNeuron(void)
{
	size_t nSize = neurons.size();
	if(nSize==0)
		return 0;

	return neurons[nSize-1];
}

void Cluster::initializeRandom(void)
{
	
	size_t rnd = (size_t) tr1random->generate(1,10); // Random # of Neurons
	for(size_t i=0;i<rnd;i++) 
	{
		SpatialDetails sd(this->location, this->area);
		sd.randomizeLocation();

		Neuron *n = Neuron::create(sd,Pyramidal,this->id,0);
		n->initializeRandom();
		neurons.push_back(n->id);
	}
	
}

Cluster *Cluster::instantiate(long key, size_t len, void *data)
{
	(void)len;
	long neuronCount = 0;
	long nid = 0;

	Cluster *cluster = new Cluster(0);
	cluster->id = key;

	char *ptr = (char*)data;

	memcpy(&cluster->parentId, ptr, sizeof(cluster->parentId));	ptr += sizeof(cluster->parentId);		
	memcpy(&cluster->location.x, ptr, sizeof(location.x)); 	ptr += sizeof(location.x);
	memcpy(&cluster->location.y, ptr, sizeof(location.y)); 	ptr += sizeof(location.y);
	memcpy(&cluster->location.z, ptr, sizeof(location.z)); 	ptr += sizeof(location.z);
	memcpy(&cluster->area.h, ptr, sizeof(area.h)); 			ptr += sizeof(area.h);
	memcpy(&cluster->area.w, ptr, sizeof(area.w)); 			ptr += sizeof(area.w);
	memcpy(&cluster->area.d, ptr, sizeof(area.d)); 			ptr += sizeof(area.d);
	memcpy(&neuronCount,ptr,sizeof(neuronCount));				ptr+=sizeof(neuronCount);

	for(size_t i=0;i<(size_t)neuronCount;i++)
	{
		memcpy(&nid,ptr,sizeof(nid));
		cluster->getNeurons().push_back(nid);
		ptr+=sizeof(nid);
	}
	return cluster;
}

Tuple *Cluster::getImage(void)
{
	long neuronCount = neurons.size();
	size_t size = sizeof(parentId)+ sizeof(location.x)+ sizeof(location.y) + sizeof(location.z) + sizeof(area.h) + sizeof(area.w) + sizeof(area.d) + sizeof(neuronCount) +(neuronCount *sizeof(long));

	char *image = globalObject->allocClearedMemory(size);
	char *ptr = (char*)image;

	memcpy(ptr, &parentId, sizeof(parentId)); 	ptr += sizeof(parentId);
	memcpy(ptr, &location.x, sizeof(location.x)); 	ptr += sizeof(location.x);
	memcpy(ptr, &location.y, sizeof(location.y)); 	ptr += sizeof(location.y);
	memcpy(ptr, &location.z, sizeof(location.z)); 	ptr += sizeof(location.z);
	memcpy(ptr, &area.h, sizeof(area.h)); 	ptr += sizeof(area.h);
	memcpy(ptr, &area.w, sizeof(area.w)); 	ptr += sizeof(area.w);
	memcpy(ptr, &area.d, sizeof(area.d)); 	ptr += sizeof(area.d);
	memcpy(ptr,&neuronCount,sizeof(neuronCount)); 	ptr+=sizeof(neuronCount);

	for(size_t i=0;i<(size_t)neuronCount;i++)
	{
		long k = neurons[i];
		memcpy(ptr,&k,sizeof(k));
		ptr+=sizeof(k);
	}

	Tuple* tuple = new Tuple();
	tuple->objectPtr = image;
	tuple->value = size;

	return tuple;

}



// ============== Cluster.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include "NNComponent.h"
#include <vector>
#include "Neuron.h"


// polarity - defined here because for some reason it can't see it in Global.h
#define EXCITATORY_SYNAPSE 1.0f
#define INHIBITORY_SYNAPSE -1.0f


class Cluster: public NNComponent
{
    friend class boost::serialization::access;
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
	{
		ar & boost::serialization::base_object<NNComponent>(*this);

		for(unsigned int i=0;i<neurons.size();i++)
		{
			ar & neurons[i];
		}
	}

public:
	virtual ~Cluster(void);
	static Cluster *create(SpatialDetails details, unsigned long parentId);
	void initializeRandom(void);
	static Cluster *instantiate(long key, size_t len, void *data);
	Tuple *getImage(void);

	void receiveInputFrom(Cluster *cluster, float sparsity=100.f, float polarity=EXCITATORY_SYNAPSE);
	std::vector<long> &getNeurons() { return this->neurons; }

	void toJSON(std::ofstream& outstream);

	long getStartNeuron(void);
	long getEndNeuron(void);


	std::vector<long> neurons;

private:
	Cluster(unsigned long parentId);

	void save(void);
	void commit(void);


	Location3D location;
	Size3D area;

};


// ============== CollectionIterator.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <map>

template <class a_Type> class CollectionIterator
{ 
private:
	std::map<long,a_Type> *coll;
	typename std::map<long,a_Type>::iterator it;
public:
	CollectionIterator(std::map<long,a_Type> *collection)
	{
		coll = collection;
		it = coll->begin();
	};
	~CollectionIterator(void)
	{
	};
	void begin(void) 
	{
		it = coll->begin();
	}
	bool more(void)
	{
		return it!=coll->end();
	}
	void next(void)
	{
		it++;
	}
	long key(void)
	{
		return it->first;
	}
	a_Type value(void)
	{
		return it->second;
	}


};


// ============== Column.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Column.h"
#include "TR1Random.h"
#include "Global.h"

#define MIN(a, b) ((a) < (b) ? (a) : (b))

Column::Column(bool createLayers, unsigned long parentId):
	NNComponent(ComponentTypeColumn)
{
	if(createLayers)
	{
		size_t layerCount = 6;												// 6 layers
		for(size_t i=0;i<layerCount;i++) 
		{
			Layer *layer1 = Layer::create(parentId);
			layers.push_back(layer1->id);
		}
	}
}

Column::Column(bool createLayers, size_t layerCount, unsigned long parentId):
	NNComponent(ComponentTypeColumn)
{
	if(createLayers)
	{
		for(size_t i=0;i<layerCount;i++) 
		{
			Layer *layer1 = Layer::create(parentId);
			layers.push_back(layer1->id);
		}
	}
}

Column::~Column(void)
{
}

/*
	std::vector<long> layers;

	Location3D location;
	Size3D area;
*/

void Column::toJSON(std::ofstream& outstream)
{
	std::stringstream ss;
	LOGSTREAM(ss) << "Exporting column..." << std::endl;
	globalObject->log(ss);

	std::string sep("");
	outstream << "            { \"_type\": \"Column\", \"id\": " << id << ", \"location\": [" << location.x << ", " << location.y << ", " << location.z << "], \"size\": [" << area.h << ", " << area.w << ", " << area.d << "], \"layers\": [ " << std::endl;
	for (unsigned int i = 0; i < layers.size(); i++)
	{
		outstream << sep;
		sep = ",";
		Layer* l = globalObject->layerDB.getComponent(layers[i]);
		l->toJSON(outstream);
	}
	outstream << "           ] } " << std::endl;

}



void Column::save(void)
{
	globalObject->columnDB.save(this);
}

void Column::commit(void)
{
	globalObject->columnDB.addToCache(this);
}

/*
Column *Column::create(SpatialDetails details, unsigned long parentId)
{
	Column *c = new Column(true,parentId);
	c->id = globalObject->nextComponent(ComponentTypeColumn);

	c->location = details.location;
	c->area = details.area;


	globalObject->insert(c);
	// connect all layers
	Layer *layer1 = globalObject->layerDB.getComponent(c->layers[0]); 
	Layer *layer2 = globalObject->layerDB.getComponent(c->layers[1]);
	Layer *layer3 = globalObject->layerDB.getComponent(c->layers[2]);
	Layer *layer4 = globalObject->layerDB.getComponent(c->layers[3]);
	Layer *layer5 = globalObject->layerDB.getComponent(c->layers[4]);
	Layer *layer6 = globalObject->layerDB.getComponent(c->layers[5]);

	layer1->projectTo(layer2); //  connect layer 1 (input) to layer 2 and 3
	layer1->projectTo(layer3);

	layer2->projectTo(layer5);
	layer3->projectTo(layer5);

	layer4->projectTo(layer2); //  connect layer 4 to layer 2,3 and 5
	layer4->projectTo(layer3);
	layer4->projectTo(layer5);

	layer5->projectTo(layer5); //  connect layer 4 to layer 2 and 3
	layer5->projectTo(layer6);

	// layer 6 is output layer


	return c;
}
*/

Column *Column::create(SpatialDetails details, size_t layerCount, unsigned long parentId)
{
	Column *c = new Column(true,layerCount, parentId);
	c->id = globalObject->nextComponent(ComponentTypeColumn);

	c->location = details.location;
	c->area = details.area;


	globalObject->insert(c);

	switch(layerCount)
	{
		case 1:
		{
			c->inputLayer = 1;
			c->outputLayer = 1;
			break;
		}
		case 2:
		{
			Layer *layer1 = globalObject->layerDB.getComponent(c->layers[0]); 
			Layer *layer2 = globalObject->layerDB.getComponent(c->layers[1]);

			c->inputLayer = 1;
			c->outputLayer = 2;

			layer1->receiveInputFrom(layer2); //  connect layer 1 (input) to layer 2 and 3
			layer2->receiveInputFrom(layer1);


	
			break;
		}
		case 3:
		{
			Layer *layer1 = globalObject->layerDB.getComponent(c->layers[0]); 
			Layer *layer2 = globalObject->layerDB.getComponent(c->layers[1]);
			Layer *layer3 = globalObject->layerDB.getComponent(c->layers[2]);

			layer1->receiveInputFrom(layer2); //  connect layer 1 (input) to layer 2 and 3
			layer2->receiveInputFrom(layer1);
			layer2->receiveInputFrom(layer3);
			layer1->receiveInputFrom(layer3); 
			layer3->receiveInputFrom(layer2);

			c->inputLayer = 1;
			c->outputLayer = 3;
			break;
		}
		case 4:
		{
			Layer *layer1 = globalObject->layerDB.getComponent(c->layers[0]); 
			Layer *layer2 = globalObject->layerDB.getComponent(c->layers[1]);
			Layer *layer3 = globalObject->layerDB.getComponent(c->layers[2]);
			Layer *layer4 = globalObject->layerDB.getComponent(c->layers[3]);

			layer1->receiveInputFrom(layer2); //  connect layer 1 (input) to layer 2 and 3
			layer1->receiveInputFrom(layer3);

			layer3->receiveInputFrom(layer4);

			layer4->receiveInputFrom(layer2); //  connect layer 4 to layer 2,3 and 5
			layer4->receiveInputFrom(layer3);
			layer4->receiveInputFrom(layer1);

			c->inputLayer = 1;
			c->outputLayer = 4;
			break;
		}
		case 5:
		{
			Layer *layer1 = globalObject->layerDB.getComponent(c->layers[0]); 
			Layer *layer2 = globalObject->layerDB.getComponent(c->layers[1]);
			Layer *layer3 = globalObject->layerDB.getComponent(c->layers[2]);
			Layer *layer4 = globalObject->layerDB.getComponent(c->layers[3]);
			Layer *layer5 = globalObject->layerDB.getComponent(c->layers[4]);

			layer1->receiveInputFrom(layer2); //  connect layer 1 (input) to layer 2 and 3
			layer1->receiveInputFrom(layer3);

			layer2->receiveInputFrom(layer5);
			layer3->receiveInputFrom(layer5);

			layer4->receiveInputFrom(layer2); //  connect layer 4 to layer 2,3 and 5
			layer4->receiveInputFrom(layer3);
			layer4->receiveInputFrom(layer5);

			layer5->receiveInputFrom(layer1); //  connect layer 4 to layer 2 and 3
			layer5->receiveInputFrom(layer2);
			layer5->receiveInputFrom(layer3);
			layer5->receiveInputFrom(layer4);

			c->inputLayer = 1;
			c->outputLayer = 5;
			break;
		}
		case 6:
		{
			Layer *layer1 = globalObject->layerDB.getComponent(c->layers[0]); 
			Layer *layer2 = globalObject->layerDB.getComponent(c->layers[1]);
			Layer *layer3 = globalObject->layerDB.getComponent(c->layers[2]);
			Layer *layer4 = globalObject->layerDB.getComponent(c->layers[3]);
			Layer *layer5 = globalObject->layerDB.getComponent(c->layers[4]);
			Layer *layer6 = globalObject->layerDB.getComponent(c->layers[5]);

			layer1->receiveInputFrom(layer2); //  connect layer 1 (input) to layer 2 and 3
			layer1->receiveInputFrom(layer3);

			layer2->receiveInputFrom(layer5);
			layer3->receiveInputFrom(layer5);

			layer4->receiveInputFrom(layer2); //  connect layer 4 to layer 2,3 and 5
			layer4->receiveInputFrom(layer3);
			layer4->receiveInputFrom(layer5);

			layer5->receiveInputFrom(layer5); //  connect layer 4 to layer 2 and 3
			layer5->receiveInputFrom(layer6);

			c->inputLayer = 1;
			c->outputLayer = 6;
			break;
		}
	}


	return c;
}


long Column::getStartNeuron(void)
{
	size_t lSize = layers.size();
	if(lSize==0)
		return 0;

	long lId = layers[0];
	Layer *layer = globalObject->layerDB.getComponent(lId);
	return layer->getStartNeuron();
}

long Column::getEndNeuron(void)
{
	size_t lSize = layers.size();
	if(lSize==0)
		return 0;

	long lId = layers[lSize-1];
	Layer *layer = globalObject->layerDB.getComponent(lId);
	return layer->getEndNeuron();
}


/*
void Column::connectTo(Column *column)
{
	// Connect source layer1 (output) to targer layer4 (input)
	Layer *layerA = globalObject->layerDB.getComponent(layers[0]);
	Layer *layerB = globalObject->layerDB.getComponent(column->layers[3]);
	layerA->connectTo(layerB);
}
*/

void Column::receiveInputFrom(Column *targetColumn, float sparsity, float polarity)
{
	std::stringstream ss;
	// Connect source layer1 (output) to target layer4 (input)

	Column *sourceColumn = this;

	Layer *sourceLayer[6];
	Layer *targetLayer[6];
	for(int i=0;i<6;i++)
	{
		sourceLayer[i] = NULL;
		targetLayer[i] = NULL;
	}


	int sourceLayerCount = sourceColumn->layers.size();

	for(int i=0;i<sourceLayerCount;i++)
	{
		sourceLayer[i] = globalObject->layerDB.getComponent(sourceColumn->layers[i]); // layer 1;
	}

	int targetLayerCount = targetColumn->layers.size();

	for(int i=0;i<targetLayerCount;i++)
	{
		targetLayer[i] = globalObject->layerDB.getComponent(targetColumn->layers[i]); // layer 1;
	}

/*
	for(int i=0;i<sourceLayerCount;i++)
	{
		for(int j=0;j<targetLayerCount;j++)
		{
			LOGSTREAM(ss) << "  Projecting source layer " << i+1 << " to target layer " << j+1 << std::endl;
			globalObject->log(ss);
			sourceLayer[i]->projectTo(targetLayer[j],sparsity);

		}
	}
*/

	// source column should send it's output layer to the target column's input layer

	int input = targetColumn->inputLayer - 1;
	Layer *tLayer = targetLayer[input];

	int output = sourceColumn->outputLayer -1;
	Layer *sLayer = sourceLayer[output];

	LOGSTREAM(ss) << "       Neurons in column (" << this->id << ")  layer " << input << " receiving input from  column (" << targetColumn->id << ") target layer " << output << std::endl;
	globalObject->log(ss);
	sLayer->receiveInputFrom(tLayer,sparsity,polarity); // excitatory

//		LOGSTREAM(ss) << "      Projecting neurons target layer " << output << " to source layer " << input << std::endl;
//		globalObject->log(ss);
//		sLayer->projectTo(tLayer,sparsity,EXCITATORY); 
}

void Column::initializeRandom(unsigned long parentId)
{
	(void)parentId;	
}

Column *Column::instantiate(long key, size_t len, void *data)
{
	(void)len;
	Column *column = new Column(false,0);
	column->id = key;

	char *ptr = (char*)data;

	long layerCount = 0;
	memcpy(&layerCount,ptr,sizeof(layerCount)); 	ptr+=sizeof(layerCount);

	for(size_t i=0;i<(size_t)layerCount;i++)
	{
		long lid = 0;
		memcpy(&lid,ptr,sizeof(lid));
		column->layers.push_back(lid);
		ptr+=sizeof(lid);
	}
//	printf("instantiate: Column %i layersize %i\n",(int)column->id,(int)column->layers.size());
	column->inputLayer =1;
	column->outputLayer = column->layers.size();
	return column;
}

Tuple *Column::getImage(void)
{


	long layerCount = layers.size();
	size_t size = sizeof(layerCount) + (layerCount * sizeof(layerCount));

	char* image = globalObject->allocClearedMemory(size);
	char* ptr = (char*)image;

	memcpy(ptr,&layerCount,sizeof(layerCount)); ptr+=sizeof(layerCount);

	for(size_t i=0;i<(size_t)layerCount;i++)
	{
		long k = layers[i];
		memcpy(ptr,&k,sizeof(k));
		ptr+=sizeof(k);
	}

	Tuple* tuple = new Tuple();
	tuple->objectPtr = image;
	tuple->value = size;

	return tuple;
}



// ============== Column.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include "NNComponent.h"
#include <map>
#include "Layer.h"
#include "Location3D.h"
#include "Size3D.h"
#include "SpatialDetails.h"

// polarity - defined here because for some reason it can't see it in Global.h
#define EXCITATORY 1.0f
#define INHIBITORY -1.0f

class Column: public NNComponent
{
	Column(bool createLayers, unsigned long parentId);
	Column(bool createLayers, size_t layerCount, unsigned long parentId);
    friend class boost::serialization::access;
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
	{
		ar & boost::serialization::base_object<NNComponent>(*this);
		for(unsigned int i=0;i<layers.size();i++)
		{
			ar & layers[i];
		}
	}
public:
	virtual ~Column(void);
	static Column *create(SpatialDetails details, size_t layerCount, unsigned long parentId);
	void initializeRandom(unsigned long parentId);
	static Column *instantiate(long key, size_t len, void *data);
	Tuple *getImage(void);

	void receiveInputFrom(Column *column, float sparsity=100.0f, float polarity=EXCITATORY_SYNAPSE); 

	void toJSON(std::ofstream& outstream);

	long getStartNeuron(void);
	long getEndNeuron(void);



	std::vector<long> layers;

	Location3D location;
	Size3D area;

	int inputLayer = 1;
	int outputLayer = 6;

private:
	void save(void);
	void commit(void);


};


// ============== ColumnNeuronProfile.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "ColumnNeuronProfile.h"

ColumnNeuronProfile::ColumnNeuronProfile(void)
{
	for(unsigned int i=0;i<6;i++)
	{
		neuronMorphology.push_back(new NeuronMorphology(Pyramidal, 100, 10));
	}
}

ColumnNeuronProfile::~ColumnNeuronProfile(void)
{
	for(unsigned int i=0;i<6;i++)
	{
		delete neuronMorphology[i];
	}
}


// ============== ColumnNeuronProfile.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <vector>
#include "NeuronMorphology.h"

class ColumnNeuronProfile
{
public:
	ColumnNeuronProfile(void);
	~ColumnNeuronProfile(void);

	std::vector<NeuronMorphology *> neuronMorphology;
};


// ============== ComponentCollection.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <string>

#include <iostream> 
#include <stdlib.h> 
#include <memory.h> 
#include <fstream>

using namespace std;

#include "Global.h"

template <class a_Type> class ComponentCollection
{
public:
	ComponentCollection(std::string componentname, size_t cacheSize=1000)
	{
		cache = 0L;
		cursorPosition = 0;
		elementSize = sizeof(a_Type);
		this->cacheSize = cacheSize;
		this->componentname = componentname+".dat";
	};

	~ComponentCollection(void){};

	void begin(void)
	{
		cursorPosition = 0;
	};

	void next(void)
	{
		cursorPosition++;
	};

	void open(void)
	{
		begin();
		if(cache!=0L)
			delete cache;
		cache = new char[cacheSize * elementSize];
		cacheIndex = new unsigned long[cacheSize];
		unsigned long offset = 0;
		file.open(componentname.c_str(), ios::binary | ios::out | ios::in);
		for(size_t i=0;i<cacheSize;i++)
		{
			cacheIndex[i] = i;
			cacheTimestamp[i] = globalObject->getCurrentTimestamp();
//			file.seekp(offset,ios::beg);
			file.read(cache+(offset*elementSize), elementSize);
		}
//		file.close();
	};

	bool isInCache(long id)
	{
		return false;
	}

	void insert(a_Type *component)
	{
		long id = component->id;
		if(isInCache(id))
		{
//			long offset = id - globalObject->componentBase[a_type->componentType];
//			file.write(buff, elementSize); // sizeof can take a type
		} 
		else 
		{
		}

	};

	void format(size_t numberOfElements)
	{
		cout << "Formatting " << componentname << ", " << numberOfElements << " elements at " << elementSize << " bytes each. " << endl;
		char *buff = new char[elementSize];
		memset(buff,0,elementSize);
		file.open(componentname.c_str(), ios::binary | ios::out);
		for(size_t i=0;i<numberOfElements;i++)
		{
			file.write(buff, elementSize); // sizeof can take a type
		}
		file.close();
	};

	std::string componentname;
	size_t elementSize;
	size_t cacheSize;
	size_t cursorPosition;
	char *cache;
	unsigned long *cacheIndex;
	unsigned long *cacheTimestamp;
	fstream file;
};


// ============== ComponentDB.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <db_cxx.h>
#include <map>
#include <boost/multi_index_container.hpp>
#include <boost/multi_index/ordered_index.hpp>
#include <boost/multi_index/identity.hpp>
#include <boost/multi_index/member.hpp>
#include <string>
#include <typeinfo>

#include "GlobalBridge.h"
#include "CachedComponent.h"
#include "Neuron.h"
#include "Axon.h"
#include "Dendrite.h"
#include "Tuple.h"

extern char *ctypes[];

// 100 MB buffer for database
#define USER_BUFFER_SIZE 100000000 
#define LOGSTREAM(s) s.str(""); s.clear(); s 

extern long getGlobalTimestep();

using namespace boost::multi_index;

struct id{};
struct referenceTimestamp{};

template <class a_Type> class ComponentDB
{
	boost::mutex cache_mutex;
	boost::mutex db_mutex;
//	boost::mutex db_putmutex;

public:
	ComponentDB(const size_t cacheSize,std::string inDBPath, std::string inModelName)
   : db_(NULL, 0),               // Instantiate Db object
	maxCacheSize(cacheSize),
	cFlags_(DB_CREATE)          // If the database doesn't yet exist, allow it to be created.
	{
		for(size_t i=0;i<sizeof(cursorp);i++)
			cursorp[i] = NULL;
		componentCount = 0;
		reimage_count = 0;
		save_count = 0;
		cacheMiss_count = 0;

		try
		{
			// Redirect debugging information to std::cerr
			db_.set_error_stream(&std::cerr);
			db_.set_cachesize(0, 8 * 1024*1024,4); // Set cachesize to 8MB (4 caches of 2MB each - 8MB total)
			std::string typeidName(lastToken(typeid(a_Type).name()));
			std::string demoname(inModelName);

			std::string directoryPath(inDBPath +  inModelName);
			// Test for the presence of the directory and create it if not present. 

			// Check if the directory exists
    		if (access(directoryPath.c_str(), 0) == 0) {
        		struct stat status;
        		stat(directoryPath.c_str(), &status);
        		if (status.st_mode & S_IFDIR) {
            		//std::cout << "The directory " <<  directoryPath.c_str() << " exists." << std::endl;
        		} else {
            		std::cout << "The path " << directoryPath.c_str() << " is a file." << std::endl;
        		}
    		} else {
        		// Create the directory
        		if (mkdir(directoryPath.c_str(),0777) == 0) {
            		std::cout << "Directory " << directoryPath.c_str() << "created successfully." << std::endl;
        		} else {
            		std::cout << "Failed to create directory " <<  directoryPath.c_str() << std::endl;
        		}
    		}

			dbFileName_ = inDBPath +  inModelName + std::string("/") + demoname + std::string("_") + typeidName + std::string(".db"); 

			// Open the database
			db_.open(NULL, dbFileName_.c_str(), NULL, DB_BTREE, cFlags_, 0);
		}
		// DbException is not a subclass of std::exception, so we
		// need to catch them both.
		catch(DbException &e)
		{
			std::cerr << "Error opening database: " << dbFileName_ << "\n";
			std::cerr << e.what() << std::endl;
		}
		catch(std::exception &e)
		{
			std::cerr << "Error opening database: " << dbFileName_ << "\n";
			std::cerr << e.what() << std::endl;
		}

		buffer = GlobalBridge::allocClearedMemory(USER_BUFFER_SIZE);
		if(buffer==NULL)
		{
			std::cout << "Unable to allocate working buffer! Press <enter> to continue." << std::endl;
			std::string response;
			std::cin >> response;
		}

	}

	~ComponentDB(void) { GlobalBridge::freeMemory(buffer); close(); }

	inline Db &getDb() { return db_; }

	void insert(a_Type *component)
	{
		if (!GlobalBridge::componentKeyInRange(component->id))
		{
			std::cerr << "insert():Error item: " << std::hex << component->id << "(" << std::dec << component->id << ") not found in " << dbFileName_ << " for insert().\n";
			return;
		}

		componentCount++;
		addToCache(component);
		save(component);
	}

	size_t getCacheCount(unsigned long cId) {
// DSH: mutex relaxation - experimental and dangerous 
//		boost::mutex::scoped_lock  amx(cache_mutex);
		return cache.count(cId);
	}

	bool isInCache(unsigned long cId) {
// DSH: mutex relaxation - experimental and dangerous 
//		boost::mutex::scoped_lock  amx(cache_mutex);
		try {
			auto ptr = cache.find(cId);
			if(ptr != cache.end())
				return true;
			else
				return false;
		} catch(...)
		{
			return false;
		}
	}

	CachedComponent<a_Type>* getCacheComponent(unsigned long cId) {
// DSH: mutex relaxation - experimental and dangerous 
//		boost::mutex::scoped_lock  amx(cache_mutex);
		return cache[cId];;
	}

	void cacheInsert(std::pair<long, CachedComponent<a_Type>*> pair) {
		boost::mutex::scoped_lock  amx(cache_mutex);
		cache.insert(pair);
	}

	void loadCache(void)
	{
		std::string typeidName(lastToken(typeid(a_Type).name()));
		std::cerr << "Loading: " << typeidName << " ...." << std::endl;

		typeidName = "ComponentType" + typeidName;
		size_t index = GlobalBridge::getTypeIndex(typeidName);
		long base = GlobalBridge::getComponentBase(index);
		long end = GlobalBridge::getComponentCounter(index);

		for (long i = base; i < end; i++)
		{ 
			getComponent(i); // this should cause the object to load
		}
		std::cerr << (end - base) << " " << typeidName << " items loaded." << std::endl;
	}

	void addToCache(a_Type *component)
	{

		if (!GlobalBridge::componentKeyInRange(component->id))
		{
			std::cerr << "addToCache():Error item: " << std::hex << component->id << "(" << std::dec << component->id << ")  not found in " << dbFileName_ << " for addToCache().\n";
			return;
		}

		if (isInCache(component->id)) {
			CachedComponent<a_Type>* cc = cache[component->id];
			a_Type* comp = cc->component;
			if (comp == component) {
				cc->referenceTimestamp = getGlobalTimestep();
			}
			else {
				std::cout << "Duplicate cache item " << component->id << " attempted insert " << std::endl;
			}
			return;
		}

		CachedComponent<a_Type> *cc = new CachedComponent<a_Type>(component,getGlobalTimestep());

		std::pair<long, CachedComponent<a_Type>*> pair(component->id, cc);

		cacheInsert(pair);
/*
		size_t cSize = cache.size();
		while(cSize > maxCacheSize) 
		{
			//trimCache();
			removeFirstCache();
			cSize = cache.size();
		}
*/
	}

	void removeFirstCache(void)
	{
		boost::mutex::scoped_lock  amx(cache_mutex);
		typename std::map<long,CachedComponent<a_Type> *>::iterator itCache = cache.begin();
		CachedComponent<a_Type> *item = itCache->second;
		if (item != NULL) {
			if (item->component != NULL) {
				if (!item->component->isDirty() || ALWAYS_SAVE) {
					try {
						destroy(itCache->first);
					}
					catch (...) {}
				}
			}

		}

	}

	void trimCache(void)
	{
		boost::mutex::scoped_lock  amx(cache_mutex);
		// find oldest component, save if dirty, then remove from cache
		unsigned long oldestItem = 0;
		unsigned long oldestTimestamp = getGlobalTimestep();

		typename std::map<long,CachedComponent<a_Type> *>::iterator itCache;
		for (itCache = cache.begin(); itCache!=cache.end(); ++itCache)
		{
			CachedComponent<a_Type> *item = itCache->second;
			if(item->referenceTimestamp <= oldestTimestamp )
			{
				oldestTimestamp = item->referenceTimestamp;
				oldestItem = item->component->id;
			}
		}
		if(oldestItem!=0)
		{
//			destroy(oldestItem);
			destroyBulk(oldestTimestamp,100); // Bulk destroy 1000 at a time
		}

	}

	size_t getCacheMissCount() {
		return cacheMiss_count;
	}

	void destroyBulk(long timestamp, size_t count)
	{
		size_t delcount = 0;
		std::vector<long> removeIds;

		for (typename std::map<long,CachedComponent<a_Type> *>::iterator itCache = cache.begin(); itCache!=cache.end(); ++itCache)
		{
			CachedComponent<a_Type> *item = itCache->second;
			if(item->referenceTimestamp == timestamp ) 
			{
				removeIds.push_back(item->component->id);
//				destroy(item->component->id);
				delcount++;
				if(delcount >= count) 
					break;
			}
		}
		for(size_t i=0;i<removeIds.size();i++)
		{
			try {
				destroy(removeIds[i]);
			}
			catch (...) {}
		}

	}

	void destroy(long itemId)
	{
/*
		if(itemId==1000500000L) 
		{
			std::cout << "Synapse 1000500000 being destroyed" << std::endl;
		}
*/
		try {
			size_t c = cache.count(itemId);
			if (c == 0) {
				std::cout << "Unable to find item " << std::hex << itemId << " in cache vector for destroy()." << std::endl;
				return;
			}

			CachedComponent<a_Type>* cacheItem = cache[itemId];

			a_Type* thisComponent = cacheItem->component;
			if (thisComponent->isDirty() || ALWAYS_SAVE)
			{
				save(thisComponent);
			}


			eraseCache(itemId);
			delete cacheItem;
			delete thisComponent;
		}
		catch (...) 
		{
			std::cout << "Error destroying " << std::hex << itemId << " from cache for destroy()." << std::endl;

		}
	}

	void eraseCache(long itemId)
	{
		boost::mutex::scoped_lock  amx(cache_mutex);

		try {
			size_t c = cache.count(itemId);

			if (c > 0) {
				cache.erase(itemId);
			}
			else {
				std::cout << "Unable to find item " << std::hex << itemId << " in cache (eraseCache) " << std::endl;
			}
		}
		catch (...) {

		}
	}
/*
	int doDbPut(DbTxn *a,Dbt *b,Dbt *c,u_int32_t d) {
		boost::mutex::scoped_lock  amx(db_putmutex);
		return db_.put(a, b, c, d); // put a wrapper on the put to ensure it's single threaded
	}
*/
	void save(a_Type *component)
	{
//		boost::mutex::scoped_lock  amx(db_mutex);

		if (!GlobalBridge::componentKeyInRange(component->id))
		{
			std::cerr << "save():Error item: " << std::hex << component->id << "(" << std::dec << component->id << ") not found in " << dbFileName_ << " for save().\n";
			return;
		}

		try {

			save_count++;

			Tuple *tuple = component->getImage();


			Dbt ky, dat;

			long thiskey = component->id;

			char *dataPointer = tuple->objectPtr;
			u_int32_t dataLen = tuple->value;

			ky.set_data(&thiskey);
			ky.set_size(sizeof(long));
			ky.set_ulen(sizeof(long));
			ky.set_flags(DB_DBT_USERMEM);

			dat.set_data(dataPointer);
			dat.set_size(dataLen);
			dat.set_ulen(dataLen);
			dat.set_flags(DB_DBT_USERMEM);

			//Dbt mykey(&(component->id), sizeof(component->id)); // Assuming component->id is a long

			// Dbt data(tuple->objectPtr, tuple->value);

//			boost::mutex::scoped_lock  amx(db_putmutex);
			boost::mutex::scoped_lock  amx(db_mutex);

			int ret = db_.put((DbTxn *)NULL, &ky, &dat, 0); // put a wrapper on the put to ensure it's single threaded
			if (ret != 0) 
			{
     		   std::cerr << "ERROR: db_.put failed: " << db_strerror(ret) << std::endl;
        		// You can add more error handling logic here, such as throwing an exception
        		// or handling specific error codes differently
        		// throw std::runtime_error(db_strerror(ret));
    		}
			else 
			{
				component->setDirty(false);
			}
			GlobalBridge::freeMemory(dataPointer);
			delete tuple;
		} catch (DbException &ex) {
			std::cout << "DB Exception encountered: " << ex.what() << " !!! " << std::endl;
		}
	}

	size_t size(void)
	{
		return componentCount;
	}

	size_t cacheSize(void)
	{
		return cache.size();
	}

	size_t saves(void)
	{
		return save_count;
	}

	size_t reimages(void)
	{
		return reimage_count;
	}


	void begin(int cursorno=0)
	{
		if (cursorp[cursorno] != NULL) 
			(cursorp[cursorno])->close();
		db_.cursor(NULL, &cursorp[cursorno], 0);
		int ret = (cursorp[cursorno])->get(&keyValue[cursorno], &data[cursorno], DB_NEXT);
		if (ret == DB_NOTFOUND) 
			moreData[cursorno] = false;
		else
			moreData[cursorno] = true;
	}

	void end(int cursorno=0)
	{
		if (cursorp[cursorno] != NULL) 
			(cursorp[cursorno])->close();
		cursorp[cursorno] = NULL;
	}

	bool more(int cursorno=0)
	{
		return moreData[cursorno];
	}


	void next(int cursorno=0)
	{
		if (cursorp[cursorno] == NULL) 
			begin();
		int ret = (cursorp[cursorno])->get(&keyValue[cursorno], &data[cursorno], DB_NEXT);
		if (ret == DB_NOTFOUND) 
			moreData[cursorno] = false;
		else
			moreData[cursorno] = true;
	}

	a_Type *getValue(int cursorno=0)
	{
		//Dbt *thisdata = &data[cursorno];
		Dbt *thiskey = &keyValue[cursorno];

		long mykey;
		memcpy(&mykey,(char *)thiskey->get_data(),sizeof(long));

		return getComponent(mykey);
	}

	long key(int cursorno=0)
	{
		long *data = (long *)keyValue[cursorno].get_data();
		long keyVal = *data;
		return keyVal;
	}

	
	a_Type* getDBComponent(long key) {


		a_Type* object = NULL;

		if(!GlobalBridge::componentKeyInRange(key))
		{
			std::cerr << "getDBComponent(1):Error item: " << std::hex << key << "(" << std::dec << key << ") not found in " << dbFileName_ << " in getDBComponent()\n";
			return object;
		}

		Dbt ky, dat;

		long thiskey = key;

		ky.set_data(&thiskey);
		ky.set_size(sizeof(long));
		ky.set_ulen(sizeof(long));
		ky.set_flags(DB_DBT_USERMEM);

		dat.set_data(buffer);
		dat.set_size(USER_BUFFER_SIZE);
		dat.set_ulen(USER_BUFFER_SIZE);
		dat.set_flags(DB_DBT_USERMEM);


		boost::mutex::scoped_lock  amx(db_mutex);
		int ret = db_.get(NULL, &ky, &dat, 0);

		if (ret == DB_NOTFOUND)
		{
			//				printf("getComponent NOT found key %d in database\n",key);
			std::cerr << "getDBComponent(2):Error item: " << std::hex << key << "(" << std::dec << key << ") not found in " << dbFileName_ << "\n";
		}
		else
		{
			//				printf("getComponent found key %d in database\n",key);
			reimage_count++;
			u_int32_t len = dat.get_ulen();
			char *data = (char *)dat.get_data();
			object = a_Type::instantiate(key, len, data);
			object->setDirty(false);
			/*
							if(object->id==1001200000L)
							{
								Synapse *s = (Synapse *)object;
								std::cout << "Synapse 1001200000L found in database in ::getComponent and owneing process is " << s->getOwningProcessComponentId() << std::endl;
							}
			*/
		}
		return object;
	}

	a_Type* getDBComponentNolock(long key) {


		a_Type* object = NULL;

		if(!GlobalBridge::componentKeyInRange(key))
		{
			std::cerr << "getDBComponent(1):Error item: " << std::hex << key << "(" << std::dec << key << ") not found in " << dbFileName_ << " in getDBComponent()\n";
			return object;
		}

		if(key == 800000000)
		{
			std::cout << "here" << std::endl;
		}

		Dbt ky, dat;

		long thiskey = key;

		ky.set_data(&thiskey);
		ky.set_size(0);
		ky.set_ulen(sizeof(long));
		ky.set_flags(DB_DBT_USERMEM);

		dat.set_data(buffer);
		dat.set_size(0);
		dat.set_ulen(USER_BUFFER_SIZE);
		dat.set_flags(DB_DBT_USERMEM);


		// nolock boost::mutex::scoped_lock  amx(db_mutex);
		int ret = db_.get(NULL, &ky, &dat, 0);

		if (ret == DB_NOTFOUND)
		{
			//				printf("getComponent NOT found key %d in database\n",key);
			std::cerr << "getDBComponent(2):Error item: " << std::hex << key << "(" << std::dec << key << ") not found in " << dbFileName_ << "\n";
		}
		else
		{
			//				printf("getComponent found key %d in database\n",key);
			reimage_count++;
//			if (key == 800000256) {
//				int breakhere = 0;
//			}
			u_int32_t len = dat.get_ulen();
			char *data = dat.get_data();
			object = a_Type::instantiate(key, len, data);
			object->setDirty(false);
			/*
							if(object->id==1001200000L)
							{
								Synapse *s = (Synapse *)object;
								std::cout << "Synapse 1001200000L found in database in ::getComponent and owneing process is " << s->getOwningProcessComponentId() << std::endl;
							}
			*/
		}
		return object;
	}


	a_Type* getComponent(long key)
	{
		a_Type* object = NULL;

		if (!GlobalBridge::componentKeyInRange(key))
		{
			std::cerr << "getComponent():Error item: " << std::hex << key << "(" << std::dec << key << ") not found in " << dbFileName_ << " or cache.\n";
			return object;
		}


		if (isInCache(key)) {
			CachedComponent<a_Type>* cc = getCacheComponent(key); //cache[key];
			cc->referenceTimestamp = getGlobalTimestep();
			object = cc->component;
		}
		else 
		{
			cacheMiss_count++;

			object = getDBComponent(key);
			if(object != NULL) {
				addToCache(object);
			}
		}

		return object;
	}

	void flush(void)
	{
		std::stringstream ss;
		

		// Flush any dirty objects in cache
//		for (typename std::map<long,CachedComponent<a_Type> *>::iterator itCache = cache.begin(); itCache != cache.end(); ++itCache)
//		{
		for (const auto& pair : cache) {
			//long itemId = pair.first;
			CachedComponent<a_Type> *item = pair.second;
			if(item->component->isDirty())
			{
				save(item->component);
			}
		}

		db_.sync(0);

	}

	void flushAll(void)
	{
		// Flush any dirty objects in cache
		std::stringstream ss;
		LOGSTREAM(ss) << "Flushall for  " << dbFileName_ << " beginning..." << std::endl;
		GlobalBridge::log(ss);

		size_t sz = cache.size();
		size_t ix = 0;
		size_t lastPct = 1000;

		long itemId = 0;

//		for (typename std::map<long, CachedComponent<a_Type>*>::iterator itCache = cache.begin(); itCache != cache.end(); ++itCache)
//		{
		for (const auto& pair : cache) {
			itemId = pair.first;
			CachedComponent<a_Type>* item = pair.second;
			save(item->component);
			ix++;
			size_t pct = (ix*100) / sz;
			if (pct != lastPct) {
				lastPct = pct;
				printf("    %d %% complete...\r", (int)pct);
			}
		}

		db_.sync(0);

		LOGSTREAM(ss) << "Flushall():Last item of flush:  " << itemId  << std::endl;
		GlobalBridge::log(ss);

		LOGSTREAM(ss) << "Flushall for  " << dbFileName_ << " Complete." << std::endl;
		GlobalBridge::log(ss);
	}

	void shutdown(void)
	{
		std::stringstream ss;
		long itemId = 0;
		std::vector<long> removeIds;

//		for (typename std::map<long,CachedComponent<a_Type> *>::iterator itCache = cache.begin(); itCache != cache.end(); ++itCache)
//		{
		for (const auto& pair : cache) {
    		itemId = pair.first;
			removeIds.push_back(itemId);
			CachedComponent<a_Type> *item = pair.second;
			if(item->component->isDirty())
			{
				save(item->component);
			}
			a_Type *object = item->component;
			delete item;
			delete object;
		}
//		for(size_t i=0;i<removeIds.size();i++)
//		{
//			eraseCache(removeIds[i]);
//		}
		std::string typeidName(lastToken(typeid(a_Type).name()));
		LOGSTREAM(ss) << "shutdown(): Last " << typeidName << " item in cache to flush:  " << itemId << std::endl;
		GlobalBridge::log(ss);

	}

	void close()
	{
		// Close the db
		try
		{
			db_.close(0);
			std::cout << "Database " << dbFileName_
				      << " is closed." << std::endl;
		}
		catch(DbException &e)
		{
			std::cerr << "Error closing database: " << dbFileName_ << "\n";
			std::cerr << e.what() << std::endl;
		}
		catch(std::exception &e)
		{
			std::cerr << "Error closing database: " << dbFileName_ << "\n";
			std::cerr << e.what() << std::endl;
		}
	} 

	char *lastToken(const char *in) 
	{
		char *ptr = (char *) (in + strlen(in));
		while (ptr > in && *ptr != ' ')
			ptr--;
		if (*ptr == ' ') 
			ptr++;
		return ++ptr;
	}

	size_t componentCount;

private:

    Db db_;
    std::string dbFileName_;
    u_int32_t cFlags_;
	Dbc *cursorp[10];
	bool moreData[10];
    Dbt keyValue[10], data[10];
	std::map<long,CachedComponent<a_Type> *> cache;
/*
	typedef multi_index_container<
		CachedComponent<a_Type> *,
		indexed_by<
		ordered_unique<tag<id>, BOOST_MULTI_INDEX_MEMBER(CachedComponent<a_Type> *, unsigned long, CachedComponent<a_Type>::id)>,
			ordered_non_unique<tag<referenceTimestamp>, BOOST_MULTI_INDEX_MEMBER(CachedComponent<a_Type> *, unsigned long, CachedComponent<a_Type>::referenceTimestamp)>
				>
		> cache;
*/
	size_t maxCacheSize;
	char *buffer;
    // We put our database close activity here.
    // This is called from our destructor. In
    // a more complicated example, we might want
    // to make this method public, but a private
    // method is more appropriate for this example.
//    void close();
	size_t reimage_count;
	size_t save_count;
	size_t cacheMiss_count;

};


// ============== Dendrite.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Dendrite.h"
#include "Global.h"
#include "Neuron.h"
#include "Synapse.h"
#include "Axon.h"
#include "TimedEvent.h"
#include <cmath>

Dendrite::Dendrite(Neuron *neuron, long newId, float polarity):
    Process(ComponentTypeDendrite)
{
    setPreSynapticNeuronId(neuron->id);
    setRate(DEFAULT_DENDRITE_RATE,false);
    setDistance(DEFAULT_DENDRITE_DISTANCE);

    Synapse *s = Synapse::create(this,polarity);
    this->synapseId = s->id;
    s->setOwningDendriteId(newId);
    s->setPosition(this->getDistance());
    neuron->setDirty();
}

Dendrite::~Dendrite(void)
{
}

void Dendrite::toJSON(std::ofstream& outstream)
{
    outstream << "                            { \"_type\": \"Dendrite\", \"id\": " << id << ", \"synapseId\": " << synapseId << " } " << std::endl;
}

void Dendrite::save(void)
{
    globalObject->dendriteDB.save(this);
}

void Dendrite::commit(void)
{
    globalObject->dendriteDB.addToCache(this);
}

float computeDistance(float x1, float y1, float z1, float x2, float y2, float z2) {
    return std::sqrt(std::pow(x2 - x1, 2) + std::pow(y2 - y1, 2) + std::pow(z2 - z1, 2));
}

Dendrite *Dendrite::create(Neuron *postSynapticNeuron, Neuron *preSynapticNeuron, float polarity)
{
    long newId = globalObject->nextComponent(ComponentTypeDendrite);
    Dendrite *d = new Dendrite(preSynapticNeuron, newId,polarity);
    d->id = newId;
    d->setPostSynapticNeuronId(postSynapticNeuron->id);
    d->setPreSynapticNeuronId(preSynapticNeuron->id);

    long synapseId = d->synapseId;
    Synapse *synapse = globalObject->synapseDB.getComponent(synapseId);
    float calculatedDistance = computeDistance(preSynapticNeuron->location.x,preSynapticNeuron->location.y,preSynapticNeuron->location.z,
                                               postSynapticNeuron->location.x,postSynapticNeuron->location.y,postSynapticNeuron->location.z);
    synapse->setPosition(calculatedDistance);

    globalObject->insert(d);
    postSynapticNeuron->getDendrites()->push_back(d->id);

    return d;
}

void Dendrite::fire(void)
{
    float lclDistance = getDistance();
    float lclRate = getRate();

    Synapse *s = globalObject->synapseDB.getComponent(this->synapseId);
    long offset = ActionPotential::computeOffset(lclDistance, lclRate);
    if(offset > 0)
    {
        // Here if we wanted to do something else, we could. Currently, offset scheduling is done via Axon firing events.
        // The dendrite itself might not need to directly schedule events; Axon and Synapse handle that.
        // This fire method is currently unused or can be left as-is.
    }
}

Dendrite::Dendrite(void): 
    Process(ComponentTypeDendrite)
{
    setRate(DEFAULT_DENDRITE_RATE);
    setDistance(10.0);
}

Tuple *Dendrite::getImage(void)
{
    float lclDistance = getDistance();
    float lclRate = getRate();

    size_t size = sizeof(parentId) + sizeof(lclDistance) + sizeof(lclRate) + sizeof(postSynapticNeuronId) + sizeof(preSynapticNeuronId) + sizeof(synapseId);

    char *image = globalObject->allocClearedMemory(size);
    char *ptr = (char*)image;

    memcpy(ptr, &parentId, sizeof(parentId));       ptr += sizeof(parentId);
    memcpy(ptr,&lclDistance,sizeof(lclDistance));   ptr+=sizeof(lclDistance);
    memcpy(ptr,&lclRate,sizeof(lclRate));           ptr+=sizeof(lclRate);
    memcpy(ptr,&postSynapticNeuronId,sizeof(postSynapticNeuronId));  ptr+=sizeof(postSynapticNeuronId);
    memcpy(ptr,&preSynapticNeuronId,sizeof(preSynapticNeuronId));    ptr+=sizeof(preSynapticNeuronId);
    memcpy(ptr,&synapseId,sizeof(synapseId));       ptr+=sizeof(synapseId);

    Tuple* tuple = new Tuple();
    tuple->objectPtr = image;
    tuple->value = size;

    return tuple;
}

Dendrite *Dendrite::instantiate(long key, size_t len, void *data)
{
    (void)len;
    Dendrite *dendrite = new Dendrite();
    dendrite->id = key;

    char *ptr = (char*)data;

    float lclDistance = 0;
    float lclRate = 0;

    memcpy(&dendrite->parentId, ptr, sizeof(dendrite->parentId));    ptr += sizeof(dendrite->parentId); 
    memcpy(&lclDistance, ptr, sizeof(lclDistance));                  ptr += sizeof(lclDistance); dendrite->setDistance(lclDistance);
    memcpy(&lclRate, ptr, sizeof(lclRate));                          ptr += sizeof(lclRate); dendrite->setRate(lclRate);
    memcpy(&dendrite->postSynapticNeuronId,ptr,sizeof(dendrite->postSynapticNeuronId)); ptr+=sizeof(dendrite->postSynapticNeuronId);  
    memcpy(&dendrite->preSynapticNeuronId,ptr,sizeof(dendrite->preSynapticNeuronId));   ptr+=sizeof(dendrite->preSynapticNeuronId);  
    memcpy(&dendrite->synapseId,ptr,sizeof(dendrite->synapseId));    ptr+=sizeof(dendrite->synapseId); 

    return dendrite;
}


// ============== Dendrite.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <map>
#include "Process.h"
#include "ActionPotential.h"

class Synapse;
class Neuron;

class Dendrite: public Process
{
    Dendrite(void);
    Dendrite(Neuron *neuron, long newId,float polarity);

    friend class boost::serialization::access;
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
    {
        ar & boost::serialization::base_object<NNComponent>(*this);
        ar & preSynapticNeuronId;
        ar & synapseId;
    }

public:
    virtual ~Dendrite(void);
    static Dendrite *create(Neuron *postSynapticNeuron,Neuron *preSynapticNeuron, float polarity);
    void fire(void);
    Tuple *getImage(void);
    static Dendrite *instantiate(long key, size_t len, void *data);

    inline bool isSameNeuron(long nid) { return preSynapticNeuronId == nid; };
    inline void setPreSynapticNeuronId(long nId) { this->preSynapticNeuronId = nId; };
    inline long getPreSynapticNeuronId(void) { return this->preSynapticNeuronId; };
    inline void setPostSynapticNeuronId(long nId) { this->postSynapticNeuronId = nId; };
    inline long getPostSynapticNeuronId(void) { return this->postSynapticNeuronId; };
    inline long getSynapseId(void) { return synapseId; };
    void toJSON(std::ofstream& outstream);

private:
    void save(void);
    void commit(void);

    long preSynapticNeuronId;
    long postSynapticNeuronId;
    long synapseId;
};


// ============== DetailTest.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Global.h"
#include "TR1Random.h"
#include "DetailTest.h"
#include "SNNEngine.h"

#include <boost/random/mersenne_twister.hpp>
#include <boost/random/uniform_int_distribution.hpp>


DetailTest::DetailTest(void)
{
}

DetailTest::~DetailTest(void)
{
}

Brain * DetailTest::create(bool rebuild) 
{

	Brain *brain; 

	std::stringstream ss;

	if(!rebuild) // if not rebuilding, just return brain
	{
		LOGSTREAM(ss) << " Loading brain" << std::endl;
		globalObject->log(ss);
		brain = Brain::load("../../../database/","DetailTest");
	} 
	else 
	{
		LOGSTREAM(ss) << " Creating brain" << std::endl;
		globalObject->log(ss);
		brain = Brain::create(true,"../../../database/","DetailTest");
	}

	SpatialDetails sd(2500, 2500, 2500, 5000, 5000, 5000); // Dummy test locations/size


	// Create Thalamus
	LOGSTREAM(ss) << "Create Micro Thalamus ... " << std::endl;
	globalObject->log(ss);

	Region *regionThalamus = 0L;
	if(brain->restartpoint())
	{
		regionThalamus = Region::create("regionThalamus", sd);
		brain->add(regionThalamus);
	} 
	else 
	{
		globalObject->regionDB.next();
		regionThalamus = globalObject->regionDB.getValue();
		LOGSTREAM(ss) << "regionThalamus globalObject->regionDB.getValue() " << std::endl;
		globalObject->log(ss);
	}
	brain->syncpoint();


	// Create Thalamic Nuclei
	ColumnNeuronProfile profile; // default profile for all layers is Pyramidal neurons, 100 neurons per cluster, with 10 clusters

	Nucleus *regionDigits = 0L;
	if(brain->restartpoint())
	{
		regionDigits = Nucleus::create("regionDigits", sd);
		regionDigits->nucleusType = SENSORY_NUCLEUS;
		regionThalamus->add(regionDigits);
//		regionDigits->addColumns(10,profile); // 10 columns, each with 6 layers, each with 5 clusters, each with 10 neurons
		regionDigits->addColumns(1,6,1,10); // 1 column, each with 6 layers, each with 1 clusters, each with 10 neurons
	} 
	else 
	{
		globalObject->nucleusDB.next();
		regionDigits = globalObject->nucleusDB.getValue();
	}
	brain->syncpoint();

	LOGSTREAM(ss) << "Region " << regionThalamus->name << " complete with " << regionThalamus->nuclei.size() << " nuclei." << std::endl;
	globalObject->log(ss);

	
	// Wrap up construction


	LOGSTREAM(ss) << " Attaching layers within columns " << std::endl;
	globalObject->log(ss);
	// Now, attach layers within a column
//	CollectionIterator<Column *> itColumn(Global::getColumnsCollection());

	size_t columnCount = globalObject->columnsSize();
	size_t columnNum = 0;

	for (globalObject->columnDB.begin(); globalObject->columnDB.more(); globalObject->columnDB.next())
	{
		Column *column = globalObject->columnDB.getValue();

		size_t pct = (columnNum*100) / columnCount;
//		std::cout << " Initializing layers within column " << column->id << std::endl;
		LOGSTREAM(ss) << " Initializing layers within column " << column->id << " - (" << columnNum++ << " of " << columnCount << " - " << pct << "%) " << std::endl;
		globalObject->log(ss);

		if(brain->restartpoint())
		{
		//	column->initializeLayers(0);
		}
		brain->syncpoint();
	}
	
	LOGSTREAM(ss) << "Connecting columns " << std::endl;
	globalObject->log(ss);
	for (globalObject->columnDB.begin(); globalObject->columnDB.more(); globalObject->columnDB.next())
	{
		Column *column1 = globalObject->columnDB.getValue();
		for (globalObject->columnDB.begin(1); globalObject->columnDB.more(1); globalObject->columnDB.next(1))
		{
			Column *column2 = globalObject->columnDB.getValue(1);
			if(column1 != column2) {
				column1->receiveInputFrom(column2);
				column2->receiveInputFrom(column1);
			}

		}
	}

	LOGSTREAM(ss) << std::endl << "... " << std::endl << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << formatNumber(globalObject->regionsSize()) << " regions created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->nucleiSize()) << " nuclei created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->columnsSize()) << " columns created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->layersSize()) << " layers created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->clustersSize()) << " clusters created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->neuronsSize()) << " neurons created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->axonsSize()) << " axons created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << std::endl << "... " << std::endl << std::endl;
	globalObject->log(ss);

	LOGSTREAM(ss) << "Attach regions" << std::endl;
	globalObject->log(ss);
// Finally, attach the Regions



	LOGSTREAM(ss) << "------------------------------------------------------" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->dendritesSize()) << " dendrites created" << std::endl;
	globalObject->log(ss);
	LOGSTREAM(ss) << formatNumber(globalObject->synapsesSize()) << " synapses created" << std::endl;
	globalObject->log(ss);

	unsigned long zeroCount = 0;
//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
//	for (itAxon.begin(); itAxon.more(); itAxon.next())
	for (globalObject->axonDB.begin(); globalObject->axonDB.more(); globalObject->axonDB.next())
	{
		if(globalObject->axonDB.getValue()->getSynapses()->size()==0) 
			zeroCount++;
	}
	LOGSTREAM(ss) << formatNumber(zeroCount) << " axons have no synapses." << std::endl;
	globalObject->log(ss);

	// Make final Adustments
	finalAdjustments(ss);


	LOGSTREAM(ss) << "SNNEngine ready to accept input..." << std::endl;
	globalObject->log(ss);


	globalObject->flush();
	return brain;
}

void DetailTest::finalAdjustments(std::stringstream &ss)
{
	LOGSTREAM(ss) << "Making final adjustments..." << std::endl;
	globalObject->log(ss);

	unsigned long zeroCount = 0;
	for (globalObject->axonDB.begin(); globalObject->axonDB.more(); globalObject->axonDB.next())
	{
		Axon* ax = globalObject->axonDB.getValue();
		if (ax->getSynapses()->size() == 0)
		{
			zeroCount++;
		}
	}

	LOGSTREAM(ss) << formatNumber(zeroCount) << " axons have no synapses before fixup." << std::endl;
	globalObject->log(ss);

	unsigned long added = 0;
	if (zeroCount > 0) {

		float pct = 0;
		float index = 1;
		//std::vector<unsigned long, unsigned long> newSynapses;
		//	CollectionIterator<Axon *> itAxon(Global::getAxonsCollection());
		//	for (itAxon.begin(); itAxon.more(); itAxon.next())
		size_t axonCount = globalObject->axonDB.size();

		for (globalObject->axonDB.begin(); globalObject->axonDB.more(); globalObject->axonDB.next())
		{
			Axon* ax = globalObject->axonDB.getValue();
			if (ax->getSynapses()->size() == 0)
			{
				// An axon with zero synapses found. Create a synapse for this guy to somewhere... anywhere
	//////////////////////////
				long neuronId = ax->neuronId;
				Neuron* neu = globalObject->neuronDB.getComponent(neuronId);				// we have the neuron in question
				long parentClusterId = neu->parentId;
				Cluster* cl = globalObject->clusterDB.getComponent(parentClusterId);			// we have the cluster that this neuron belongs to
				size_t cSize = cl->getNeurons().size();
				for (size_t i = 0; i < cSize; i++)										// Loop through each neuron in this cluster
				{
					long nId = cl->getNeurons()[i];
					if (nId > 0)
					{
						if (nId != neuronId)										// Ignore if we're looking at our own neuron
						{	// Valud neuronId and not equal to current one
							Neuron* neuX = globalObject->neuronDB.getComponent(nId);			// Get the neuron we want to attach to....
							if (neuX != NULL)												// Make sure it's valid
							{
								added++;
								Dendrite* den = Dendrite::create(neuX, neu,-1.0);				// Create a new dendrite
                                neuX->dendriteMap.insert(std::make_pair(neu->id, den->id));
								Synapse* s = Synapse::create(den,-1.0);					// Add a synapse to the dendrite
								long sid = s->id;
								ax->insertSynapse(sid);								// Attatch this new synapse to our axon
							}
							else
							{
								LOGSTREAM(ss) << "Neuron id " << formatNumber(nId) << " in cluster  " << formatNumber(parentClusterId) << " not found" << std::endl;
								globalObject->log(ss);
							}
						}
					}
					else
					{
						LOGSTREAM(ss) << "Zero neuronId found in cluster  " << formatNumber(parentClusterId) << " not found" << std::endl;
						globalObject->log(ss);
					}
				}
				//////////////////////////
			}
			pct = index / axonCount;
			printf("Pct Complete %f\r", pct * 100.0f);

			index++;
		}
	}

	// Wrap up...

	LOGSTREAM(ss) << formatNumber(added) << " synapses added." << std::endl;
	globalObject->log(ss);


	zeroCount = 0;
	for (globalObject->axonDB.begin(); globalObject->axonDB.more(); globalObject->axonDB.next())
	{
		Axon* ax = globalObject->axonDB.getValue();
		if (ax->getSynapses()->size() == 0)
		{
			zeroCount++;
		}
	}

	LOGSTREAM(ss) << formatNumber(zeroCount) << " axons have no synapses after fixup." << std::endl;
	globalObject->log(ss);


	LOGSTREAM(ss) << "Final adjustments complete..." << std::endl;
	globalObject->log(ss);

}



void DetailTest::step(Brain *brain)
{
	(void)brain;
//	std::cout << "Current timestamp " << globalObject->getCurrentTimestamp() << " Current AP count " << globalObject->actionPotentialsSize() << std::endl;


	std::stringstream ss;
/****
	if(globalObject->actionPotentialsSize()>0) {
		LOGSTREAM(ss) << "Current timestamp " << globalObject->getCurrentTimestamp() << " Current AP count " << globalObject->actionPotentialsSize() << std::endl;
		globalObject->log(ss);
	}
****/

}

std::string DetailTest::formatNumber(unsigned long long number) {
	std::stringstream ss;
	ss.imbue(std::locale(""));
	ss << std::fixed << number;
	return ss.str();

}

// This kludge is to sprinkle synapses among the clusters within nucleus, and within the neurons within clusters
void DetailTest::insertSynapses(Nucleus* nuc) {
	for (size_t i = 0; i < nuc->columns.size(); i++) {
		long colId = nuc->columns[i];
		Column* col = globalObject->columnDB.getComponent(colId);
		for (size_t j = 0; j < col->layers.size(); j++) {
			long layerId = col->layers[j];
			Layer *lay = globalObject->layerDB.getComponent(layerId);
			// If inputlayer, polarity is inhibitory, otherwise excitatory
			float polarity = EXCITATORY_SYNAPSE;
			if(j==(size_t)col->inputLayer)
				polarity = EXCITATORY_SYNAPSE;

			for (size_t k = 0; k < lay->clusters.size(); k++) {
				long clusterId = lay->clusters[k];
				Cluster* clu = globalObject->clusterDB.getComponent(clusterId);
				for (size_t l = 0; l < clu->getNeurons().size(); l++) {
					long neuronId = clu->getNeurons()[l];
					Neuron* neu = globalObject->neuronDB.getComponent(neuronId);
					std::vector<long> *axons = neu->getAxons();
					for (size_t m = 0; m < axons->size(); m++) {
						//long axonId = (*axons)[m];
						//Axon* axon = globalObject->axonDB.getComponent(axonId);
						// We know have the axon which we will be attaching synapses to
						// This is a place holder for a more sophisticated algorythm to assign synapses. Perhaps future models with 3D information loaded in (SpatialDetails)
						// can place synapses where axons and dendrites come in close proximity
						//
						// But for now, let's just do random
						//
						// Iterate over neurons in this cluster and associate X% of them, selected at random, with the dendrites of other neurons
						// 
						int percent = 95; // start with 98%
						//
						boost::random::mt19937 gen;

						for (size_t ll = 0; ll < clu->getNeurons().size(); ll++) {
							unsigned long neuronId2 = clu->getNeurons()[ll];
							if (neuronId2 != neu->id) { // If not ourself
								Neuron* neu2 = globalObject->neuronDB.getComponent(neuronId2);
								boost::random::uniform_int_distribution<> dist(0, 100);
								int value = dist(gen);
								if (value <= percent) 
								{
									if(!neu->isConnectedTo(neu2)) {
										neu->connectTo(neu2,polarity);
									}
								}
							}

						}

					}

				}
			}
		}
	}
}

// This kludge is to sprinkle synapses between nucleus's A and B
void DetailTest::insertSynapses(Nucleus* nucA, Nucleus* nucB) {
	(void)nucA;
	(void)nucB;
	// null for now
}


Brain* DetailTest::createFromJSON(void) 
{
	Brain* brain;

	std::stringstream ss;

	LOGSTREAM(ss) << " Loading brain from JSON" << std::endl;
	globalObject->log(ss);
	brain = Brain::loadFromJSON("../../../database/","DetailTest");
	return brain;
}

int BDetailTest_main(int argc, char *argv[])
{
	SNNEngine *engine = new SNNEngine();
	engine->initialize("../../../database/","DetailTest");
	engine->startEngine();
}


// ============== DetailTest.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

class DetailTest
{
public:
	DetailTest(void);
	~DetailTest(void);
	static Brain *create(bool rebuild=true);
	static Brain* createFromJSON(void);
	static void step(Brain *brain);
	static std::string formatNumber(unsigned long long number);
	static void insertSynapses(Nucleus *nuc);
	static void insertSynapses(Nucleus* nucA, Nucleus* nucB);
	static void finalAdjustments(std::stringstream &ss);
};


// ============== Encoder.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Encoder.h"
#include "Global.h"

Encoder::Encoder(Nucleus *nucleus)
{
	this->nucleus = nucleus;
}

Encoder::~Encoder(void)
{
}

void Encoder::post(Event *e)
{
//	int eSize = e->sampleSize;
/*
	int nSize = 0;
	for(size_t i=0;i<nucleus->columns.size();i++)
	{
		Column *col = nucleus->columns[i];
		for(size_t j=0;j<col->layers[3]->clusters.size();j++) // layer 4 is input
		{
			Cluster *cls = col->layers[3]->clusters[j];
			nSize += cls->neurons.size();
		}
	}
*/
	// We now know the number of neurons in this layer
	size_t ePos = 0;
	for(size_t i=0;i<nucleus->columns.size();i++)
	{
		if(ePos<e->sampleSize) 
		{
			Column *col = globalObject->columnDB.getComponent(nucleus->columns[i]);
			Layer *thisLayer = globalObject->layerDB.getComponent(col->layers[3]);
			size_t clSize = thisLayer->clusters.size();
			for(size_t j=0;j<clSize;j++) // layer 4 is input
			{
				if(ePos<e->sampleSize) 
				{
					Cluster *cls = globalObject->clusterDB.getComponent(thisLayer->clusters[j]);
					for(size_t k=0;k<cls->getNeurons().size();k++)
					{	
						if(ePos<e->sampleSize) 
						{
							if(e->samples[ePos++]!=0)
							{
								Neuron *neuron = globalObject->neuronDB.getComponent(cls->getNeurons()[k]);
								//
								if(globalObject->logEvents) 
								{	
									std::stringstream ss;
									ss << "encoder_post_firing: neuron=" << neuron->id;
									globalObject->writeEventLog(ss.str().c_str());
								}
								//
								neuron->fire();
							}
						}
						else
							break;
					}
				}
				else
					break;
			}
		}
		else
			break;
	}
}

Event *Encoder::get(void)
{
	size_t nSize = 0;
	for(size_t i=0;i<nucleus->columns.size();i++)
	{
		Column *col = globalObject->columnDB.getComponent(nucleus->columns[i]);
		Layer *thisLayer = globalObject->layerDB.getComponent(col->layers[0]); // layer 1 is input
		for(size_t j=0;j<thisLayer->clusters.size();j++) 
		{
			Cluster *cls = globalObject->clusterDB.getComponent(thisLayer->clusters[j]);
			nSize += cls->getNeurons().size();
		}
	}

	Event *e = new Event(nSize);

	int ePos = 0;
	for(size_t i=0;i<nucleus->columns.size();i++)
	{
		if(ePos<(int)e->sampleSize) 
		{
			Column *col = globalObject->columnDB.getComponent(nucleus->columns[i]);
			Layer *thisLayer = globalObject->layerDB.getComponent(col->layers[0]); // layer 1 is input
			for(size_t j=0;j<thisLayer->clusters.size();j++) 
			{
				if(ePos<(int)e->sampleSize) 
				{
					Cluster *cls = globalObject->clusterDB.getComponent(thisLayer->clusters[j]);
					for(size_t k=0;k<cls->getNeurons().size();k++)
					{	
						if(ePos<(int)e->sampleSize) 
						{
							Neuron *neuron = globalObject->neuronDB.getComponent(cls->getNeurons()[k]);
							if(neuron->isFiring())
								e->samples[ePos++]=1;
							else
								e->samples[ePos++]=0;
						}
						else
							break;
					}
				}
				else
					break;
			}
		}
		else
			break;
	}
	return e;
}


// ============== Encoder.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include "Nucleus.h"
#include "Event.h"

class Encoder
{
	Nucleus *nucleus;
public:
	Encoder(Nucleus *nucleus);
	~Encoder(void);
	void post(Event *e);
	Event *get(void);
};


// ============== Event.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Event.h"

Event::Event(size_t size)
{
	sampleSize = size;
	samples = new char[size];
}

Event::~Event(void)
{
}


// ============== Event.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <stddef.h>
class Event
{
public:
	Event(size_t size);
	virtual ~Event(void);
	size_t sampleSize;
	char *samples;
};


// ============== FloatTuple.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
class FloatTuple
{
public:
	float first;
	float second;
};



// ============== Global.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <ctime>
#include "Global.h"
#include "Server.h" // if needed

extern Global *globalObject;
FILE *logFile;
int logMemoryAllocations;

char *ctypes[] = {"ComponentTypeUnknown", "ComponentTypeBrain", "ComponentTypeRegion", "ComponentTypeNucleus", "ComponentTypeColumn", "ComponentTypeLayer",
                  "ComponentTypeCluster", "ComponentTypeNeuron", "ComponentTypeAxon", "ComponentTypeDendrite", "ComponentTypeSynapse",
                  "ComponentTypeActionPotential", "ComponentTypeTimedEvent"};


long getGlobalTimestep()
{
	return globalObject->getCurrentTimestamp();
}

Global::Global(std::string inDBPath, std::string inModelName) : 
    neuronDB(30000,inDBPath, inModelName), 
    clusterDB(1000,inDBPath, inModelName), 
    dendriteDB(500000,inDBPath, inModelName), 
    synapseDB(500000,inDBPath, inModelName), 
    axonDB(30000,inDBPath, inModelName),
    layerDB(1000,inDBPath, inModelName),
    columnDB(1000,inDBPath, inModelName),
    nucleusDB(1000,inDBPath, inModelName),
    regionDB(100,inDBPath, inModelName),
    brainDB(10,inDBPath, inModelName)
{
    setDBPath(inDBPath);
    setModelName(inModelName);
    std::stringstream ss;
    for (size_t i = 0; i < CTYPE_COUNT; i++)
    {
        long index = (long)i;
        componentBase[i] = 100000000 * index;
        componentCounter[i] = componentBase[i];
        componentCounter2[i] = 0;

        ss << "Component " << ctypes[i] << " assigned values starting at  " << componentCounter[i] << std::endl;
        log(ss);
        ss.str(""); ss.clear();
    }

    current_timestep = 0;
    logMemoryAllocations = 0;
    startRealTime = boost::posix_time::microsec_clock::local_time();

    for (size_t i = 0; i < MAX_TIMEINTERVAL_BUFFER_SIZE; i++)
    {
        timeIntervalEvents[i] = std::vector<TimedEvent *>();
        teVector_mutex.push_back(new boost::mutex());
    }

    syncpoint = -1;

    logFile = NULL;

    workers = new boost::asio::thread_pool(MAX_THREADPOOL_SIZE);
    firefile = NULL;
    firelogfile = NULL;
    debugfile = NULL;
    eventlogfile = NULL;
    structurelogfile = NULL;
    firePatternlogfile = NULL;

    setLogFiring = false;
    keepWebserverRunning = true;
    logEvents = false;
}

Global::~Global(void)
{
}

size_t Global::getTypeIndex(std::string name)
{
    for (int i = 0; i < CTYPE_COUNT; i++)
    {
        if (name == std::string(ctypes[i]))
        {
            return i;
        }
    }
    return (size_t)-1;
}

char *Global::allocClearedMemory(size_t count)
{
    if (logFile == NULL)
    {
        if (logMemoryAllocations)
            logFile = fopen((std::string(getDBPath()) + getModelName() + std::string("/") + std::string("DebugLogFile.txt")).c_str(), "w");
    }

    if (logMemoryAllocations)
        fprintf(logFile, "Allocating %d bytes...\r", (int)count);

    char *mem = new char[count];
    memset(mem, '\0', count);

    if (logMemoryAllocations)
        fprintf(logFile, "%d (0x%llx) bytes Allocated\n", (int)count, (unsigned long long)mem);

    return mem;
}

void Global::freeMemory(char *mem)
{
    unsigned long long ptr = (unsigned long long)mem;

    if (logMemoryAllocations && logFile == NULL)
        logFile = fopen((std::string(getDBPath()) + getModelName() + std::string("/") + std::string("DebugLogFile.txt")).c_str(), "w");

    if (logMemoryAllocations)
        fprintf(logFile, "Deallocating 0x%llx\r", ptr);

    delete[] mem;

    if (logMemoryAllocations)
        fprintf(logFile, "0x%llx deallocated\n", ptr);
}

void Global::step(void)
{
    brain->step();
}

long Global::getTotalEvents() 
{
    long cts = getCurrentTimestamp();
    long maxLookahead = cts + MAX_TIMEINTERVAL_OFFSET;
    long totalEvents = 0;
    for(long i=cts;i<maxLookahead;i++)
    {
        size_t intervalOffsetValue = (size_t) i % MAX_TIMEINTERVAL_BUFFER_SIZE;
        totalEvents += timeIntervalEvents[intervalOffsetValue].size();
    }
    return totalEvents;
}

long Global::getAllTotalEvents() 
{
    long totalEvents = 0;
    for(long i=0;i<MAX_TIMEINTERVAL_BUFFER_SIZE;i++)
    {
        totalEvents += timeIntervalEvents[i].size();
    }
    return totalEvents;
}

void Global::increment(void)
{
    boost::mutex::scoped_lock amx(timestep_mutex);
    current_timestep++;
}

long Global::nextComponent(ComponentType type)
{
    return componentCounter[type]++;
}

bool Global::validTimedEvent(unsigned long id)
{
    if (id >= componentBase[ComponentTypeTimedEvent] && id < componentBase[ComponentTypeTimedEvent] + 100000000)
        return true;
    return false;
}

bool Global::validActionPotential(unsigned long id)
{
    if (id >= componentBase[ComponentTypeActionPotential] && id < componentBase[ComponentTypeTimedEvent])
        return true;
    return false;
}

void Global::insert(Brain *brain)
{
    brainDB.insert(brain);
    this->brain = brain;
}

size_t Global::brainSize(void)
{
    return brainDB.size();
}

void Global::insert(Region *region)
{
    regionDB.insert(region);
    bool newRegion = true;
    for(size_t i=0;i<brain->regions.size();i++)
    {
        if(brain->regions[i] == region->id)
        {
            newRegion = false;
        } 
    }
    if(newRegion)
        brain->regions.push_back(region->id);
}

size_t Global::regionsSize(void)
{
    return regionDB.size();
}

void Global::insert(Nucleus *nucleus)
{
    nucleusDB.insert(nucleus);
}

size_t Global::nucleiSize(void)
{
    return nucleusDB.size();
}

void Global::insert(Column *column)
{
    columnDB.insert(column);
}

size_t Global::columnsSize(void)
{
    return columnDB.size();
}

void Global::insert(Layer *layer)
{
    layerDB.insert(layer);
}

size_t Global::layersSize(void)
{
    return layerDB.size();
}

void Global::insert(Cluster *cluster)
{
    clusterDB.insert(cluster);
}

size_t Global::clustersSize(void)
{
    return clusterDB.size();
}

void Global::insert(Neuron *neuron)
{
    neuronDB.insert(neuron);
}

size_t Global::neuronsSize(void)
{
    return neuronDB.size();
}

void Global::insert(Axon *axon)
{
    axonDB.insert(axon);
}

size_t Global::axonsSize(void)
{
    return axonDB.size();
}

void Global::insert(Dendrite *dendrite)
{
    dendriteDB.insert(dendrite);
}

size_t Global::dendritesSize(void)
{
    return dendriteDB.size();
}

void Global::insert(Synapse *synapse)
{
    synapseDB.insert(synapse);
}

size_t Global::synapsesSize(void)
{
    return synapseDB.size();
}

void Global::insertFiring(Neuron *neuron)
{
    boost::mutex::scoped_lock amx(firingNeurons_mutex);
    firingNeurons.insert(std::make_pair(neuron->id, neuron));
}

bool Global::componentKeyInRange(unsigned long key)
{
    if (key >= componentBase[ComponentTypeBrain] && key <= (componentBase[ComponentTypeTimedEvent] + 100000000))
    {
        return true;
    }
    return false;
}

void Global::insert(TimedEvent *timedEvent, int intervalOffset)
{
    size_t intervalOffsetValue = (size_t)intervalOffset % MAX_TIMEINTERVAL_BUFFER_SIZE;
    boost::mutex::scoped_lock amx(*teVector_mutex[intervalOffsetValue]);
    timeIntervalEvents[intervalOffsetValue].push_back(timedEvent);
}

float Global::euclideanDistance(const std::vector<float>& a, const std::vector<float>& b) {
    float sum = 0.0;
    for (size_t i = 0; i < a.size(); ++i) {
        float diff = a[i] - b[i];
        sum += diff * diff;
    }
    return std::sqrt(sum);
}

std::map<int, float> Global::clusterPatterns(const std::vector<std::vector<float>> &patterns, int numClusters, int vectorLength)
{
    // Simple K-Means clustering (as placeholder)
    std::vector<std::vector<float>> centroids(numClusters, std::vector<float>(vectorLength, 0.0));
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution<> dis(0, (int)patterns.size() - 1);

    for (int i = 0; i < numClusters; ++i)
    {
        centroids[i] = patterns[dis(gen)];
    }

    std::vector<int> assignments(patterns.size(), -1);
    bool changed;

    do
    {
        changed = false;

        for (size_t i = 0; i < patterns.size(); ++i)
        {
            float minDist = std::numeric_limits<float>::max();
            int bestCluster = -1;
            for (int j = 0; j < numClusters; ++j)
            {
                float dist = euclideanDistance(patterns[i], centroids[j]);
                if (dist < minDist)
                {
                    minDist = dist;
                    bestCluster = j;
                }
            }
            if (assignments[i] != bestCluster)
            {
                assignments[i] = bestCluster;
                changed = true;
            }
        }

        std::vector<std::vector<float>> newCentroids(numClusters, std::vector<float>(vectorLength, 0.0));
        std::vector<int> counts(numClusters, 0);

        for (size_t i = 0; i < patterns.size(); ++i)
        {
            int cluster = assignments[i];
            for (int j = 0; j < vectorLength; ++j)
            {
                newCentroids[cluster][j] += patterns[i][j];
            }
            counts[cluster]++;
        }

        for (int j = 0; j < numClusters; ++j)
        {
            if (counts[j] > 0)
            {
                for (int k = 0; k < vectorLength; ++k)
                {
                    newCentroids[j][k] /= counts[j];
                }
            }
        }

        centroids = newCentroids;

    } while (changed);

    std::map<int, float> patternProbabilities;
    for (size_t i = 0; i < patterns.size(); ++i)
    {
        int cluster = assignments[i];
        float dist = euclideanDistance(patterns[i], centroids[cluster]);
        float probability = std::exp(-dist);
        patternProbabilities[(int)i] = probability;
    }

    return patternProbabilities;
}

void Global::cycle(void)
{
    runInference();
}

long Global::getCurrentTimestamp(void)
{
    return current_timestep;
}

Range Global::batchFire(std::vector<Neuron *> *firingNeurons, long waitPeriod)
{
    boost::mutex::scoped_lock amx1(batchfire_mutex);
    std::stringstream ss;
    if(logEvents) 
    {
        ss << "batch_fire: neurons=";
    }
    std::string sep = "";

    long lowestOffset = MAX_TIMEINTERVAL_OFFSET;
    long highestOffset = -MAX_TIMEINTERVAL_OFFSET;
    for (size_t i = 0; i < firingNeurons->size(); i++)
    {
        Neuron *neuron = (*firingNeurons)[i];
		neuron->setMembranePotential(neuron->threshold+1.0f);
        Range offset = neuron->fire();

        if(lowestOffset > offset.low)
            lowestOffset = offset.low;
        if(highestOffset < offset.high)
            highestOffset = offset.high;

        if(logEvents) 
        {
            ss << sep << neuron->id;
            sep = ",";
        }
    }

    if(logEvents) 
    {
        writeEventLog(ss.str().c_str());
    }

    globalObject->lastFiredNeuron = NULL;
    // (Here you might wait or do other logic if needed)
    Range range;
    range.low = lowestOffset;
    range.high = highestOffset;    
    return range;
}

Range Global::batchLearn(std::vector<Neuron *> *inputNeurons, std::vector<Neuron *> *outputNeurons, std::string nucleusName)
{
    Range range;
    std::vector<Neuron *> firingNeurons;
    for(size_t i=0;i<inputNeurons->size();i++)
    {
        firingNeurons.push_back((*inputNeurons)[i]);
    }
    for(size_t i=0;i<outputNeurons->size();i++)
    {
        firingNeurons.push_back((*outputNeurons)[i]);
    }

    batchFire(&firingNeurons);
    range.low = 0;
    range.high = 0;
    return range;
}

float Global::evaluateResponse(std::vector<Neuron *> *outputNeurons,std::vector<Neuron *> *nucleusNeurons)
{
    size_t totalSize = nucleusNeurons->size();
    size_t totalCorrectFiring = 0;
    size_t totalCorrectNotFiring = 0;
    size_t totalIncorrectFiring = 0;
    size_t totalIncorrectNotFiring = 0;
    std::unordered_map<unsigned long, Neuron *> outputNeuronMap;
    for(size_t i=0;i<outputNeurons->size();i++)
    {
        Neuron *n = (*outputNeurons)[i];
        outputNeuronMap.insert(std::make_pair(n->id, n));
    }

    for(size_t i=0;i<nucleusNeurons->size();i++)
    {
        Neuron *thisNeuron =(*nucleusNeurons)[i];
        auto it = outputNeuronMap.find(thisNeuron->id);
        if (it != outputNeuronMap.end())
        {
            Neuron *outputNeuron = it->second;
            if(outputNeuron->isFiring())
                totalCorrectFiring++;
            else 
                totalIncorrectNotFiring++;
        }
        else
        {
            if(thisNeuron->isFiring())
                totalIncorrectFiring++;
            else 
                totalCorrectNotFiring++;
        }
    }

    size_t correct = (totalCorrectFiring + totalCorrectNotFiring);
    float pct = (float)correct / (float)totalSize;
    return pct *  100.0;
}

void Global::runInference(void)
{
    boost::mutex::scoped_lock amx1(inference_mutex);
    size_t intervalOffsetValue = (size_t)getCurrentTimestamp() % MAX_TIMEINTERVAL_BUFFER_SIZE;
    boost::mutex::scoped_lock amx(*teVector_mutex[intervalOffsetValue]);
    std::vector<TimedEvent *> *teVector = &timeIntervalEvents[intervalOffsetValue];
    size_t tevSize = teVector->size();

    if (tevSize > 0)
    {
        if (tevSize > THREADPOOL_SLICE_THRESHOLD)
        {
            size_t sizeper = tevSize / (size_t)MAX_THREADPOOL_SIZE;
            for (size_t n = 0; n < (size_t)MAX_THREADPOOL_SIZE; ++n)
            {
                size_t per = sizeper;
                size_t startper = n * sizeper;
                if(startper + per > tevSize)
                    per = tevSize - startper;

                boost::asio::post(*workers, [=] {
                    inferenceSlice(teVector, startper, per, false, intervalOffsetValue);
                });
            }
            workers->join();
        }
        else
        {
            inferenceSlice(teVector, 0, tevSize, false, intervalOffsetValue);
        }

        // Clean up processed events
        for (auto &te : *teVector)
        {
            delete te;
        }
        teVector->clear();
    }
}

void Global::runLearning(void)
{
    long learningWindowSize = 100L;
    long learningInterval = getCurrentTimestamp()  - learningWindowSize;
    std::pair<std::vector<Neuron *> *, std::vector<Neuron *> *> *neurons = getNeurons(learningInterval, learningWindowSize);

    std::vector<Neuron *> *preNeurons = neurons->first;
    std::vector<Neuron *> *postNeurons = neurons->second;

    if (preNeurons->empty() && postNeurons->empty()) {
        delete preNeurons;
        delete postNeurons;
        delete neurons;
        return;
    }

    long neuronIdStart = componentBase[ComponentTypeNeuron];
    long neuronIdEnd = componentCounter[ComponentTypeNeuron];
    std::vector<Neuron *> affectedNeurons;

    for(long neuronIndex = neuronIdStart; neuronIndex < neuronIdEnd; neuronIndex++)
    {
        Neuron *thisNeuron = neuronDB.getComponent(neuronIndex);
        if(thisNeuron && thisNeuron->lastfired > (unsigned long)(learningInterval - learningWindowSize))
        {
            thisNeuron->applySTDP(neurons, learningInterval);
            affectedNeurons.push_back(thisNeuron);
        }
    }

    // Normalize potentials after STDP
    size_t nCount = affectedNeurons.size();
    if(nCount>0)
    {
        Neuron *thisNeuron = nullptr;
        float totalPotential = 0;
        for(size_t i = 0; i < nCount; i++)
        {
            thisNeuron = affectedNeurons[i];
            totalPotential += thisNeuron->getMembranePotential();
        }
        float mean = totalPotential / (float)nCount;

        if(!std::isnan(mean))
        {
            for(size_t i = 0; i < nCount; i++)
            {
                thisNeuron = affectedNeurons[i];
                thisNeuron->setMembranePotential(thisNeuron->getMembranePotential() - mean);
            }
        }
        for(size_t i = 0; i < nCount; i++)
        {
            thisNeuron = affectedNeurons[i];
			thisNeuron->fire();
        }

    }
	globalObject->applyLocalHomeostasis(preNeurons); // run homeostasis
	globalObject->applyLocalHomeostasis(postNeurons); // run homeostasis

    delete preNeurons;
    delete postNeurons;
    delete neurons;

}

void Global::inferenceSlice(std::vector<TimedEvent *> *teVector, size_t start, size_t count, bool display, size_t intervalOffsetValue)
{
    (void)display;
    (void)intervalOffsetValue;
    for (size_t i = start; i < start + count; i++)
    {
        TimedEvent *te = (*teVector)[i];
        ActionPotential *ap = te->ap;
        if (ap->owningProcessId >= componentBase[ComponentTypeAxon] && ap->owningProcessId < componentBase[ComponentTypeSynapse])
        {
            if (ap->owningProcessId >= componentBase[ComponentTypeDendrite])
            {
                Synapse *s = synapseDB.getComponent(te->synapseId);
                if(s) s->receiveAP(ap);
            }
        }
    }
}

void Global::flush(void)
{
    layerDB.flush();
    clusterDB.flush();
    columnDB.flush();
    nucleusDB.flush();
    regionDB.flush();
    brainDB.flush();
    neuronDB.flush();
    axonDB.flush();
    dendriteDB.flush();
    synapseDB.flush();
}

void Global::flushAll(void)
{
    layerDB.flushAll();
    clusterDB.flushAll();
    columnDB.flushAll();
    nucleusDB.flushAll();
    regionDB.flushAll();
    brainDB.flushAll();
    neuronDB.flushAll();
    axonDB.flushAll();
    dendriteDB.flushAll();
    synapseDB.flushAll();
}

void Global::loadAll(void)
{
    layerDB.loadCache();
    clusterDB.loadCache();
    columnDB.loadCache();
    nucleusDB.loadCache();
    regionDB.loadCache();
    brainDB.loadCache();
    neuronDB.loadCache();
    axonDB.loadCache();
    dendriteDB.loadCache();
    synapseDB.loadCache();
}

void Global::shutdown(void)
{
    layerDB.shutdown();
    clusterDB.shutdown();
    columnDB.shutdown();
    nucleusDB.shutdown();
    regionDB.shutdown();
    brainDB.shutdown();
    neuronDB.shutdown();
    axonDB.shutdown();
    dendriteDB.shutdown();
    synapseDB.shutdown();
}

void Global::debug(char *str)
{
    boost::mutex::scoped_lock amx(debug_mutex);
    time_t rawtime;
    struct tm *timeinfo;
    char buffer[80];

    time(&rawtime);
    timeinfo = localtime(&rawtime);

    strftime(buffer, 80, "%m-%d-%Y %I:%M:%S", timeinfo);
    std::string timestr(buffer);

    std::string s(str);
    if (debugfile == NULL)
    {
        std::string filename(std::string(getDBPath()) + getModelName() + std::string("/") + std::string("debug.txt"));
        debugfile = new std::ofstream(filename, std::ios::out);
    }
    *debugfile << timestr << " : " << s << std::endl;
}

void Global::debug(std::stringstream &ss)
{
    debug((char *)ss.str().c_str());
}

void Global::log(char *str)
{
    time_t rawtime;
    struct tm *timeinfo;
    char buffer[80];

    time(&rawtime);
    timeinfo = localtime(&rawtime);

    strftime(buffer, 80, "%m-%d-%Y %I:%M:%S", timeinfo);
    std::string timestr(buffer);

    std::string s(str);
    std::cout << timestr << " : " << s;

    std::ofstream logfile;
    logfile.open(dbPath + modelName + std::string("/") + "logfile.txt", std::ios::app);
    logfile << timestr << " : " << s;
    logfile.close();
}

void Global::log(std::stringstream &ss)
{
    log((char *)ss.str().c_str());
}

void Global::writeSyncpoint(int sp)
{
    time_t rawtime;
    struct tm *timeinfo;
    char buffer[80];

    time(&rawtime);
    timeinfo = localtime(&rawtime);

    strftime(buffer, 80, "%m-%d-%Y %I:%M:%S", timeinfo);
    std::string timestr(buffer);

    std::ofstream spfile;
    spfile.open(std::string(getDBPath()) + getModelName() + std::string("/") + "syncpoint.txt", std::ios::trunc);
    spfile << timestr << " | syncpoint = " << sp << std::endl;

    spfile.close();
}

void Global::writeCounters(void)
{


    std::ofstream ctrfile;
    ctrfile.open(std::string(getDBPath()) + getModelName() + std::string("/") + "counters.txt", std::ios::trunc);
	for(size_t i=0; i<CTYPE_COUNT;i++) {
		long ctr = globalObject->componentCounter[i];
        ctrfile << i << " = " << ctr << std::endl;
	}

    ctrfile.close();
}

void Global::readCounters(void)
{


    std::ifstream ctrfile;
    ctrfile.open(std::string(getDBPath()) + getModelName() + std::string("/") + "counters.txt");
	for(size_t i=0; i<CTYPE_COUNT;i++) {
        std::string line;
        size_t seq=0;
        long val=0;
        char eq;
        std::getline(ctrfile,line);
        std::istringstream iss(line);
        iss >> seq >> eq >> val;

		globalObject->componentCounter[seq] = val;
        globalObject->componentCounter2[seq] = val - globalObject->componentBase[seq];
	}

    ctrfile.close();
}

int Global::readSyncpoint(void)
{
    std::string line;
    std::string delimiter1 = "|";
    std::string delimiter2 = "=";
    std::ifstream spfile;
    spfile.open(std::string(getDBPath()) + getModelName() + std::string("/") + "syncpoint.txt", std::ios::in);
    while (std::getline(spfile, line))
    {
        std::string temp = line.substr(line.find(delimiter1) + 1);
        std::string sptoken1 = trim(temp);
        size_t pos = sptoken1.find(delimiter2);
        temp = sptoken1.substr(0, pos);
        std::string sptokenKey = trim(temp);
        temp = sptoken1.substr(pos + 1);
        std::string sptokenValue = trim(temp);
        int value = atoi(sptokenValue.c_str());

        if (sptokenKey == "syncpoint")
            syncpoint = value;
    }

    spfile.close();
    return syncpoint;
}

std::string Global::getMessage(void)
{
    boost::mutex::scoped_lock mx(xThreadQueue_mutex);
    std::string msg;
    if (!xThreadQueue.empty())
    {
        msg = xThreadQueue.front();
        xThreadQueue.pop();
    }
    return msg;
}

void Global::putMessage(std::string msg)
{
    boost::mutex::scoped_lock mx(xThreadQueue_mutex);
    xThreadQueue.push(msg);
}

void Global::writeFireLog(std::string msg)
{
    if (firelogfile == NULL)
    {
        firelogfile = new std::ofstream(std::string(LOGGING_PATH) + getModelName() + std::string("/") + "fireLog.txt", std::ios::app);
    }
    *firelogfile << std::setw(10) << std::setfill('0') <<  getCurrentTimestamp() << " : " << msg << std::endl;
}

void Global::closeFireLog(void)
{
    if (firelogfile != NULL)
    {
        firelogfile->close();
        firelogfile = NULL;
    }
}

void Global::writeEventLog(std::string msg)
{
    boost::mutex::scoped_lock amx(log_event_mutex);
    if (eventlogfile == NULL)
    {
        std::string filename = std::string(LOGGING_PATH) + getModelName() + std::string("/") + "eventLog.txt";
        eventlogfile = new std::ofstream(filename, std::ios::app);
    }

    *eventlogfile << std::setw(10) << std::setfill('0') <<  getCurrentTimestamp() << " : " << msg << std::endl;
    eventlogfile->flush();
}

void Global::closeEventLog(void)
{
    if (eventlogfile != NULL)
    {
        eventlogfile->flush();
        eventlogfile->close();
        eventlogfile = NULL; 
    }
}

void Global::writeStructureLog(std::string msg)
{
    if (structurelogfile == NULL)
    {
        std::string filename = std::string(LOGGING_PATH) + getModelName() + std::string("/") + "structureLog.txt";
        structurelogfile = new std::ofstream(filename, std::ios::app);
    }

    *structurelogfile << std::setw(10) << std::setfill('0') <<  getCurrentTimestamp() << " : " << msg << std::endl;
    structurelogfile->flush();
}

void Global::closeStructureLog(void)
{
    if (structurelogfile != NULL)
    {
        structurelogfile->flush();
        structurelogfile->close();
        structurelogfile = NULL; 
    }
}

void Global::writeFirePatternLog(std::string msg)
{
    boost::mutex::scoped_lock amx(firingPatterns_mutex);
    if (firePatternlogfile == NULL)
    {
        std::string filename = std::string(LOGGING_PATH) + getModelName() + std::string("/") + "firePatterLog.txt";
        firePatternlogfile = new std::ofstream(filename, std::ios::app);
    }

    *firePatternlogfile << std::setw(10) << std::setfill('0') <<  getCurrentTimestamp() << " : " << msg << std::endl;
    firePatternlogfile->flush();
}

void Global::closeFirePatternLog(void)
{
    if (firePatternlogfile != NULL)
    {
        firePatternlogfile->flush();
        firePatternlogfile->close();
        firePatternlogfile = NULL; 
    }
}

void Global::logStructure(void)
{
    long nucleusIdStart = componentBase[ComponentTypeNucleus];
    long nucleusIdEnd = componentCounter[ComponentTypeNucleus];
    for(long nucleusId=nucleusIdStart;nucleusId<nucleusIdEnd;nucleusId++)
    {
        Nucleus *nucleus = nucleusDB.getComponent(nucleusId);
        if(nucleus)
            logStructure(nucleus);
    }

    std::stringstream ss2;
    ss2 << "structure_complete: nucleusCount=" << nucleusIdEnd - nucleusIdStart;
    writeStructureLog(ss2.str().c_str());

    closeStructureLog();
}

void Global::logStructure(Nucleus *nucleus)
{
    long neuron_count = 0;
    long noDendriteNeuronCount = 0;
    size_t numColumns = nucleus->columns.size();
    for(size_t i=0;i<numColumns;i++)
    {
        long col_id = nucleus->columns[i];
        Column *column = columnDB.getComponent(col_id);
        size_t numLayers = column->layers.size();
        for(size_t j=0;j<numLayers;j++)
        {
            long layer_id = column->layers[j];
            Layer *layer = layerDB.getComponent(layer_id);
            size_t numClusters = layer->clusters.size();
            for(size_t k=0;k<numClusters;k++)
            {
                long cluster_id = layer->clusters[k];
                Cluster *cluster = clusterDB.getComponent(cluster_id);
                size_t numNeurons = cluster->neurons.size();
                for(size_t l=0;l<numNeurons;l++) 
                {
                    std::stringstream ss;
                    long neuron_id = cluster->neurons[l];
                    Neuron *neuron = neuronDB.getComponent(neuron_id);
                    if(!neuron) continue;
                    neuron_count++;

                    ss << "neuron_structure: neuron=" << neuron->id << ", nucleus=" << nucleus->name << ", axons=[";
                    size_t numAxons = neuron->getAxons()->size();
                    std::string sep="";
                    for(size_t m=0;m<numAxons;m++)
                    {
                        long axon_id = (*neuron->getAxons())[m];
                        Axon *ax = axonDB.getComponent(axon_id);

                        ss << sep << ax->id;

                        std::vector<long> *synapses = ax->getSynapses();
                        size_t numSynapses = synapses->size();
                        for(size_t n=0;n<numSynapses;n++)
                        {
                            long synapse_id = (*ax->getSynapses())[n];
                            ss << "/" << synapse_id;
                        }
                        sep=";";
                    }
                    ss << "], dendrites=[";
                    size_t numDendrites = neuron->getDendrites()->size();
                    if(numDendrites==0) {
                        noDendriteNeuronCount++;
                    }
                    sep="";
                    for(size_t m=0;m<numDendrites;m++)
                    {
                        long dendrite_id = (*neuron->getDendrites())[m];
                        Dendrite *den = dendriteDB.getComponent(dendrite_id);

                        ss << sep << den->id;
                        long synapse_id = den->getSynapseId();
                        long associate_neuron_id = den->getPreSynapticNeuronId();

                        ss << "/" << synapse_id << "-" << associate_neuron_id;
                        sep=";";
                    }
                    ss << "]";
                    writeStructureLog(ss.str().c_str());
                }
            }
        }
    }

    long synapse_start = componentBase[ComponentTypeSynapse];
    long synapse_end = componentCounter[ComponentTypeSynapse];
    for(long i=synapse_start;i<synapse_end;i++)
    {
        Synapse *synapse = synapseDB.getComponent(i);
        if(!synapse) continue;
        std::stringstream ss;
        ss << "synapse_structure: synapse=" << synapse->id << ", neuron=" << synapse->postSynapticNeuronId;
        writeStructureLog(ss.str().c_str());
    }

    long synapse_count = synapse_end - synapse_start;
    std::stringstream ss2;
    ss2 << "nucleus_counts: neuron_count=" << neuron_count << ", synapse_count=" << synapse_count;
    writeStructureLog(ss2.str().c_str());
}

std::vector<float> Global::softmax(const std::vector<float> &input)
{
    std::vector<float> exponentials(input.size());
    std::transform(input.begin(), input.end(), exponentials.begin(), [](float value)
    { return std::exp(value); });

    float sum = std::accumulate(exponentials.begin(), exponentials.end(), 0.0f);
    std::vector<float> softmaxVector(input.size());

    if (sum != 0)
    {
        std::transform(exponentials.begin(), exponentials.end(), softmaxVector.begin(), [sum](float value)
        { return value / sum; });
    }

    return softmaxVector;
}

Dendrite *Global::findConnectingDendrite(Neuron *neuronA, Neuron *neuronB)
{
    Dendrite *returnDendrite = NULL;
    auto it = neuronA->dendriteMap.find(neuronB->id);
    if (it != neuronA->dendriteMap.end())
    {
        long dendriteId = it->second;
        returnDendrite = dendriteDB.getComponent(dendriteId);
    }
    return returnDendrite;
}

std::pair<std::vector<Tuple*>*, std::vector<Tuple*>*> *Global::getSpikes(long now, long interval)
{
    std::vector<Tuple*> *preSpikeTimes = new std::vector<Tuple*>();
    std::vector<Tuple*> *postSpikeTimes = new std::vector<Tuple*>();

    int beginning_timestamp = (int)(now - interval);
    int ending_timestamp = (int)(now + interval);

    for(int thisInterval=beginning_timestamp;thisInterval<ending_timestamp;thisInterval++)
    {
        int thisIndex = thisInterval % MAX_TIMEINTERVAL_BUFFER_SIZE;
        boost::mutex::scoped_lock amx(*teVector_mutex[thisIndex]);
        int numEvents = (int)timeIntervalEvents[thisIndex].size();
        if (numEvents > 0)
        {
            for (int teIndex = 0; teIndex < numEvents; teIndex++)
            {
                TimedEvent *te = timeIntervalEvents[thisIndex][teIndex];
                if (thisInterval <= now)
                {
                    Tuple *t = new Tuple();
                    t->objectPtr = (char *)te;
                    t->value = te->slice;
                    preSpikeTimes->push_back(t);
                }
                else if (thisInterval > now)
                {
                    Tuple *t = new Tuple();
                    t->objectPtr = (char *)te;
                    t->value = te->slice;
                    postSpikeTimes->push_back(t);
                }
            }
        }
    }

    std::pair<std::vector<Tuple*>*, std::vector<Tuple*>*> *retpair = new std::pair<std::vector<Tuple*>*, std::vector<Tuple*>*>();
    retpair->first = preSpikeTimes;
    retpair->second = postSpikeTimes;

    return retpair;
}

std::pair<std::vector<Neuron *>*, std::vector<Neuron *>* > *Global::getNeurons(long now, long interval)
{
    std::vector<Neuron *> *preNeurons = new std::vector<Neuron *>();
    std::vector<Neuron *> *postNeurons = new std::vector<Neuron *>();

    unsigned long beginning_timestamp = (unsigned long)(now - interval);

    long neuronStart = componentBase[ComponentTypeNeuron];
    long neuronEnd = componentCounter[ComponentTypeNeuron];
    for(long neuronId = neuronStart; neuronId<neuronEnd; neuronId++)
    {
        Neuron *neuron = neuronDB.getComponent(neuronId);
        if(neuron && neuron->lastfired > beginning_timestamp)
        {
            if (neuron->lastfired <= (unsigned long) now && neuron->lastfired >= beginning_timestamp)
            {
                preNeurons->push_back(neuron);
            }
            else if (neuron->lastfired > (unsigned long) now)
            {
                postNeurons->push_back(neuron);
            }
        }

    }

    std::pair<std::vector<Neuron *> *, std::vector<Neuron *> *> *retpair = new std::pair<std::vector<Neuron *> *, std::vector<Neuron *> *>();
    retpair->first = preNeurons;
    retpair->second = postNeurons;

    return retpair;
}

void Global::logFiring(Neuron *n,bool firestatus)
{
    int intStat = (firestatus) ? 1 : 0;
    std::stringstream msg;
    if (setLogFiring)
    {
        msg << "Neuron " << n->id << ", state " << intStat << ", threshold " << n->threshold << ", potential " << n->getMembranePotential();
        writeFireLog(msg.str().c_str());
    }
}




// New method to apply local homeostasis
void Global::applyLocalHomeostasis(std::vector<Neuron *> *neurons)
{
	for(int idx=0;idx<neurons->size();idx++) 
	{
		Neuron *neuron = (*neurons)[idx];
        float recentRate = neuron->getEstimatedFiringRate(); 
        float diff = HOMEOSTASIS_TARGET_RATE - recentRate;

        if(std::fabs(diff) > 0.001f)
        {
            neuron->threshold += diff * HOMEOSTASIS_ADJUST_FACTOR; 
            if (neuron->threshold < 0.001f) {
                neuron->threshold = 0.001f; 
            }
            // Scale all synaptic weights of this neuron
            neuron->applySynapticScaling(SYNAPTIC_SCALING_FACTOR);
        }
    }
}

// New method to apply global homeostasis
void Global::applyGlobalHomeostasis()
{
    long neuronStart = componentBase[ComponentTypeNeuron];
    long neuronEnd = componentCounter[ComponentTypeNeuron];

    for(long neuronId = neuronStart; neuronId < neuronEnd; neuronId++)
    {
        Neuron *neuron = neuronDB.getComponent(neuronId);
        if(!neuron) continue;

        float recentRate = neuron->getEstimatedFiringRate(); 
        float diff = HOMEOSTASIS_TARGET_RATE - recentRate;

        if(std::fabs(diff) > 0.001f)
        {
            neuron->threshold += diff * HOMEOSTASIS_ADJUST_FACTOR; 
            if (neuron->threshold < 0.001f) {
                neuron->threshold = 0.001f; 
            }
            // Scale all synaptic weights of this neuron
            neuron->applySynapticScaling(SYNAPTIC_SCALING_FACTOR);
        }
    }
}


// ============== Global.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

//
// You can define your MODEL_IMPLEMENTATION_CLASS here if needed.
// #define MODEL_IMPLEMENTATION_CLASS BrainDemoTiny

#define MODEL_IMPLEMENTATION_CLASS BrainDemoTiny

#define DB_PATH globalObject->getDBPath()
#define LOGGING_PATH "/mnt/nas8t/SNNLogs/"

enum LayerType {input, output};

// Default simulation parameters
#define MAX_TIMEINTERVAL_BUFFER_SIZE 100000
#define MAX_TIMEINTERVAL_OFFSET 5000
#define MAX_THREADPOOL_SIZE 20
#define THREADPOOL_SLICE_THRESHOLD 1000 

// cap on number of APs before slowing down - twice as many as synapses
#define MAX_ACTIVE_ACTIONPOTENTIALS (globalObject->synapsesSize()*2) 

// rate for computing offset offset = position + (long)((position * rate) * AP_OFFSET_RATE);
#define AP_OFFSET_RATE 0.01f


// Conversions
#define MICROSECONDS 1
#define MILLISECONDS 1000
#define SECONDS 1000000

// Neural parameters
#define RESTING_POTENTIAL -65.0f
#define INITIAL_THRESHOLD -50.0f
#define INITIAL_LEARNING_RATE 10.0f
#define MAXIMUM_SYNAPSE_WEIGHT 65.0f
#define MINIMUM_SYNAPSE_WEIGHT -65.0f
#define MAXIMUM_AXON_RATE 1.0f
#define MAXIMUM_DENDRITE_RATE 1.0f
#define MINIMUM_MEMBRANE_POTENTIAL -65.f
#define MAXIMUM_MEMBRANE_POTENTIAL 130.f

// Default rates and distances
#define DEFAULT_AXON_RATE 1000.0f
#define DEFAULT_AXON_DISTANCE 1000.0f
#define DEFAULT_AXON_DISTANCE_STEP 0.2f
#define DEFAULT_DENDRITE_RATE 1.0f
#define DEFAULT_DENDRITE_DISTANCE 1000.0f
#define DEFAULT_DENDRITE_DISTANCE_STEP 0.2f
#define DEFAULT_STDP_RATE 1.25f
#define DEFAULT_SYNAPSE_POSITION 500.0

// STDP tuning constants (new)
#define A_PLUS 1.0f
#define A_MINUS -0.8f
#define TAU_PLUS 10.0f
#define TAU_MINUS 10.0f

// Homeostatic plasticity parameters (new)
#define HOMEOSTASIS_TARGET_RATE 0.1f
#define HOMEOSTASIS_ADJUST_FACTOR 0.001f

// Membrane potential decay (leaky integrate-and-fire) (new)
#define LEAK_FACTOR 0.99f

// Synaptic scaling factor applied after STDP (new)
#define SYNAPTIC_SCALING_FACTOR 1.0f

// Growth of dendrites disabled for now
#define GROW_DENDRITES false

#define EXCITATORY 1.0f
#define INHIBITORY -1.0f

#include <stdio.h>
#include <map>
#include <vector>
#include <string>
#include <iostream>
#include <sstream>
#include <algorithm>
#include <queue>
#include <boost/thread.hpp>
#include <boost/asio.hpp>
#include <boost/asio/post.hpp>
#include <boost/asio/thread_pool.hpp>
#include <cmath>
#include <fstream>

#include "NNComponent.h"
#include "Brain.h"
#include "Region.h"
#include "Nucleus.h"
#include "Column.h"
#include "Layer.h"
#include "Cluster.h"
#include "Neuron.h"
#include "Axon.h"
#include "Dendrite.h"
#include "Synapse.h"
#include "ActionPotential.h"
#include "TimedEvent.h"
#include "CollectionIterator.h"
#include "ComponentDB.h"
#include "Location3D.h"
#include "Range.h"
#include "FloatTuple.h"

#define STALL_OVERHEAD 100

extern class Global *globalObject;


class Global
{
private:
    long timeEventsCounter = 0L;
    std::map<unsigned long,Neuron *> firedNeurons;

public:
    boost::mutex xThreadQueue_mutex;
    boost::mutex log_event_mutex;
    boost::mutex neuron_cycle_mutex;
    boost::mutex inference_mutex;
    boost::mutex timestamp_mutex;
    boost::mutex firedneuron_mutex;

    std::string modelName;
    std::string dbPath;

    std::queue<std::string> xThreadQueue;

    bool logResponseMode = false;

    std::string lastImageString;

    Global(std::string inDBPath, std::string inModelName);
    virtual ~Global(void);

    std::string getModelName(void) { return modelName; };
    void setModelName(std::string inModelName) { modelName = inModelName; };
    std::string getDBPath() { return dbPath; };
    void setDBPath(std::string inDBPath) { dbPath = inDBPath; };

    void step(void);
    void increment(void);
    void addTimedEvent(TimedEvent* te);
    long nextComponent(ComponentType type);
    void runInference(void);
    void runLearning(void);
    void cycle(void);
    void inferenceSlice(std::vector<TimedEvent*>* teVector, size_t start, size_t count, bool display, size_t intervalOffsetValue);
    void flush(void);
    void flushAll(void);
    void shutdown(void);
    void log(char *str);
    void log(std::stringstream &ss);
    void logFiring(Neuron *n,bool firestatus);
    void writeCounters(void);
    void readCounters(void);

    Range batchFire(std::vector<Neuron *> *firingNeurons, long waitPeriod=0);
    Range batchLearn(std::vector<Neuron *> *inputNeurons, std::vector<Neuron *> *outputNeurons, std::string nucleusName);
    float evaluateResponse(std::vector<Neuron *> *outputNeurons,std::vector<Neuron *> *nucleusNeurons);
    long getCurrentTimestamp(void);
    float euclideanDistance(const std::vector<float>& a, const std::vector<float>& b);
    std::map<int, float> clusterPatterns(const std::vector<std::vector<float>> &patterns, int numClusters, int vectorLength);

    Dendrite *findConnectingDendrite(Neuron *neuronA, Neuron *neuronB);
    long getTotalEvents(void);
    long getAllTotalEvents(void);

    void debug(char *str);
    void debug(std::stringstream &ss);

    std::map<long,Neuron *> firingNeurons;

    std::vector<float> softmax(const std::vector<float>& input);
    std::pair<std::vector<Tuple*>*, std::vector<Tuple*>* > *getSpikes(long now, long interval);
    std::pair<std::vector<Neuron *>*, std::vector<Neuron *>* > *getNeurons(long now, long interval);

    char* allocClearedMemory(size_t count);
    void freeMemory(char *ptr);

    bool componentKeyInRange(unsigned long key);
    bool validTimedEvent(unsigned long id);
    bool validActionPotential(unsigned long id);

    void loadAll(void);

    size_t getTypeIndex(std::string  name);

    // Insert methods
    void insert(Brain *brain);
    size_t brainSize(void);
    void insert(Region *region);
    size_t regionsSize(void);
    void insert(Nucleus *nucleus);
    size_t nucleiSize(void);
    void insert(Column *column);
    size_t columnsSize(void);
    void insert(Layer *layer);
    size_t layersSize(void);
    void insert(Cluster *cluster);
    size_t clustersSize(void);
    void insert(Neuron *neuron);
    size_t neuronsSize(void);
    void insert(Axon *axon);
    size_t axonsSize(void);
    void insert(Dendrite *dendrite);
    size_t dendritesSize(void);
    void insert(Synapse *synapse);
    size_t synapsesSize(void);

    void insert(TimedEvent *timedEvent,int intervalOffset);

    void insertFiring(Neuron *neuron);

    void writeSyncpoint(int sp);
    int readSyncpoint(void);

    std::string getMessage(void);
    void putMessage(std::string);

    void writeFireLog(std::string msg);
    void closeFireLog(void);
    void closeDebugLog(void);

    void writeEventLog(std::string msg);
    void closeEventLog(void);

    void writeStructureLog(std::string msg);
    void closeStructureLog(void);

    void logStructure(void);
    void logStructure(Nucleus *nucleus);

    void writeFirePatternLog(std::string msg);
    void closeFirePatternLog(void);

// trim from start (in place)
	static inline std::string &ltrim(std::string& s) {
		s.erase(s.begin(), std::find_if(s.begin(), s.end(), [](unsigned char ch) {
			return !std::isspace(ch);
			}));
		return s;
	}

	// trim from end (in place)
	static inline std::string &rtrim(std::string& s) {
		s.erase(std::find_if(s.rbegin(), s.rend(), [](unsigned char ch) {
			return !std::isspace(ch);
			}).base(), s.end());
		return s;
	}

	// trim from both ends (in place)
	static inline std::string &trim(std::string& s) {
		ltrim(s);
		rtrim(s);
		return s;
	}

	// trim from start (copying)
	static inline std::string ltrim_copy(std::string s) {
		ltrim(s);
		return s;
	}

	// trim from end (copying)
	static inline std::string rtrim_copy(std::string s) {

		rtrim(s);
		return s;
	}

	// trim from both ends (copying)
	static inline std::string trim_copy(std::string s) {
		trim(s);
		return s;
	}

    inline void incrementTimedEventsCounter(void) {
        boost::mutex::scoped_lock amx1(timeeventscounter_mutex);
        timeEventsCounter++;
    }

    inline void decrementTimedEventsCounter(void) {
        boost::mutex::scoped_lock amx1(timeeventscounter_mutex);
        timeEventsCounter--;
    }

    inline long getTimedEventsCounter(void) {
        boost::mutex::scoped_lock amx1(timeeventscounter_mutex);
        return timeEventsCounter;
    }

    unsigned long componentBase[CTYPE_COUNT];
    long componentCounter[CTYPE_COUNT];
    long componentCounter2[CTYPE_COUNT];
    long current_timestep;
    boost::posix_time::ptime startRealTime;

    std::map<long, TimedEvent*> allTimedEvents;
    std::vector<TimedEvent *> timeIntervalEvents[MAX_TIMEINTERVAL_BUFFER_SIZE];

    ComponentDB<Layer> layerDB;
    ComponentDB<Cluster> clusterDB;
    ComponentDB<Column> columnDB;
    ComponentDB<Nucleus> nucleusDB;
    ComponentDB<Region> regionDB;
    ComponentDB<Brain> brainDB;
    ComponentDB<Neuron> neuronDB;
    ComponentDB<Axon> axonDB;
    ComponentDB<Dendrite> dendriteDB;
    ComponentDB<Synapse> synapseDB;

    std::vector<NNComponent *> deletedComponents;

    boost::asio::thread_pool *workers;

    int syncpoint;

    Location3D nullLocation;

    std::ofstream *firefile;
    std::ofstream *firelogfile;
    std::ofstream *debugfile;
    std::ofstream *eventlogfile;
    std::ofstream *structurelogfile;
    std::ofstream *firePatternlogfile;

    bool setLogFiring;
    bool keepWebserverRunning;
    bool logEvents;

    boost::mutex timestep_mutex;
    boost::mutex actionpotential_mutex;
    boost::mutex firingNeurons_mutex;
    boost::mutex timedevents_mutex;
    boost::mutex debug_mutex;
    boost::mutex firingPatterns_mutex;
    boost::mutex stdp_mutex;
    boost::mutex timeeventscounter_mutex;
    boost::mutex batchfire_mutex;

    std::vector <boost::mutex *> teVector_mutex;

    std::string latestOutputTarget;
    unsigned char lastBuffer[28*28];
    Neuron *lastFiredNeuron;
    Brain* brain;

    // New method to apply global homeostasis
    void applyGlobalHomeostasis();
    void applyLocalHomeostasis(std::vector<Neuron *> *neurons);
};





// ============== GlobalBridge.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Global.h"

#include "GlobalBridge.h"

extern Global *globalObject;

bool GlobalBridge::componentKeyInRange(long key)
{
    return globalObject->componentKeyInRange(key);
}

char* GlobalBridge::allocClearedMemory(long bufferSize)
{
    return (char *)globalObject->allocClearedMemory(bufferSize);
}

void GlobalBridge::freeMemory(char *ptr)
{
    globalObject->freeMemory(ptr);
}

void GlobalBridge::log(std::stringstream &ss)
{
    globalObject->log(ss);
}

size_t GlobalBridge::getTypeIndex(std::string  name)
{
    return globalObject->getTypeIndex(name);
}

long GlobalBridge::getComponentBase(size_t index)
{
    return globalObject->componentBase[index];
}

long GlobalBridge::getComponentCounter(size_t index)
{
    return globalObject->componentCounter[index];
}







// ============== GlobalBridge.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <string>


class GlobalBridge
{
    public:
        static bool componentKeyInRange(long key);
        static char*  allocClearedMemory(long bufferSize);
        static void freeMemory(char *ptr);
       	static void log(std::stringstream &ss);

       	static size_t getTypeIndex(std::string  name);
       	static long getComponentBase(size_t index);
       	static long getComponentCounter(size_t index);
};

// ============== HTTPMessage.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "HTTPMessage.h"

#include <algorithm>
#include <cctype>
#include <iterator>
#include <map>
#include <sstream>
#include <stdexcept>
#include <string>
#include <type_traits>
#include <utility>
#include "uri.h"

namespace simple_http_server {

std::string to_string(HttpMethod method) {
  switch (method) {
    case HttpMethod::GET:
      return "GET";
    case HttpMethod::HEAD:
      return "HEAD";
    case HttpMethod::POST:
      return "POST";
    case HttpMethod::PUT:
      return "PUT";
    case HttpMethod::DELETE:
      return "DELETE";
    case HttpMethod::CONNECT:
      return "CONNECT";
    case HttpMethod::OPTIONS:
      return "OPTIONS";
    case HttpMethod::TRACE:
      return "TRACE";
    case HttpMethod::PATCH:
      return "PATCH";
    default:
      return std::string();
  }
}

std::string to_string(HttpVersion version) {
  switch (version) {
    case HttpVersion::HTTP_0_9:
      return "HTTP/0.9";
    case HttpVersion::HTTP_1_0:
      return "HTTP/1.0";
    case HttpVersion::HTTP_1_1:
      return "HTTP/1.1";
    case HttpVersion::HTTP_2_0:
      return "HTTP/2.0";
    default:
      return std::string();
  }
}

std::string to_string(HttpStatusCode status_code) {
  switch (status_code) {
    case HttpStatusCode::Continue:
      return "Continue";
    case HttpStatusCode::Ok:
      return "OK";
    case HttpStatusCode::Accepted:
      return "Accepted";
    case HttpStatusCode::MovedPermanently:
      return "Moved Permanently";
    case HttpStatusCode::Found:
      return "Found";
    case HttpStatusCode::BadRequest:
      return "Bad Request";
    case HttpStatusCode::Forbidden:
      return "Forbidden";
    case HttpStatusCode::NotFound:
      return "Not Found";
    case HttpStatusCode::MethodNotAllowed:
      return "Method Not Allowed";
    case HttpStatusCode::ImATeapot:
      return "I'm a Teapot";
    case HttpStatusCode::InternalServerError:
      return "Internal Server Error";
    case HttpStatusCode::NotImplemented:
      return "Not Implemented";
    case HttpStatusCode::BadGateway:
      return "Bad Gateway";
    default:
      return std::string();
  }
}

HttpMethod string_to_method(const std::string& method_string) {
  std::string method_string_uppercase;
  std::transform(method_string.begin(), method_string.end(),
                 std::back_inserter(method_string_uppercase),
                 [](char c) { return toupper(c); });
  if (method_string_uppercase == "GET") {
    return HttpMethod::GET;
  } else if (method_string_uppercase == "HEAD") {
    return HttpMethod::HEAD;
  } else if (method_string_uppercase == "POST") {
    return HttpMethod::POST;
  } else if (method_string_uppercase == "PUT") {
    return HttpMethod::PUT;
  } else if (method_string_uppercase == "DELETE") {
    return HttpMethod::DELETE;
  } else if (method_string_uppercase == "CONNECT") {
    return HttpMethod::CONNECT;
  } else if (method_string_uppercase == "OPTIONS") {
    return HttpMethod::OPTIONS;
  } else if (method_string_uppercase == "TRACE") {
    return HttpMethod::TRACE;
  } else if (method_string_uppercase == "PATCH") {
    return HttpMethod::PATCH;
  } else {
    throw std::invalid_argument("Unexpected HTTP method");
  }
}

HttpVersion string_to_version(const std::string& version_string) {
  std::string version_string_uppercase;
  std::transform(version_string.begin(), version_string.end(),
                 std::back_inserter(version_string_uppercase),
                 [](char c) { return toupper(c); });
  if (version_string_uppercase == "HTTP/0.9") {
    return HttpVersion::HTTP_0_9;
  } else if (version_string_uppercase == "HTTP/1.0") {
    return HttpVersion::HTTP_1_0;
  } else if (version_string_uppercase == "HTTP/1.1") {
    return HttpVersion::HTTP_1_1;
  } else if (version_string_uppercase == "HTTP/2" ||
             version_string_uppercase == "HTTP/2.0") {
    return HttpVersion::HTTP_2_0;
  } else {
    throw std::invalid_argument("Unexpected HTTP version");
  }
}

std::string to_string(const HttpRequest& request) {
  std::ostringstream oss;

  oss << to_string(request.method()) << ' ';
  oss << request.uri().path() << ' ';
  oss << to_string(request.version()) << "\r\n";
  for (const auto& p : request.headers())
    oss << p.first << ": " << p.second << "\r\n";
  oss << "\r\n";
  oss << request.content();

  return oss.str();
}

std::string to_string(const HttpResponse& response, bool send_content) {
  std::ostringstream oss;

  oss << to_string(response.version()) << ' ';
  oss << static_cast<int>(response.status_code()) << ' ';
  oss << to_string(response.status_code()) << "\r\n";
  for (const auto& p : response.headers())
    oss << p.first << ": " << p.second << "\r\n";
  oss << "\r\n";
  if (send_content) oss << response.content();

  return oss.str();
}

HttpRequest string_to_request(const std::string& request_string) {
  std::string start_line, header_lines, message_body;
  std::istringstream iss;
  HttpRequest request;
  std::string line, method, path, version;  // used for first line
  std::string key, value;                   // used for header fields
  Uri uri;
  size_t lpos = 0, rpos = 0;

  rpos = request_string.find("\r\n", lpos);
  if (rpos == std::string::npos) {
    throw std::invalid_argument("Could not find request start line");
  }

  start_line = request_string.substr(lpos, rpos - lpos);
  lpos = rpos + 2;
  rpos = request_string.find("\r\n\r\n", lpos);
  if (rpos != std::string::npos) {  // has header
    header_lines = request_string.substr(lpos, rpos - lpos);
    lpos = rpos + 4;
    rpos = request_string.length();
    if (lpos < rpos) {
      message_body = request_string.substr(lpos, rpos - lpos);
    }
  }

  iss.clear();  // parse the start line
  iss.str(start_line);
  iss >> method >> path >> version;
  if (!iss.good() && !iss.eof()) {
    throw std::invalid_argument("Invalid start line format");
  }
  request.SetMethod(string_to_method(method));
  request.SetUri(Uri(path));
  if (string_to_version(version) != request.version()) {
    throw std::logic_error("HTTP version not supported");
  }

  iss.clear();  // parse header fields
  iss.str(header_lines);
  while (std::getline(iss, line)) {
    std::istringstream header_stream(line);
    std::getline(header_stream, key, ':');
    std::getline(header_stream, value);

    // remove whitespaces from the two strings
    key.erase(std::remove_if(key.begin(), key.end(),
                             [](char c) { return std::isspace(c); }),
              key.end());
    value.erase(std::remove_if(value.begin(), value.end(),
                               [](char c) { return std::isspace(c); }),
                value.end());
    request.SetHeader(key, value);
  }

  request.SetContent(message_body);

  return request;
}

HttpResponse string_to_response(const std::string& response_string) {
  (void)response_string;
  throw std::logic_error("Method not implemented");
}

}  // namespace simple_http_server

// ============== HTTPMessage.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

// Defines objects that represents HTTP request and response
// and some utility functions to manipulate HTTP data

#ifndef HTTPMESSAGE_H_
#define HTTPMESSAGE_H_

#include <map>
#include <string>
#include <utility>


#include "uri.h"

namespace simple_http_server {

// HTTP methods defined in the following document:
// https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods
enum class HttpMethod {
  GET,
  HEAD,
  POST,
  PUT,
  DELETE,
  CONNECT,
  OPTIONS,
  TRACE,
  PATCH
};

// Here we only support HTTP/1.1
enum class HttpVersion {
  HTTP_0_9 = 9,
  HTTP_1_0 = 10,
  HTTP_1_1 = 11,
  HTTP_2_0 = 20
};

// HTTP response status codes as listed in:
// https://developer.mozilla.org/en-US/docs/Web/HTTP/Status
// Note that not all of them are present in this enum class
enum class HttpStatusCode {
  Continue = 100,
  SwitchingProtocols = 101,
  EarlyHints = 103,
  Ok = 200,
  Created = 201,
  Accepted = 202,
  NonAuthoritativeInformation = 203,
  NoContent = 204,
  ResetContent = 205,
  PartialContent = 206,
  MultipleChoices = 300,
  MovedPermanently = 301,
  Found = 302,
  NotModified = 304,
  BadRequest = 400,
  Unauthorized = 401,
  Forbidden = 403,
  NotFound = 404,
  MethodNotAllowed = 405,
  RequestTimeout = 408,
  ImATeapot = 418,
  InternalServerError = 500,
  NotImplemented = 501,
  BadGateway = 502,
  ServiceUnvailable = 503,
  GatewayTimeout = 504,
  HttpVersionNotSupported = 505
};

// Utility functions to convert between string or integer to enum classes
std::string to_string(HttpMethod method);
std::string to_string(HttpVersion version);
std::string to_string(HttpStatusCode status_code);
HttpMethod string_to_method(const std::string& method_string);
HttpVersion string_to_version(const std::string& version_string);

// Defines the common interface of an HTTP request and HTTP response.
// Each message will have an HTTP version, collection of header fields,
// and message content. The collection of headers and content can be empty.
class HttpMessageInterface {
 public:
  HttpMessageInterface() : version_(HttpVersion::HTTP_1_1) {}
  virtual ~HttpMessageInterface() = default;

  void SetHeader(const std::string& key, const std::string& value) {
    headers_[key] = std::move(value);
  }
  void RemoveHeader(const std::string& key) { headers_.erase(key); }
  void ClearHeader() { headers_.clear(); }
  void SetContent(const std::string& content) {
    content_ = std::move(content);
    SetContentLength();
  }
  void ClearContent(const std::string& content) {
    (void)content;
    content_.clear();
    SetContentLength();
  }

  HttpVersion version() const { return version_; }
  std::string header(const std::string& key) const {
    if (headers_.count(key) > 0) return headers_.at(key);
    return std::string();
  }
  std::map<std::string, std::string> headers() const { return headers_; }
  std::string content() const { return content_; }
  size_t content_length() const { return content_.length(); }

 protected:
  HttpVersion version_;
  std::map<std::string, std::string> headers_;
  std::string content_;

  void SetContentLength() {
    SetHeader("Content-Length", std::to_string(content_.length()));
  }
};

// An HttpRequest object represents a single HTTP request
// It has a HTTP method and URI so that the server can identify
// the corresponding resource and action
class HttpRequest : public HttpMessageInterface {
 public:
  HttpRequest() : method_(HttpMethod::GET) {}
  ~HttpRequest() = default;

  void SetMethod(HttpMethod method) { method_ = method; }
  void SetUri(const Uri& uri) { uri_ = std::move(uri); }

  HttpMethod method() const { return method_; }
  Uri uri() const { return uri_; }

  friend std::string to_string(const HttpRequest& request);
  friend HttpRequest string_to_request(const std::string& request_string);

 private:
  HttpMethod method_;
  Uri uri_;
};

// An HTTPResponse object represents a single HTTP response
// The HTTP server sends an HTTP response to a client that include
// an HTTP status code, headers, and (optional) content
class HttpResponse : public HttpMessageInterface {
 public:
  HttpResponse() : status_code_(HttpStatusCode::Ok) {}
  HttpResponse(HttpStatusCode status_code) : status_code_(status_code) {}
  ~HttpResponse() = default;

  void SetStatusCode(HttpStatusCode status_code) { status_code_ = status_code; }

  HttpStatusCode status_code() const { return status_code_; }

  friend std::string to_string(const HttpResponse& request, bool send_content);
  friend HttpResponse string_to_response(const std::string& response_string);

 private:
  HttpStatusCode status_code_;
};

// Utility functions to convert HTTP message objects to string and vice versa
std::string to_string(const HttpRequest& request);
std::string to_string(const HttpResponse& response, bool send_content = true);
HttpRequest string_to_request(const std::string& request_string);
HttpResponse string_to_response(const std::string& response_string);

}  // namespace simple_http_server

#endif  // HTTPMESSAGE_H_

// ============== HTTPServer.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "HTTPServer.h"

#include <arpa/inet.h>
#include <sys/epoll.h>
#include <sys/socket.h>
#include <sys/types.h>
#include <unistd.h>

#include <cerrno>
#include <chrono>
#include <cstring>
#include <functional>
#include <map>
#include <sstream>
#include <stdexcept>
#include <string>

#include "HTTPMessage.h"
#include "uri.h"

namespace simple_http_server {

HttpServer::HttpServer(const std::string &host, std::uint16_t port)
    : host_(host),
      port_(port),
      sock_fd_(0),
      running_(false),
      worker_epoll_fd_(),
      rng_(std::chrono::steady_clock::now().time_since_epoch().count()),
      sleep_times_(10, 100) {
  CreateSocket();
}

void HttpServer::Start() {
  int opt = 1;
  sockaddr_in server_address;

  if (setsockopt(sock_fd_, SOL_SOCKET, SO_REUSEADDR | SO_REUSEPORT, &opt,
                 sizeof(opt)) < 0) {
    throw std::runtime_error("Failed to set socket options");
  }

  server_address.sin_family = AF_INET;
  server_address.sin_addr.s_addr = INADDR_ANY;
  inet_pton(AF_INET, host_.c_str(), &(server_address.sin_addr.s_addr));
  server_address.sin_port = htons(port_);

  if (bind(sock_fd_, (sockaddr *)&server_address, sizeof(server_address)) < 0) {
    throw std::runtime_error("Failed to bind to socket");
  }

  if (listen(sock_fd_, kBacklogSize) < 0) {
    std::ostringstream msg;
    msg << "Failed to listen on port " << port_;
    throw std::runtime_error(msg.str());
  }

  SetUpEpoll();
  running_ = true;
  listener_thread_ = std::thread(&HttpServer::Listen, this);
  for (int i = 0; i < kThreadPoolSize; i++) {
    worker_threads_[i] = std::thread(&HttpServer::ProcessEvents, this, i);
  }
}

void HttpServer::Stop() {
  running_ = false;
  listener_thread_.join();
  for (int i = 0; i < kThreadPoolSize; i++) {
    worker_threads_[i].join();
  }
  for (int i = 0; i < kThreadPoolSize; i++) {
    close(worker_epoll_fd_[i]);
  }
  close(sock_fd_);
}

void HttpServer::CreateSocket() {
  if ((sock_fd_ = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0)) < 0) {
    throw std::runtime_error("Failed to create a TCP socket");
  }
}

void HttpServer::SetUpEpoll() {
  for (int i = 0; i < kThreadPoolSize; i++) {
    if ((worker_epoll_fd_[i] = epoll_create1(0)) < 0) {
      throw std::runtime_error(
          "Failed to create epoll file descriptor for worker");
    }
  }
}

void HttpServer::Listen() {
  EventData *client_data;
  sockaddr_in client_address;
  socklen_t client_len = sizeof(client_address);
  int client_fd;
  int current_worker = 0;
  bool active = true;

  // accept new connections and distribute tasks to worker threads
  while (running_) {
    if (!active) {
      std::this_thread::sleep_for(
          std::chrono::microseconds(sleep_times_(rng_)));
    }
    client_fd = accept4(sock_fd_, (sockaddr *)&client_address, &client_len,
                        SOCK_NONBLOCK);
    if (client_fd < 0) {
      active = false;
      continue;
    }

    active = true;
    client_data = new EventData();
    client_data->fd = client_fd;
    control_epoll_event(worker_epoll_fd_[current_worker], EPOLL_CTL_ADD,
                        client_fd, EPOLLIN, client_data);
    current_worker++;
    if (current_worker == HttpServer::kThreadPoolSize) current_worker = 0;
  }
}

void HttpServer::ProcessEvents(int worker_id) {
  EventData *data;
  int epoll_fd = worker_epoll_fd_[worker_id];
  bool active = true;

  while (running_) {
    if (!active) {
      std::this_thread::sleep_for(
          std::chrono::microseconds(sleep_times_(rng_)));
    }
    int nfds = epoll_wait(worker_epoll_fd_[worker_id],
                          worker_events_[worker_id], HttpServer::kMaxEvents, 0);
    if (nfds <= 0) {
      active = false;
      continue;
    }

    active = true;
    for (int i = 0; i < nfds; i++) {
      const epoll_event &current_event = worker_events_[worker_id][i];
      data = reinterpret_cast<EventData *>(current_event.data.ptr);
      if ((current_event.events & EPOLLHUP) ||
          (current_event.events & EPOLLERR)) {
        control_epoll_event(epoll_fd, EPOLL_CTL_DEL, data->fd);
        close(data->fd);
        delete data;
      } else if ((current_event.events == EPOLLIN) ||
                 (current_event.events == EPOLLOUT)) {
        HandleEpollEvent(epoll_fd, data, current_event.events);
      } else {  // something unexpected
        control_epoll_event(epoll_fd, EPOLL_CTL_DEL, data->fd);
        close(data->fd);
        delete data;
      }
    }
  }
}

void HttpServer::HandleEpollEvent(int epoll_fd, EventData *data,
                                  std::uint32_t events) {
  int fd = data->fd;
  EventData *request, *response;

  if (events == EPOLLIN) {
    request = data;
    ssize_t byte_count = recv(fd, request->buffer, kMaxBufferSize, 0);
    if (byte_count > 0) {  // we have fully received the message
      response = new EventData();
      response->fd = fd;
      HandleHttpData(*request, response);
      control_epoll_event(epoll_fd, EPOLL_CTL_MOD, fd, EPOLLOUT, response);
      delete request;
    } else if (byte_count == 0) {  // client has closed connection
      control_epoll_event(epoll_fd, EPOLL_CTL_DEL, fd);
      close(fd);
      delete request;
    } else {
      if (errno == EAGAIN || errno == EWOULDBLOCK) {  // retry
        request->fd = fd;
        control_epoll_event(epoll_fd, EPOLL_CTL_MOD, fd, EPOLLIN, request);
      } else {  // other error
        control_epoll_event(epoll_fd, EPOLL_CTL_DEL, fd);
        close(fd);
        delete request;
      }
    }
  } else {
    response = data;
    ssize_t byte_count = send(fd, response->buffer + response->cursor, response->length, 0);

    if (byte_count >= (ssize_t)0) {
      if (byte_count < (ssize_t)response->length) {  // there are still bytes to write
        response->cursor += byte_count;
        response->length -= byte_count;
        control_epoll_event(epoll_fd, EPOLL_CTL_MOD, fd, EPOLLOUT, response);
      } else {  // we have written the complete message
        request = new EventData();
        request->fd = fd;
        control_epoll_event(epoll_fd, EPOLL_CTL_MOD, fd, EPOLLIN, request);
        delete response;
      }
    } else {
      if (errno == EAGAIN || errno == EWOULDBLOCK) {  // retry
        control_epoll_event(epoll_fd, EPOLL_CTL_ADD, fd, EPOLLOUT, response);
      } else {  // other error
        control_epoll_event(epoll_fd, EPOLL_CTL_DEL, fd);
        close(fd);
        delete response;
      }
    }
  }
}

void HttpServer::HandleHttpData(const EventData &raw_request,
                                EventData *raw_response) {
  std::string request_string(raw_request.buffer), response_string;
  HttpRequest http_request;
  HttpResponse http_response;

  try {
    http_request = string_to_request(request_string);

    // At this point, the request has the parsed request from the client.
    // http_request.simple_http_server::HttpMessageInterface.headers_ contains the list of headers
    // http_request.simple_http_server::HttpMessageInterface.content_ contains the JSON payload
    // http_request.method_ is simple_http_server::HttpMethod::POST
    // http_request.path_ is the uri (eg /api/data )
    
    http_response = HandleHttpRequest(http_request);
  } catch (const std::invalid_argument &e) {
    http_response = HttpResponse(HttpStatusCode::BadRequest);
    http_response.SetContent(e.what());
  } catch (const std::logic_error &e) {
    http_response = HttpResponse(HttpStatusCode::HttpVersionNotSupported);
    http_response.SetContent(e.what());
  } catch (const std::exception &e) {
    http_response = HttpResponse(HttpStatusCode::InternalServerError);
    http_response.SetContent(e.what());
  }

  // Set response to write to client
  response_string =
      to_string(http_response, http_request.method() != HttpMethod::HEAD);
  memcpy(raw_response->buffer, response_string.c_str(), response_string.length());
  raw_response->length = response_string.length();
}

HttpResponse HttpServer::HandleHttpRequest(const HttpRequest &request) {
  auto it = request_handlers_.find(request.uri());
  if (it == request_handlers_.end()) {  // this uri is not registered
    return HttpResponse(HttpStatusCode::NotFound);
  }
  auto callback_it = it->second.find(request.method());
  if (callback_it == it->second.end()) {  // no handler for this method
    return HttpResponse(HttpStatusCode::MethodNotAllowed);
  }
  return callback_it->second(request);  // call handler to process the request
}

void HttpServer::control_epoll_event(int epoll_fd, int op, int fd,
                                     std::uint32_t events, void *data) {
  if (op == EPOLL_CTL_DEL) {
    if (epoll_ctl(epoll_fd, op, fd, nullptr) < 0) {
      throw std::runtime_error("Failed to remove file descriptor");
    }
  } else {
    epoll_event ev;
    ev.events = events;
    ev.data.ptr = data;
    if (epoll_ctl(epoll_fd, op, fd, &ev) < 0) {
      throw std::runtime_error("Failed to add file descriptor");
    }
  }
}

}  // namespace simple_http_server

// ============== HTTPServer.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

// Defines the HTTP server object with some constants and structs
// useful for request handling and improving performance

#ifndef HTTPSERVER_H_
#define HTTPSERVER_H_

#include <sys/epoll.h>
#include <sys/socket.h>
#include <sys/types.h>

#include <chrono>
#include <functional>
#include <map>
#include <random>
#include <string>
#include <thread>
#include <utility>

#include "HTTPMessage.h"
#include "uri.h"

namespace simple_http_server {

// Maximum size of an HTTP message is limited by how much bytes
// we can read or send via socket each time
#define MEGABYTE 1024*1024;
constexpr size_t kMaxBufferSize = 100 * MEGABYTE; // 100MB

struct EventData {
  EventData() : fd(0), length(0), cursor(0), buffer() {}
  int fd;
  size_t length;
  size_t cursor;
  char buffer[kMaxBufferSize];
};

// A request handler should expect a request as argument and returns a response
using HttpRequestHandler_t = std::function<HttpResponse(const HttpRequest&)>;

// The server consists of:
// - 1 main thread
// - 1 listener thread that is responsible for accepting new connections
// - Possibly many threads that process HTTP messages and communicate with
// clients via socket.
//   The number of workers is defined by a constant
class HttpServer {
 public:
  explicit HttpServer(const std::string& host, std::uint16_t port);
  ~HttpServer() = default;

  HttpServer() = default;
  HttpServer(HttpServer&&) = default;
  HttpServer& operator=(HttpServer&&) = default;

  void Start();
  void Stop();
  void RegisterHttpRequestHandler(const std::string& path, HttpMethod method,
                                  const HttpRequestHandler_t callback) {
    Uri uri(path);
    request_handlers_[uri].insert(std::make_pair(method, std::move(callback)));
  }
  void RegisterHttpRequestHandler(const Uri& uri, HttpMethod method,
                                  const HttpRequestHandler_t callback) {
    request_handlers_[uri].insert(std::make_pair(method, std::move(callback)));
  }

  std::string host() const { return host_; }
  std::uint16_t port() const { return port_; }
  bool running() const { return running_; }

 private:
  static constexpr int kBacklogSize = 1000;
  static constexpr int kMaxConnections = 10000;
  static constexpr int kMaxEvents = 10000;
  static constexpr int kThreadPoolSize = 5;

  std::string host_;
  std::uint16_t port_;
  int sock_fd_;
  bool running_;
  std::thread listener_thread_;
  std::thread worker_threads_[kThreadPoolSize];
  int worker_epoll_fd_[kThreadPoolSize];
  epoll_event worker_events_[kThreadPoolSize][kMaxEvents];
  std::map<Uri, std::map<HttpMethod, HttpRequestHandler_t>> request_handlers_;
  std::mt19937 rng_;
  std::uniform_int_distribution<int> sleep_times_;

  void CreateSocket();
  void SetUpEpoll();
  void Listen();
  void ProcessEvents(int worker_id);
  void HandleEpollEvent(int epoll_fd, EventData* event, std::uint32_t events);
  void HandleHttpData(const EventData& request, EventData* response);
  HttpResponse HandleHttpRequest(const HttpRequest& request);

  void control_epoll_event(int epoll_fd, int op, int fd,
                           std::uint32_t events = 0, void* data = nullptr);
};

}  // namespace simple_http_server

#endif  // HTTPSERVER_H_

// ============== HTTPServerMain.cpp ==============
/*
 * Proprietary License
 *
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 *
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 *
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "HTTPServerMain.h"


// Settable externs
extern long FIRING_WINDOW;
extern long PROPAGATION_DELAY_MICROSECONDS;
extern double DECAY_FACTOR;
extern long REFACTORY_PERIOD;
extern float WEIGHT_GRADATION;
extern float RATE_GRADATION;

unsigned char bitmapper[8] = {128, 64, 32, 16, 8, 4, 2, 1};
// unsigned char andbitmapper[8] = {127, 191, 223, 239, 247, 251, 253, 254};

typedef unsigned char BYTE;

static const std::string base64_chars =
    "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    "abcdefghijklmnopqrstuvwxyz"
    "0123456789+/";

int randomFireCount = 0;


static inline bool is_base64(BYTE c)
{
  return (isalnum(c) || (c == '+') || (c == '/'));
}

std::string base64_encoder(BYTE const *buf, unsigned int bufLen)
{
  std::string ret;
  int i = 0;
  int j = 0;
  BYTE char_array_3[3];
  BYTE char_array_4[4];

  while (bufLen--)
  {
    char_array_3[i++] = *(buf++);
    if (i == 3)
    {
      char_array_4[0] = (char_array_3[0] & 0xfc) >> 2;
      char_array_4[1] = ((char_array_3[0] & 0x03) << 4) + ((char_array_3[1] & 0xf0) >> 4);
      char_array_4[2] = ((char_array_3[1] & 0x0f) << 2) + ((char_array_3[2] & 0xc0) >> 6);
      char_array_4[3] = char_array_3[2] & 0x3f;

      for (i = 0; (i < 4); i++)
        ret += base64_chars[char_array_4[i]];
      i = 0;
    }
  }

  if (i)
  {
    for (j = i; j < 3; j++)
      char_array_3[j] = '\0';

    char_array_4[0] = (char_array_3[0] & 0xfc) >> 2;
    char_array_4[1] = ((char_array_3[0] & 0x03) << 4) + ((char_array_3[1] & 0xf0) >> 4);
    char_array_4[2] = ((char_array_3[1] & 0x0f) << 2) + ((char_array_3[2] & 0xc0) >> 6);
    char_array_4[3] = char_array_3[2] & 0x3f;

    for (j = 0; (j < i + 1); j++)
      ret += base64_chars[char_array_4[j]];

    while ((i++ < 3))
      ret += '=';
  }

  return ret;
}

std::vector<BYTE> base64_decoder(std::string const &encoded_string)
{
  int in_len = encoded_string.size();
  int i = 0;
  int j = 0;
  int in_ = 0;
  BYTE char_array_4[4], char_array_3[3];
  std::vector<BYTE> ret;

  while (in_len-- && (encoded_string[in_] != '=') && is_base64(encoded_string[in_]))
  {
    char_array_4[i++] = encoded_string[in_];
    in_++;
    if (i == 4)
    {
      for (i = 0; i < 4; i++)
        char_array_4[i] = base64_chars.find(char_array_4[i]);

      char_array_3[0] = (char_array_4[0] << 2) + ((char_array_4[1] & 0x30) >> 4);
      char_array_3[1] = ((char_array_4[1] & 0xf) << 4) + ((char_array_4[2] & 0x3c) >> 2);
      char_array_3[2] = ((char_array_4[2] & 0x3) << 6) + char_array_4[3];

      for (i = 0; (i < 3); i++)
        ret.push_back(char_array_3[i]);
      i = 0;
    }
  }

  if (i)
  {
    for (j = i; j < 4; j++)
      char_array_4[j] = 0;

    for (j = 0; j < 4; j++)
      char_array_4[j] = base64_chars.find(char_array_4[j]);

    char_array_3[0] = (char_array_4[0] << 2) + ((char_array_4[1] & 0x30) >> 4);
    char_array_3[1] = ((char_array_4[1] & 0xf) << 4) + ((char_array_4[2] & 0x3c) >> 2);
    char_array_3[2] = ((char_array_4[2] & 0x3) << 6) + char_array_4[3];

    for (j = 0; (j < i - 1); j++)
      ret.push_back(char_array_3[j]);
  }

  return ret;
}

long setActivationPatternCount = 0;

std::string base64_encode(unsigned char const *bytes_to_encode, size_t in_len)
{

  const BYTE *buf = bytes_to_encode;
  unsigned int buflen = (unsigned int)in_len;
  std::string result;
  result = base64_encoder(buf, buflen);
  return result;
}

unsigned char *base64_decode(std::string const &encoded_string, size_t *out_len)
{
  const std::string s = encoded_string;

  std::vector<BYTE> result = base64_decoder(s);
  unsigned char *ret = (unsigned char *)calloc(1, result.size());
  size_t resultsSize = result.size();
  for (size_t i = 0; i < resultsSize; i++)
  {
    ret[i] = result[i];
  }
  *out_len = resultsSize;
  return ret;
}

void ensure_enough_resource(int resource, std::uint32_t soft_limit,
                            std::uint32_t hard_limit)
{
  rlimit new_limit, old_limit;

  new_limit.rlim_cur = soft_limit;
  new_limit.rlim_max = hard_limit;
  getrlimit(resource, &old_limit);

  std::cout << "Old limit: " << old_limit.rlim_cur << " (soft limit), "
            << old_limit.rlim_cur << " (hard limit)." << std::endl;
  std::cout << "New limit: " << new_limit.rlim_cur << " (soft limit), "
            << new_limit.rlim_cur << " (hard limit)." << std::endl;

  if (setrlimit(resource, &new_limit))
  {
    std::cerr << "Warning: Could not update resource limit ";
    std::cerr << "(" << strerror(errno) << ")." << std::endl;
    std::cerr << "Consider setting the limit manually with ulimit" << std::endl;
    exit(-1);
  }
}

size_t min(size_t a, size_t b)
{
  return (a < b) ? a : b;
}

// Function to convert the grayscale pixel value to an ASCII character
char pixelToAscii(unsigned char pixelValue)
{
  // Expanded set of ASCII characters for 50 levels of brightness
  const char *asciiChars = " .`'^\",-~:;_+=<>i!lI?/\\|()1{}[]rctvzXYUJCLQ0OZmwqpdbkhao*#MW&8%B@$";
  int numLevels = 50; // Number of levels of brightness represented by ASCII chars

  // Map the pixel value (0-255) to an index in the ASCII character array (0-49)
  int index = (pixelValue * (numLevels - 1)) / 255;
  return asciiChars[index];
}

// Function to display the 28x28 grayscale image buffer as ASCII art
void displayAsciiImage(unsigned char *tempBuffer)
{
  if (!tempBuffer)
  {
    std::cerr << "Error: Buffer is null." << std::endl;
    return;
  }

  std::stringstream pattern;
  for (int row = 0; row < 28; ++row)
  {
    for (int col = 0; col < 28; ++col)
    {
      // Get the pixel value from the buffer
      unsigned char pixelValue = tempBuffer[row * 28 + col];
      // Convert the pixel value to an ASCII character and print it
      pattern << pixelToAscii(pixelValue);
    }
    // Move to the next line after printing each row
    pattern << std::endl;
  }

  globalObject->lastImageString = pattern.str().c_str();
  globalObject->writeFirePatternLog(globalObject->lastImageString);
}

std::string parseAndRespond(std::string content)
{
  (void)content;
  // get number of APs

  std::stringstream response;

  // size_t apCount = 0;
  // for (typename std::map<long, TimedEvent*>::iterator timedEventIterator = globalObject->allTimedEvents.begin(); timedEventIterator != globalObject->allTimedEvents.end(); ++timedEventIterator)
  //{
  // TimedEvent* te = timedEventIterator->second;
  // ActionPotential *ap = te->ap;
  //      apCount++;
  //}

  //	std::vector<TimedEvent*>* teVector = globalObject->getTimedEventCollection();

  response << "<h2>Timed Events</h2>";

  response << "<p>" << globalObject->allTimedEvents.size() << " total timed events" << "<p>";

  for (size_t i = 0; i < MAX_TIMEINTERVAL_BUFFER_SIZE; i++)
  {
    size_t intervalOffsetValue = (globalObject->getCurrentTimestamp() + i) % MAX_TIMEINTERVAL_BUFFER_SIZE;
    std::vector<TimedEvent *> *teVector = &globalObject->timeIntervalEvents[intervalOffsetValue];
    long sz = teVector->size();

    if (sz > 0)
      response << "<p>Interval " << i << ": " << sz << "<p>";
  }

  return response.str();
}

std::string bitsToString(unsigned char *buffer, long numbits)
{
  std::string result;
  for (size_t index = 0; index < (size_t)numbits; index++)
  {
    size_t byteIndex = index / 8;
    size_t bitIndex = index % 8;
    unsigned char thisbyte = buffer[byteIndex] & bitmapper[bitIndex];
    if (thisbyte == '\0')
      result += "0";
    else
      result += "1";
  }

  return result;
}

std::string parseAndRespondJSON(std::string content)
{

  //  std::cout << content << std::endl;

  nlohmann::json jsonObject = nlohmann::json::parse(content);

  std::string command = jsonObject["command"];

  int returnCode = 999;
  std::string returnMessage = "Unknown command received: " + command;

  if (!command.empty())
  {
    if (boost::iequals(command, "GETNEURONS"))
    {
      //
      returnCode = 998;
      returnMessage = "command not currently implemented: " + command;
    }
    else if (boost::iequals(command, "SETACTIVATION"))
    {
      //
      returnCode = 998;
      returnMessage = "command not currently implemented: " + command;
    }
    else if (boost::iequals(command, "GETACTIVATION"))
    {
      //
      returnCode = 998;
      returnMessage = "command not currently implemented: " + command;
    }
    else if (boost::iequals(command, "GETACTIVENEURONS"))
    {
      //
      returnCode = 998;
      returnMessage = "command not currently implemented: " + command;
    }
    else if (boost::iequals(command, "STARTEVENTLOG"))
    {
      //
      globalObject->logEvents = true;
      returnCode = 0;
      returnMessage = "EVENT LOGGING ON ";

      std::string returnString("");
      returnString += "\", \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "STOPEVENTLOG"))
    {
      //
      globalObject->closeEventLog();
      globalObject->logEvents = false;
      returnCode = 0;
      returnMessage = "EVENT LOGGING OFF ";

      std::string returnString("");
      returnString += "\", \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "LOGRESPONSEON"))
    {
      //
      globalObject->closeEventLog();
      globalObject->logResponseMode = true;
      returnCode = 0;
      returnMessage = "LOGRESPONSE ON ";

      std::string returnString("");
      returnString += "\", \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "LOGRESPONSEOFF"))
    {
      //
      globalObject->closeEventLog();
      globalObject->logResponseMode = false;
      returnCode = 0;
      returnMessage = "LOGRESPONSE OFF ";

      std::string returnString("");
      returnString += "\", \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "GETTESTRESPONSE"))
    {

      // globalObject->logResponseMode = true;

      auto nuclei = jsonObject["nuclei"];
      if (nuclei.is_array())
      {
        auto inputElement = nuclei[0];
        auto outputElement = nuclei[1];

        std::string inputNucleus = inputElement["nucleusin"];
        std::string inputPattern = inputElement["pattern"];

        std::string outputNucleus = outputElement["nucleusout"];

        std::vector<long> neurons = Server::getNeurons(inputNucleus, LayerType::input); // Layer 1 = input
        size_t totalSize = neurons.size();

        size_t tempBufferSize = 0;
        unsigned char *tempBuffer = base64_decode(inputPattern, &tempBufferSize);

        if(tempBufferSize == (28*28)) {
          displayAsciiImage(tempBuffer);
          memcpy(globalObject->lastBuffer,tempBuffer,28*28);
        }

        size_t numbits = min(totalSize, tempBufferSize * 8);

        std::vector<Neuron *> firingNeurons;
        // We now have the vector of neurons to update and the bit pattern to update them with
        for (int i = 0; i < (int)numbits; i++)
        {
          int byteindex = i / 8;
          int bitindex = i % 8; // get the modulus
          long neuronId = neurons[i];
          Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);

          unsigned char value = *(tempBuffer + byteindex); // get value of byte
          value &= bitmapper[bitindex];

          if (value != 0)
          { // Turn on firing
            // neuron->potential=1.0; // GETTESTRESPONSE is always 1
            // neuron->fire();
            firingNeurons.push_back(neuron);
          }
        }

        // std::string thispattern = bitsToString(tempBuffer, numbits);
        //        std::string thispattern = convertToBinaryString(tempBuffer, tempBufferSize);

        //        std::cout << inputNucleus << " pattern: " << thispattern << std::endl;

        //
        free(tempBuffer);

        long defaultWait = 1020;
        Range offset = globalObject->batchFire(&firingNeurons, defaultWait);
        long lowestOffset = offset.low;
        long highestOffset = offset.high;
        long startTimer = globalObject->getCurrentTimestamp();

        long delay = PROPAGATION_DELAY_MICROSECONDS;
        if (highestOffset < delay && highestOffset > 0)
          delay = highestOffset;

        if (delay > MAX_TIMEINTERVAL_OFFSET)
          delay = MAX_TIMEINTERVAL_OFFSET;

        long endTimer = startTimer + delay + PROPAGATION_DELAY_MICROSECONDS;
        // globalObject->cycleNeurons(); // cycle through all neurons a if potiential > threshold, fire the neurons

        /*
                while(globalObject->getCurrentTimestamp() < endTimer)
                {
        //          std::cout << "delay current: " << glofiringNeuronsbalObject->getCurrentTimestamp() << ", till: " << endTimer << std::endl;
                  usleep(10); // 20ms delay to allow for ap propagation
                }
        */
        // we have fired the stimulus. Lets give a few ms to allow the APs to propagate.
         //usleep(delay + PROPAGATION_DELAY_MICROSECONDS); // 5ms which is half the refactor period

        // Now lets return the results from the output neurons

        // std::string pattern("");
        std::string nucleus = outputNucleus;
        if (nucleus.empty())
        {
          returnCode = 500; // invalid object reference
          returnMessage = "invalid object reference";
          std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
          return returnString;
        }

        int totalFirings = 0;
        float highestWeight = -65.0f;
        Neuron *highestNeuron = NULL;
        neurons = Server::getNeurons(nucleus, LayerType::output); //  output
        totalSize = neurons.size();

        tempBufferSize = totalSize / 8 + 1;

        tempBuffer = (unsigned char *)calloc(1, tempBufferSize);


        // wait for the first neuron firing, or 
        long endTime = startTimer+ delay + PROPAGATION_DELAY_MICROSECONDS;
        bool didFire = false;
        long ct = globalObject->getCurrentTimestamp();
        // wait for a response
        endTime +=25; // wait max of 0.025 seconds times as longer than expected
        bool done=false;
        while (!done)
        {
          for (size_t i = 0; i < totalSize; i++)
          {
            if(!didFire)
            {
              ct = globalObject->getCurrentTimestamp();
              long neuronId = neurons[i];
              Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
              if (neuron->isFiring(FIRING_WINDOW))
              {
//                std::cout << "Neuron " << neuron->id << " firing after " << (ct - startTimer) << "ms" << std::endl;
                didFire = true;
              }
            }
            else
            {
              break;
            }
          }
          if(ct >= endTime || didFire)
            done = true;
          else 
            usleep(25);
        }
/*
        if(!didFire) {
          long ct = globalObject->getCurrentTimestamp();
          std::cout << "Giving up waiting on firing after " << (ct - startTimer) << "ms" << std::endl;
          std::cout << "StarTimer: " << startTimer << "ms" << " Current Time:" << ct << " EndTime: " << endTime << std::endl;
        }
*/

        for (size_t i = 0; i < totalSize; i++)
        {
          long neuronId = neurons[i];
          Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
          int byteindex = i / 8;
          int bitindex = i % 8; // get the modulus

          if (neuron != NULL)
          {
            if (neuron->isFiring(FIRING_WINDOW)) // Allow for a 10 ms window to be considered "firing"
            {
              totalFirings++;
              tempBuffer[byteindex] = tempBuffer[byteindex] | bitmapper[bitindex];
            }
          }
        }
        //        }
        // tempBuffer now contains the activations in binary (on bit indicates neuron is firing)

        // printf("Response: %s\n",convertBitmapToString(tempBuffer,totalSize).c_str());
        // convert the buffer into a base64 string

        // thispattern = bitsToString(tempBuffer, totalSize);

        // std::cout << outputNucleus << " pattern: " << thispattern << std::endl;

        std::string encoded = base64_encode(tempBuffer, tempBufferSize);
        // release the tempbuffer
        free(tempBuffer);

        // format the return json string

        std::stringstream st;

        st << "SUCCESS TotalFirings = " << totalFirings;

        returnCode = 0;
        returnMessage = st.str();

        //        if (totalFirings > 0)
        //          printf("Total Firings = %d\n", totalFirings);

        std::string returnString("{ \"pattern\": \"");
        returnString += encoded;
        returnString += "\", \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
        // printf("%s\n",returnString.c_str());
        return returnString;
      }
      else
      {
        returnCode = 997;
        returnMessage = "nuclei missing: " + command;
        std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
        // printf("%s\n",returnString.c_str());
        return returnString;
      }
    }
    else if (boost::iequals(command, "SETACTIVATIONPATTERN"))
    {

      globalObject->logResponseMode = false;

      setActivationPatternCount++;
      //      printf("SETACTIVATIONPATTERN %d\r",setActivationPatternCount);
      // std::cout << "SETACTIVATIONPATTERN " << setActivationPatternCount << std::endl;

      //      int retryCount = 0;
      std::vector<Neuron *> firingNeurons;
      std::vector<Neuron *> inputFiringNeurons;
      std::vector<Neuron *> outputFiringNeurons;
      std::string nucleusName;

      // bool firing = false;
      //       while (!firing && retryCount < 100)
      //       {
      firingNeurons.clear();
      inputFiringNeurons.clear();
      outputFiringNeurons.clear();
      auto nuclei = jsonObject["nuclei"];
      if (nuclei.is_array())
      {
        int nucleusIndex = 0;
        for (const auto &element : nuclei)
        {

          std::string nucleus = element["nucleus"];
          nucleusName = nucleus;

          // printf("processing nucleus %s\n", nucleus.c_str());

          std::string pattern = element["pattern"];

          std::vector<long> neurons;
          if (nucleusIndex == 0)
            neurons = Server::getNeurons(nucleus, LayerType::input); // Layer input
          else
            neurons = Server::getNeurons(nucleus, LayerType::output); // Layer output

          size_t totalSize = neurons.size();

          size_t tempBufferSize = 0;
          unsigned char *tempBuffer = base64_decode(pattern, &tempBufferSize);

          size_t numbits = min(totalSize, tempBufferSize * 8);

          if (nucleusIndex == 0) {
            displayAsciiImage(tempBuffer);
            memcpy(globalObject->lastBuffer,tempBuffer,28*28);
          }

          //          std::string thispattern = bitsToString(tempBuffer, numbits);

          //          std::cout << nucleus << " pattern: " << thispattern << std::endl;

          // We now have the vector of neurons to update and the bit pattern to update them with
          std::string outString;
          for (int i = 0; i < (int)numbits; i++)
          {
            int byteindex = i / 8;
            int bitindex = i % 8; // get the modulus
            long neuronId = neurons[i];
            Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);

            unsigned char value = tempBuffer[byteindex]; // get value of byte
            value = value & bitmapper[bitindex];

            if (value != 0)
            { // Turn on firing
              firingNeurons.push_back(neuron);

              if (nucleusIndex == 0) // input
              {
                inputFiringNeurons.push_back(neuron);
              }
              else
              { // output
                outString += "1";
                outputFiringNeurons.push_back(neuron);
              }
            }
            else
            {
              if (nucleusIndex != 0) // input
              {
                outString += "0";
              }
            }
          }

          globalObject->latestOutputTarget = outString;

          //
          free(tempBuffer);

          nucleusIndex++;
        }

        bool growDendrites = GROW_DENDRITES;

        if (growDendrites)
        {
          // experimental growing dendrites.
          size_t infNeuronsCount = inputFiringNeurons.size();
          size_t outfNeuronsCount = outputFiringNeurons.size();
          for (size_t i = 0; i < infNeuronsCount; i++)
          {
            Neuron *in = inputFiringNeurons[i];
            for (size_t j = 0; j < outfNeuronsCount; j++)
            {
              Neuron *out = outputFiringNeurons[j];
              Dendrite *outDendrite = globalObject->findConnectingDendrite(out, in);
              if (outDendrite == NULL)
              {
                out->connectFrom(in, INHIBITORY);
              }

              Dendrite *inDendrite = globalObject->findConnectingDendrite(in, out);
              if (inDendrite == NULL)
              {
                out->connectTo(in, INHIBITORY); // default to inhibitory
              }
            }
          }
        }

        // As a test, lets fire random association cortex neurons.

        if (randomFireCount < 25)
        {
          TR1Random tr1random;
          int rnd1 = tr1random.generate(1, 100);

          if (rnd1 > 75)
          {

            std::vector<long> associationNeurons = Server::getNeurons("nucleusAssociative", LayerType::input); // Layer input

            for (size_t ix = 0; ix < associationNeurons.size(); ix++)
            {
              int rnd2 = tr1random.generate(1, 100);

              bool selected = (rnd2 > 75);
              if (selected)
              {
                long neuronId = associationNeurons[ix];
                Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
                inputFiringNeurons.push_back(neuron);
              }
            }
            randomFireCount++;
          }
        }

        long delay = PROPAGATION_DELAY_MICROSECONDS;
        long startTimer = globalObject->getCurrentTimestamp();
        long endTimer = startTimer + delay + PROPAGATION_DELAY_MICROSECONDS;

          Range offset = globalObject->batchLearn(&inputFiringNeurons, &outputFiringNeurons, nucleusName);
          long lowestOffset = offset.low;
          long highestOffset = offset.high;
          startTimer = globalObject->getCurrentTimestamp();

          //std::cout << "batchLearn Range: " << offset.low << " - " << offset.high << std::endl;

          delay = PROPAGATION_DELAY_MICROSECONDS;
          if (highestOffset < delay && highestOffset > 0)
            delay = highestOffset;

          if (delay > MAX_TIMEINTERVAL_OFFSET)
            delay = MAX_TIMEINTERVAL_OFFSET;

          endTimer = startTimer + delay + PROPAGATION_DELAY_MICROSECONDS + REFACTORY_PERIOD; 
          // globalObject->cycleNeurons(); // cycle through all neurons a if potiential > threshold, fire the neurons
//          while (globalObject->getAllTotalEvents() > 0)
//          {
//            usleep(250); // 0.25 seconds
//          }
        long ct = globalObject->getCurrentTimestamp();
        while(ct < endTimer)
        {
          usleep(25);
          ct = globalObject->getCurrentTimestamp();
        }
/*        
        int max_loop_count = 60;
        long loopcount = 0;
        long totalEvents = globalObject->getTotalEvents();
        while (totalEvents > 0 && loopcount < max_loop_count) // If more than MAX_ACTIVE_ACTIONPOTENTIALS events in progress - slow it down
        {
          std::cout << "delay current: " << globalObject->getCurrentTimestamp() << ", retry: " << loopcount + 1 << " of " << max_loop_count << " tries." << std::endl;
          sleep(1); // 1 sec delay to allow for ap propagation
          totalEvents = globalObject->getTotalEvents();
          loopcount++;
        }

*/        
        // proceed anyway and hope they die down.... may need some logic to kill
        std::stringstream ss;
        ss << "complete for - " << globalObject->latestOutputTarget << std::endl;
        globalObject->writeFirePatternLog(ss.str().c_str());
      }
      else
      {
        returnCode = 997;
        returnMessage = "nuclei missing: " + command;
        std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
        // printf("%s\n",returnString.c_str());
        return returnString;
      }
/*      
      // wait until the input neurons stop firing
      bool done = false;
      size_t infNeuronsCount = inputFiringNeurons.size();
      while(~done)
      {
        done = true;
        for(size_t i=0;i<infNeuronsCount;i++)
        {
          Neuron* n = inputFiringNeurons[i];
          if(n->isFiring())
          {
//            std::cout << "Neuron : " << n->id << " still firing" << std::endl;
            done = false;
          }
        }
        usleep(10);
      }
*/

      returnCode = 0;
      returnMessage = "SUCCESS";
      std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "GETACTIVATIONPATTERN"))
    {
      //
      // std::string pattern("");
      std::string nucleus = jsonObject["nucleus"];
      if (nucleus.empty())
      {
        returnCode = 500; // invalid object reference
        returnMessage = "invalid object reference";
        std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
        return returnString;
      }

      std::vector<long> neurons = Server::getNeurons(nucleus, LayerType::output); // Layer 6 = output
      size_t totalSize = neurons.size();

      size_t tempBufferSize = totalSize / 8 + 1;

      unsigned char *tempBuffer = (unsigned char *)calloc(1, tempBufferSize);

      for (size_t i = 0; i < totalSize; i++)
      {
        long neuronId = neurons[i];
        Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
        int byteindex = i / 8;
        int bitindex = i % 8; // get the modulus

        if (neuron != NULL)
        {
          if (neuron->isFiring(FIRING_WINDOW))
          {
            *(tempBuffer + byteindex) |= bitmapper[bitindex]; // OR the byte to set the particular bit on
          }
        }
      }
      // tempBuffer now contains the activations in binary (on bit indicates neuron is firing)
      // convert the buffer into a base64 string
      std::string encoded = base64_encode(tempBuffer, tempBufferSize);
      // release the tempbuffer
      free(tempBuffer);

      // format the return json string

      returnCode = 0;
      returnMessage = "SUCCESS";

      std::string returnString("{ \"pattern\": \"");
      returnString += encoded;
      returnString += "\", \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "STARTATOMIC"))
    {
      //
      std::string value = jsonObject["value"];

      if (boost::iequals(value, "TRUE"))
      {
      }
      else
      {
      }
      returnCode = 998;
      returnMessage = "command not currently implemented: " + command;
      std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "SETVALUE"))
    {
      //
      /*

      // The variables below can be changed on the fly via the SETVALUE rest interface command
      // example JSON format is { "command": "SETVALUE", "name": "FIRING_WINDOW", "value": 10 }

      // set initial FIRING WINDOW to slightly longer than refactory period
      //#define FIRING_WINDOW 10
      long FIRING_WINDOW = 10;

      //#define PROPAGATION_DELAY_MICROSECONDS 20
      long PROPAGATION_DELAY_MICROSECONDS = 20;

      //#define DECAY_FACTOR  0.01f
      //float DECAY_FACTOR = 0.01f;

      //long REFACTORY_PERIOD = 10;

      // WEIGHT_GRADATION is used to slow the rate of change for weight over time (defined by n updates)
      //#define WEIGHT_GRADATION 10000.0f
      float WEIGHT_GRADATION = 10000.0f;

      // RATE_GRADATION is used to slow the rate of change for rate over time (defined by n updates)
      //#define RATE_GRADATION 10000.0f
      float RATE_GRADATION = 10000.0f;


      */
      //
      std::string key = jsonObject["name"];

      std::string value = jsonObject["value"];

      if (boost::iequals(key, "FIRING_WINDOW"))
      {
        FIRING_WINDOW = std::stol(value);
      }
      else if (boost::iequals(key, "PROPAGATION_DELAY_MICROSECONDS"))
      {
        PROPAGATION_DELAY_MICROSECONDS = std::stol(value);
      }
      else if (boost::iequals(key, "DECAY_FACTOR"))
      {
        DECAY_FACTOR = std::stof(value);
      }
      else if (boost::iequals(key, "REFACTORY_PERIOD"))
      {
        REFACTORY_PERIOD = std::stol(value);
      }
      else if (boost::iequals(key, "WEIGHT_GRADATION"))
      {
        WEIGHT_GRADATION = std::stof(value);
      }
      else if (boost::iequals(key, "RATE_GRADATION"))
      {
        RATE_GRADATION = std::stof(value);
      }
      else
      {
        returnCode = 995;
        returnMessage = "SETVALUE command key or value not valid";
        std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
        // printf("%s\n",returnString.c_str());
        return returnString;
      }

      printf("SETVALUE name:%s, value:%s successfully set.\n", key.c_str(), value.c_str());

      returnCode = 0;
      returnMessage = "SUCCESS";
      std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "GETVALUE"))
    {
      //
      /*

      // The variables below can be retrieved on the fly via the GETVALUE rest interface command
      // example JSON format is { "command": "GETVALUE", "name": "FIRING_WINDOW" }

      */
      //
      std::string key = jsonObject["name"];

      std::string value;

      if (boost::iequals(key, "FIRING_WINDOW"))
      {
        value = std::to_string(FIRING_WINDOW);
      }
      else if (boost::iequals(key, "PROPAGATION_DELAY_MICROSECONDS"))
      {
        value = std::to_string(PROPAGATION_DELAY_MICROSECONDS);
      }
      else if (boost::iequals(key, "DECAY_FACTOR"))
      {
        value = std::to_string(DECAY_FACTOR);
      }
      else if (boost::iequals(key, "REFACTORY_PERIOD"))
      {
        value = std::to_string(REFACTORY_PERIOD);
      }
      else if (boost::iequals(key, "WEIGHT_GRADATION"))
      {
        value = std::to_string(WEIGHT_GRADATION);
      }
      else if (boost::iequals(key, "RATE_GRADATION"))
      {
        value = std::to_string(RATE_GRADATION);
      }
      else
      {
        returnCode = 995;
        returnMessage = "SETVALUE command key or value not valid";
        std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
        // printf("%s\n",returnString.c_str());
        return returnString;
      }

      printf("GETVALUE name:%s, value:%s \n", key.c_str(), value.c_str());

      returnCode = 0;
      returnMessage = "SUCCESS";
      std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\", \"Value\": \"" + value + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "FLUSH"))
    {
      //
      std::cout << "FLUSH command received" << std::endl;
      globalObject->flush(); // flush all databases - persist all Databases to disc
      std::cout << "FLUSH complete." << std::endl;
      returnCode = 0;
      returnMessage = "SUCCESS";
      std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "STAT"))
    {
      //
      std::cout << "STAT command received" << std::endl;
      std::string resp = "";
      std::string sep = "";

      std::stringstream s1;
      s1 << "Total Events :" << globalObject->getAllTotalEvents() << std::endl;
      resp = s1.str();

      for (int i = 0; i < FIRING_WINDOW * 2; i++)
      {
        std::stringstream ss;
        long thistimestamp = (globalObject->getCurrentTimestamp() - FIRING_WINDOW) + i; //
        long thisindex = thistimestamp % MAX_TIMEINTERVAL_BUFFER_SIZE;
        long count = globalObject->timeIntervalEvents[thisindex].size();
        ss << sep << (i - FIRING_WINDOW) << ":" << count;
        resp += ss.str();
        sep = ",";
      }

      std::cout << "STAT complete." << std::endl;
      returnCode = 0;
      returnMessage = "SUCCESS";
      std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\", \"Response\": [" + resp + "] }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else if (boost::iequals(command, "REPORT"))
    {
      returnCode = 998;
      returnMessage = "command not currently implemented: " + command;
      std::string returnString = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";
      // printf("%s\n",returnString.c_str());
      return returnString;
    }
    else
    {
      returnCode = 999;
      returnMessage = "Unknown command received: " + command;

      std::string responseContent = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";

      return responseContent;
    }
  }
  else
  {
    returnCode = 997;
    returnMessage = "empty command received: " + command;

    std::string responseContent = "{ \"Returncode\": \"" + std::to_string(returnCode) + "\", \"ReturnMessage\": \"" + returnMessage + "\" }";

    return responseContent;
  }

  std::string emptyresponseContent;
  return emptyresponseContent;
}

std::string computeResponse(std::string content)
{
  long max_allowed = MAX_ACTIVE_ACTIONPOTENTIALS;
  //  long max_allowed = 100;

  if (globalObject->getTotalEvents() > (long)(max_allowed)) // If more than MAX_ACTIVE_ACTIONPOTENTIALS events in progress - slow it down
  {
    std::cout << "computeResponse: More than " << max_allowed << "  events in progress. Slow it down." << std::endl;
    std::cout << std::endl;

    long currentTotalEvents = globalObject->getTotalEvents();
    long previousTotalEvents = currentTotalEvents;

    bool keepWaiting = true;
    constexpr int MAX_UNCHANGED=100;
    int unchangedCount=0;

    while (currentTotalEvents > (long)(max_allowed) && keepWaiting)
    {
      sleep(5); // sleep for 5 seconds
      previousTotalEvents = currentTotalEvents;
      currentTotalEvents = globalObject->getTotalEvents();
      if (currentTotalEvents < previousTotalEvents)
      {
        std::cout << "computeResponse: Current event count is " << currentTotalEvents << ", down from " << previousTotalEvents << " by " << previousTotalEvents - currentTotalEvents << ".      \r";
        unchangedCount=0;
      }
      else if (currentTotalEvents > previousTotalEvents)
      {
        std::cout << "computeResponse: Current event count is " << currentTotalEvents << ", up from " << previousTotalEvents << " by " << currentTotalEvents - previousTotalEvents << ".        \r";
        unchangedCount=0;
      }
      else
      {
        std::cout << "computeResponse: Current event count is " << currentTotalEvents << ", unchanged from previous count.                                                                      \r";
        unchangedCount++;
        if(unchangedCount>MAX_UNCHANGED)
          keepWaiting = false;
      }
    }
    std::cout << std::endl
              << "computeResponse: Continuing." << std::endl;
  }

  std::string responseContent = parseAndRespondJSON(content);
  return responseContent;
}

std::string computeStatus(std::string content)
{

  std::string responseContent = parseAndRespond(content);
  return responseContent;
}

extern int main_process(Brain *brain)
{

  (void)brain;
  pid_t tid = syscall(SYS_gettid);
//  std::cout << "httpServerMain.main_process thread is " << tid << std::endl;

  std::string host = "0.0.0.0";
  int port = 8124;
  HttpServer server(host, port);

  //

  // Register a few endpoints for demo and benchmarking
  // auto say_hello = [](const HttpRequest &request) -> HttpResponse
  //{
  //  HttpResponse response(HttpStatusCode::Ok);
  //  response.SetHeader("Content-Type", "text/plain");
  //  response.SetContent("Hello, world\n");
  //  return response;
  //};

  auto say_json = [](const HttpRequest &request) -> HttpResponse
  {
    HttpResponse response(HttpStatusCode::Created);
    response.SetHeader("Content-Type", "application/json");
    // Compute response

    pid_t tid = syscall(SYS_gettid);
//    std::cout << "httpServerMain.response thread " << tid << " starting." << std::endl;

    std::string content = computeResponse(request.content());
    response.SetContent(content);

    long totalEvents = globalObject->getTotalEvents();
//    std::cout << "httpServerMain.response thread " << tid << " ending with " << totalEvents << " events remaining. Global Counter: " << globalObject->getTimedEventsCounter() << std::endl;
    return response;
  };

  // auto send_html = [](const HttpRequest &request) -> HttpResponse
  //{
  //   HttpResponse response(HttpStatusCode::Ok);
  //   std::string content;
  //   content += "<!doctype html>\n";
  //   content += "<html>\n<body>\n\n";
  //   content += "<h1>Hello, world in an Html page</h1>\n";
  //   content += "<p>A Paragraph</p>\n\n";
  //   content += "</body>\n</html>\n";
  //
  //   response.SetHeader("Content-Type", "text/html");
  //   response.SetContent(content);
  //   return response;
  // };

  auto send_status = [](const HttpRequest &request) -> HttpResponse
  {
    HttpResponse response(HttpStatusCode::Ok);
    std::string content;
    content += "<!doctype html>\n";
    content += "<html>\n<body>\n\n";
    content += "<h1>SNNEngine Status</h1>\n";
    content += computeStatus(request.content());
    content += "</body>\n</html>\n";

    response.SetHeader("Content-Type", "text/html");
    response.SetContent(content);
    return response;
  };

  //  server.RegisterHttpRequestHandler("/", HttpMethod::HEAD, say_hello);
  //  server.RegisterHttpRequestHandler("/", HttpMethod::GET, say_hello);
  //  server.RegisterHttpRequestHandler("/hello.html", HttpMethod::HEAD, send_html);
  //  server.RegisterHttpRequestHandler("/hello.html", HttpMethod::GET, send_html);
  server.RegisterHttpRequestHandler("/api/data", HttpMethod::POST, say_json);
  server.RegisterHttpRequestHandler("/status", HttpMethod::GET, send_status);
  server.RegisterHttpRequestHandler("/networkStatus.json", HttpMethod::GET, show_network_status);
  server.RegisterHttpRequestHandler("/networkView",       HttpMethod::GET, show_network_view);

  try
  {
    // std::cout << "Setting new limits for file descriptor count.." <<
    // std::endl; ensure_enough_resource(RLIMIT_NOFILE, 15000, 15000);

    // std::cout << "Setting new limits for number of threads.." << std::endl;
    // ensure_enough_resource(RLIMIT_NPROC, 60000, 60000);

    std::cout << "Starting the web server on " << host << ":" << port << std::endl;
    server.Start();
    std::cout << "Server listening on " << host << ":" << port << std::endl;

    // std::cout << "Enter [quit] to stop the server" << std::endl;
    std::string command;
    while (globalObject->keepWebserverRunning)
    { // std::cin >> command, command != "quit") {
      std::this_thread::sleep_for(std::chrono::milliseconds(1000));
    }
    std::cout << "Stopping the web server.." << std::endl;
    server.Stop();
    std::cout << "Server stopped" << std::endl;
  }
  catch (std::exception &e)
  {
    std::cerr << "An error occurred: " << e.what() << std::endl;
    return -1;
  }

  return 0;
}

std::string convertToBinaryString(unsigned char *data, size_t size)
{
  std::string returnString;

  for (int i = 0; i < (int)size; i++)
  {
    int byteindex = i / 8;
    int bitindex = i % 8;

    unsigned char value = data[byteindex] & bitmapper[bitindex];
    if (value == '\0')
    {
      returnString += "0";
    }
    else
    {
      returnString += "1";
    }
  }

  return returnString;
}

std::vector<long> getAllComponentIds(void)
{
  std::vector<long> neurons;
  long neuronIdStart = globalObject->componentBase[ComponentTypeNeuron];
	long neuronIdEnd = globalObject->componentCounter[ComponentTypeNeuron];
  for(long n=neuronIdStart; n<neuronIdEnd;n++)
  {
    neurons.push_back(n);
	}
  return neurons;
}

HttpResponse show_network_status(const HttpRequest &request)
{
    HttpResponse response(HttpStatusCode::Ok);
    response.SetHeader("Content-Type", "application/json");

    // We'll build a JSON structure using nlohmann::json
    nlohmann::json networkJson;
    networkJson["neurons"] = nlohmann::json::array();
    networkJson["links"]   = nlohmann::json::array();

    // 1) Gather the neurons
    //    Adjust this to however you retrieve your neuron IDs.
    //    For example: auto neuronIds = globalObject->neuronDB.getAllComponentIds();
    std::vector<long>  neuronIds = getAllComponentIds();

    // We'll map neuronId -> index so we can reference them in "links"
    std::unordered_map<long, size_t> neuronIndexMap;
    size_t index = 0;

    for (auto &nid : neuronIds)
    {
        Neuron* n = globalObject->neuronDB.getComponent(nid);
        if (!n) continue;

        // Build a JSON object for each neuron
        nlohmann::json neuronJson;
        neuronJson["id"]        = (long)n->id;
        neuronJson["threshold"] = n->threshold;
        neuronJson["potential"] = n->getMembranePotential();
        neuronJson["firing"]    = n->isFiring() ? true : false;

        // Optionally include location
        neuronJson["x"] = n->location.x;
        neuronJson["y"] = n->location.y;
        neuronJson["z"] = n->location.z;

        networkJson["neurons"].push_back(neuronJson);

        // Store the index
        neuronIndexMap[n->id] = index++;
    }

    // 2) Gather synapse connections as "links"
    //    For each neuron, we look at its dendrites and retrieve the synapse info
    for (auto &nid : neuronIds)
    {
        Neuron* postNeuron = globalObject->neuronDB.getComponent(nid);
        if (!postNeuron) continue;

        auto& dendrites = *(postNeuron->getDendrites());
        for (auto dId : dendrites)
        {
            Dendrite* d = globalObject->dendriteDB.getComponent(dId);
            if (!d) continue;

            long preId = d->getPreSynapticNeuronId();
            Synapse* s = globalObject->synapseDB.getComponent(d->getSynapseId());
            if (!s) continue;

            // Build a JSON link
            nlohmann::json linkJson;
            linkJson["source"]   = (long)preId;          // actual neuron ID
            linkJson["target"]   = (long)postNeuron->id; // actual neuron ID
            linkJson["weight"]   = s->getWeight();
            linkJson["polarity"] = s->getPolarity();

            // For force-directed or zero-based indexing, you can also store the index:
            linkJson["sourceIdx"] = (long)neuronIndexMap[preId];
            linkJson["targetIdx"] = (long)neuronIndexMap[postNeuron->id];

            networkJson["links"].push_back(linkJson);
        }
    }

    // Convert to string
    std::string jsonString = networkJson.dump();
    response.SetContent(jsonString);

    return response;
};

HttpResponse show_network_view(const HttpRequest &request)

{
    HttpResponse response(HttpStatusCode::Ok);
    response.SetHeader("Content-Type", "text/html");

    // This HTML includes embedded JavaScript (D3.js) which
    // fetches /networkStatus.json and displays a force-directed graph.
    // Feel free to customize styling and behavior.
    std::stringstream ss;
    ss << "<!DOCTYPE html>\n"
       << "<html>\n"
       << "<head>\n"
       << "  <meta charset='utf-8'>\n"
       << "  <title>SNN Network Visualization</title>\n"
       << "  <script src='https://d3js.org/d3.v7.min.js'></script>\n"
       << "  <style>\n"
       << "    .link { stroke: #999; stroke-opacity: 0.6; }\n"
       << "    .node { stroke: #fff; stroke-width: 1.5px; cursor: pointer; }\n"
       << "    .node.firing { fill: red; }\n"
       << "    .node.notfiring { fill: steelblue; }\n"
       << "    text { font-family: sans-serif; font-size: 12px; }\n"
       << "  </style>\n"
       << "</head>\n"
       << "<body>\n"
       << "  <h1>SNN Network Visualization</h1>\n"
       << "  <div id='chart'></div>\n"
       << "  <script>\n"
       << "    const width = 800, height = 600;\n"
       << "    const svg = d3.select('#chart').append('svg')\n"
       << "        .attr('width', width)\n"
       << "        .attr('height', height);\n"
       << "\n"
       << "    d3.json('/networkStatus.json').then(function(data) {\n"
       << "      const nodes = data.neurons;\n"
       << "      const links = data.links;\n"
       << "\n"
       << "      const simulation = d3.forceSimulation(nodes)\n"
       << "        .force('link', d3.forceLink(links).id(d => d.id))\n"
       << "        .force('charge', d3.forceManyBody().strength(-30))\n"
       << "        .force('center', d3.forceCenter(width / 2, height / 2));\n"
       << "\n"
       << "      const link = svg.selectAll('.link')\n"
       << "        .data(links)\n"
       << "        .enter().append('line')\n"
       << "        .attr('class', 'link')\n"
       << "        .style('stroke-width', d => Math.max(1, d.weight * 2));\n"
       << "\n"
       << "      const node = svg.selectAll('.node')\n"
       << "        .data(nodes)\n"
       << "        .enter().append('circle')\n"
       << "        .attr('class', d => 'node ' + (d.firing ? 'firing' : 'notfiring'))\n"
       << "        .attr('r', 8)\n"
       << "        .call(d3.drag()\n"
       << "          .on('start', dragstarted)\n"
       << "          .on('drag', dragged)\n"
       << "          .on('end', dragended));\n"
       << "\n"
       << "      node.append('title')\n"
       << "        .text(d => `Neuron: ${d.id}\\nThreshold: ${d.threshold}\\nPotential: ${d.potential}`);\n"
       << "\n"
       << "      simulation.on('tick', () => {\n"
       << "        link\n"
       << "          .attr('x1', d => d.source.x)\n"
       << "          .attr('y1', d => d.source.y)\n"
       << "          .attr('x2', d => d.target.x)\n"
       << "          .attr('y2', d => d.target.y);\n"
       << "\n"
       << "        node\n"
       << "          .attr('cx', d => d.x)\n"
       << "          .attr('cy', d => d.y);\n"
       << "      });\n"
       << "\n"
       << "      function dragstarted(event, d) {\n"
       << "        if (!event.active) simulation.alphaTarget(0.3).restart();\n"
       << "        d.fx = d.x;\n"
       << "        d.fy = d.y;\n"
       << "      }\n"
       << "      function dragged(event, d) {\n"
       << "        d.fx = event.x;\n"
       << "        d.fy = event.y;\n"
       << "      }\n"
       << "      function dragended(event, d) {\n"
       << "        if (!event.active) simulation.alphaTarget(0);\n"
       << "        d.fx = null;\n"
       << "        d.fy = null;\n"
       << "      }\n"
       << "    });\n"
       << "  </script>\n"
       << "</body>\n"
       << "</html>\n";

    response.SetContent(ss.str());
    return response;
};


// ============== HTTPServerMain.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#ifndef HTTPSERVERMAIN_H_
#define HTTPSERVERMAIN_H_
#include <string>
#include <vector>
#include <sys/resource.h>
#include <sys/time.h>
#include <math.h>

#include <cerrno>
#include <chrono>
#include <cstring>
#include <iostream>
#include <stdexcept>
#include <string>
#include <thread>
#include <vector>

#include "HTTPMessage.h"
#include "HTTPServer.h"
#include "uri.h"
#include "Global.h"

#include "nlohmann/json.hpp"
#include <boost/algorithm/string.hpp>
#include "TR1Random.h"

using simple_http_server::HttpMethod;
using simple_http_server::HttpRequest;
using simple_http_server::HttpResponse;
using simple_http_server::HttpServer;
using simple_http_server::HttpStatusCode;

//std::string  computeResponse(const std::string content);

std::string bitsToString(char *buffer, long bufferSize);
std::string convertToBinaryString(unsigned char* data, size_t size);
std::stringstream getLastAsciiImage(void);
std::vector<long> getAllComponentIds(void);
HttpResponse show_network_status(const HttpRequest &request);
HttpResponse show_network_view(const HttpRequest &request);

#endif  // HTTPSERVERMAIN_H_

// ============== Layer.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Layer.h"
#include "TR1Random.h"
#include "Global.h"

Layer::Layer(unsigned long parentId):
	NNComponent(ComponentTypeLayer)
{
	(void)parentId;
}

Layer::~Layer(void)
{
}

/*
	std::vector<long> clusters;

	Location3D location;
	Size3D area;
*/
void Layer::toJSON(std::ofstream& outstream)
{
	std::stringstream ss;
	LOGSTREAM(ss) << "Exporting layer..." << std::endl;
	globalObject->log(ss);

	std::string sep("");
	outstream << "                { \"_type\": \"Layer\", \"id\": " << id << ", \"location\": [" << location.x << ", " << location.y << ", " << location.z << "], \"size\": [" << area.h << ", " << area.w << ", " << area.d << "], \"clusters\": [ " << std::endl;
	for (unsigned int i = 0; i < clusters.size(); i++)
	{
		outstream << sep;
		sep = ",";
		Cluster* c = globalObject->clusterDB.getComponent(clusters[i]);
		c->toJSON(outstream);
	}
	outstream << "                ] } " << std::endl;

}

void Layer::save(void)
{
	globalObject->layerDB.save(this);
}

void Layer::commit(void)
{
	globalObject->layerDB.addToCache(this);
}


Layer *Layer::create(unsigned long parentId)
{
	Layer *l = new Layer(parentId);
	l->id = globalObject->nextComponent(ComponentTypeLayer);
	globalObject->insert(l);
	return l;
}


void Layer::receiveInputFrom(Layer *layer, float sparsity, float polarity)
{
	std::stringstream ss;
//	std::cout << " Connecting layer " << id << " ... " << std::endl;
	size_t cSize = clusters.size();
	size_t cSize2 = layer->clusters.size();
	for(size_t i=0;i<cSize;i++)
	{
		Cluster *cFrom = globalObject->clusterDB.getComponent(clusters[i]);
		for(size_t j=0;j<cSize2;j++)
		{
			Cluster *cTo = globalObject->clusterDB.getComponent(layer->clusters[j]);
//			LOGSTREAM(ss) << "      Cluster " << cFrom->id << " (" << cFrom->neurons.size() << " neurons) receiving input from   " << cTo->id << " (" << cTo->neurons.size() << " neurons)" << std::endl;
//			globalObject->log(ss);
			cFrom->receiveInputFrom(cTo, sparsity,polarity);
		}
	}
}

long Layer::getStartNeuron(void)
{
	size_t cSize = clusters.size();
	if(cSize==0)
		return 0;

	long cId = clusters[0];
	Cluster *cluster = globalObject->clusterDB.getComponent(cId);
	return cluster->getStartNeuron();
}

long Layer::getEndNeuron(void)
{
	size_t cSize = clusters.size();
	if(cSize==0)
		return 0;

	long cId = clusters[cSize-1];
	Cluster *cluster = globalObject->clusterDB.getComponent(cId);
	return cluster->getEndNeuron();
}


void Layer::initializeRandom(unsigned long parentId)
{
	
	size_t rnd = (size_t) tr1random->generate(1,10); // Random # of Clusters
	for(size_t i=0;i<rnd;i++) 
	{
		SpatialDetails sd(this->location, this->area);
		sd.randomizeLocation();

		Cluster *c = Cluster::create(sd,parentId);
		c->initializeRandom();
		clusters.push_back(c->id);
		this->commit();
	}
	
}

Layer *Layer::instantiate(long key, size_t len, void *data)
{
	(void)len;
// 	size_t size = sizeof(float)+sizeof(float)+sizeof(long)+sizeof(long);
	long clusterCount = 0;
	Layer *layer = new Layer(0);
	layer->id = key;

	char *ptr = (char*)data;

	memcpy(&layer->location.x, ptr, sizeof(location.x)); 	ptr += sizeof(location.x);
	memcpy(&layer->location.y, ptr, sizeof(location.y));	ptr += sizeof(location.y);
	memcpy(&layer->location.z, ptr, sizeof(location.z));	ptr += sizeof(location.z);
	memcpy(&layer->area.h, ptr, sizeof(area.h)); 	ptr += sizeof(area.h);
	memcpy(&layer->area.w, ptr, sizeof(area.w)); 	ptr += sizeof(area.w);
	memcpy(&layer->area.d, ptr, sizeof(area.d)); 	ptr += sizeof(area.d);
	memcpy(&clusterCount,ptr,sizeof(clusterCount)); 	ptr+=sizeof(clusterCount);

	for(size_t i=0;i<(size_t)clusterCount;i++)
	{
		long cid = 0;
		memcpy(&cid,ptr,sizeof(cid));
		layer->clusters.push_back(cid);
		ptr+=sizeof(cid);
	}
//	printf("instantiate: Layer %i clusterSize %i\n",(int)layer->id,(int)layer->clusters.size());
	return layer;
}

Tuple *Layer::getImage(void)
{
/* -- persisted values
	u_int32_t clusterCount;
	std::vector<long> clusters;
*/
	long clusterCount = clusters.size();
	size_t size = sizeof(location.x)+ sizeof(location.y) + sizeof(location.z) + sizeof(area.h) + sizeof(area.w) + sizeof(area.d) + sizeof(clusterCount) +(clusterCount * sizeof(long));

	char *image = globalObject->allocClearedMemory(size);
	char *ptr = (char*)image;

	memcpy(ptr, &location.x, sizeof(location.x)); 	ptr += sizeof(location.x);
	memcpy(ptr, &location.y, sizeof(location.y)); 	ptr += sizeof(location.y);
	memcpy(ptr, &location.z, sizeof(location.z)); 	ptr += sizeof(location.z);
	memcpy(ptr, &area.h, sizeof(area.h)); 	ptr += sizeof(area.h);
	memcpy(ptr, &area.w, sizeof(area.w)); 	ptr += sizeof(area.w);
	memcpy(ptr, &area.d, sizeof(area.d)); 	ptr += sizeof(area.d);
	memcpy(ptr,&clusterCount,sizeof(clusterCount)); 	ptr+=sizeof(clusterCount);

	for(size_t i=0;i<(size_t)clusterCount;i++)
	{
		long k = clusters[i];
		memcpy(ptr,&k,sizeof(k));
		ptr+=sizeof(k);
	}

	Tuple* tuple = new Tuple();
	tuple->objectPtr = image;
	tuple->value = size;

	return tuple;
}




// ============== Layer.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <map>
#include "NNComponent.h"
#include "Cluster.h"

// polarity - defined here because for some reason it can't see it in Global.h
#define EXCITATORY 1.0f
#define INHIBITORY -1.0f

class Layer: public NNComponent
{
	Layer(unsigned long parentId);
    friend class boost::serialization::access;
    // When the class Archive corresponds to an output archive, the
    // & operator is defined similar to <<.  Likewise, when the class Archive
    // is a type of input archive the & operator is defined similar to >>.
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
	{
		ar & boost::serialization::base_object<NNComponent>(*this);
		for(unsigned int i=0;i<clusters.size();i++)
		{
			ar & clusters[i];
		}
/*
		std::map<long,Cluster *>::iterator itCluster = clusters.begin();
		for (itCluster=clusters.begin(); itCluster!=clusters.end(); ++itCluster)
		{
			ar & itCluster->second;
		}
*/
	}

public:
	virtual ~Layer(void);
	static Layer *create(unsigned long parentId);
	void initializeRandom(unsigned long parentId);
	static Layer *instantiate(long key, size_t len, void *data);
	Tuple *getImage(void);

	void receiveInputFrom(Layer *layer, float sparsity=100.0f, float polarity=EXCITATORY_SYNAPSE);
	void toJSON(std::ofstream& outstream);

	long getStartNeuron(void);
	long getEndNeuron(void);


	std::vector<long> clusters;

	Location3D location;
	Size3D area;

private:
	void save(void);
	void commit(void);


};


// ============== Location3D.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
class Location3D
{
public:
	Location3D(float x, float y, float z) { this->x = x; this->y = y; this->z = z; };
		
	Location3D(void) { this->x = 0; this->y = 0; this->z = 0; };

	void operator = (const Location3D& L) {
		x = L.x;
		y = L.y;
		z = L.z;
	}

	float x;
	float y;
	float z;
};



// ============== NNComponent.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "NNComponent.h"
#include "Global.h"

NNComponent::NNComponent(ComponentType type)
{
	this->componentType = type;
//	id = globalObject->nextComponent(type);
	globalObject->componentCounter2[this->componentType]++;	// Add counter to number of objects of this type
	dirty=false;												// Initial state is set to 'dirty'

	if(componentType == ComponentTypeUnknown) 
	{
		std::stringstream ss;
		LOGSTREAM(ss) << "WTF!" << std::endl;
		globalObject->log(ss);
	}
}

NNComponent::~NNComponent(void)
{
	globalObject->componentCounter2[componentType]--;
}

void NNComponent::save(void) 
{
	// override 
}

void NNComponent::commit(void)
{
	// override 
}





// ============== NNComponent.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <fstream>
#include <iostream>

// include headers that implement a archive in simple text format
#include <boost/archive/text_oarchive.hpp>
#include <boost/archive/text_iarchive.hpp>
#include <boost/archive/xml_iarchive.hpp>
#include <boost/archive/xml_oarchive.hpp>
#include "Tuple.h"


enum ComponentType {ComponentTypeUnknown=0, ComponentTypeBrain, ComponentTypeRegion, ComponentTypeNucleus, ComponentTypeColumn, ComponentTypeLayer, 
					ComponentTypeCluster, ComponentTypeNeuron, ComponentTypeAxon, ComponentTypeDendrite, ComponentTypeSynapse, 
					ComponentTypeActionPotential, ComponentTypeTimedEvent};
#define CTYPE_COUNT 13

#define MOTOR_NUCLEUS 2
#define SENSORY_NUCLEUS 1
#define INTER_NUCLEUS 0


class NNComponent
{
    friend class boost::serialization::access;
    // When the class Archive corresponds to an output archive, the
    // & operator is defined similar to <<.  Likewise, when the class Archive
    // is a type of input archive the & operator is defined similar to >>.
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
	{
        ar & componentType;
        ar & id;
	}
public:
	NNComponent(ComponentType type=ComponentTypeUnknown);
	virtual ~NNComponent(void);

	inline bool isDirty(void) {return dirty; };
	inline void setDirty(bool value=true) {dirty = value; };
	virtual void save(void);
	virtual void commit(void);


	ComponentType componentType;
	unsigned long id;
	unsigned long parentId;

private:
	bool dirty;
};



// ============== Neuron.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

/* Neuron.cpp */

#include "Neuron.h"
#include "TR1Random.h"
#include "Global.h"
#include "Axon.h"
#include "Dendrite.h"
#include "Synapse.h"
#include "SpatialDetails.h"
#include <sstream>
#include <cmath>
#include <algorithm>

extern long   PROPAGATION_DELAY_MICROSECONDS; // example external
extern double DECAY_FACTOR;                   // example external
extern float  RATE_GRADATION;                 // example external
extern long REFACTORY_PERIOD;

// Example external method from your environment
// std::vector<long> Server::getNeurons(const std::string &nucleusName, LayerType layerType);

Neuron::Neuron(unsigned long parentId, int nucleusType)
    : NNComponent(ComponentTypeNeuron)
{
    this->parentId        = parentId;
    this->nucleusType     = nucleusType;
    this->neuronPolarity  = Polarity::EXCITATORY_NEURON; // default
    this->threshold       = INITIAL_THRESHOLD;
    this->membranePotential = RESTING_POTENTIAL;
    this->firing          = false;
    this->latch           = false;
    this->lastfired       = 0;
    this->recentSpikeCount= 0.0f;
    this->lastUpdateStep  = globalObject->getCurrentTimestamp();

    // Example random location
    SpatialDetails sd(2500, 2500, 2500, 5000, 5000, 5000);
    sd.randomizeLocation();
    this->location = sd.location;
}

Neuron::~Neuron(void)
{
}

Neuron* Neuron::create(SpatialDetails details, NeuronType nType,
                       unsigned long parentId, int nucleusType)
{
    Neuron* n = new Neuron(parentId, nucleusType);
    n->id = globalObject->nextComponent(ComponentTypeNeuron);
    n->neuronType = nType;
    n->location = details.location;

    // Create an axon for the neuron
    Axon *a = Axon::create(n);
    n->axons.push_back(a->id);

    globalObject->insert(n);
    return n;
}

void Neuron::toJSON(std::ofstream &outstream)
{
    // Minimal example
    outstream << "{ \"_type\": \"Neuron\", \"id\": " << id
              << ", \"threshold\": " << threshold
              << ", \"potential\": " << membranePotential
              << ", \"polarity\": " << neuronPolarity
              << ", \"location\": [" << location.x << ", "
                                    << location.y << ", "
                                    << location.z << "] }" << std::endl;
}

void Neuron::save(void)
{
    globalObject->neuronDB.save(this);
}

void Neuron::commit(void)
{
    globalObject->neuronDB.addToCache(this);
}

Tuple* Neuron::getImage(void)
{
    long axonCount = (long)axons.size();
    long dendriteCount = (long)dendrites.size();

    size_t size = sizeof(nucleusType)
                  + sizeof(parentId)
                  + sizeof(neuronType)
                  + sizeof(threshold)
                  + sizeof(membranePotential)
                  + sizeof(neuronPolarity)
                  + sizeof(location.x)
                  + sizeof(location.y)
                  + sizeof(location.z)
                  + sizeof(axonCount)
                  + sizeof(dendriteCount)
                  + (axonCount * sizeof(long))
                  + (dendriteCount * sizeof(long));

    char *image = globalObject->allocClearedMemory(size);
    char *ptr = image;

    memcpy(ptr, &nucleusType, sizeof(nucleusType));
    ptr += sizeof(nucleusType);

    memcpy(ptr, &parentId, sizeof(parentId));
    ptr += sizeof(parentId);

    memcpy(ptr, &neuronType, sizeof(neuronType));
    ptr += sizeof(neuronType);

    memcpy(ptr, &threshold, sizeof(threshold));
    ptr += sizeof(threshold);

    memcpy(ptr, &membranePotential, sizeof(membranePotential));
    ptr += sizeof(membranePotential);

    memcpy(ptr, &neuronPolarity, sizeof(neuronPolarity));
    ptr += sizeof(neuronPolarity);

    memcpy(ptr, &location.x, sizeof(location.x));
    ptr += sizeof(location.x);

    memcpy(ptr, &location.y, sizeof(location.y));
    ptr += sizeof(location.y);

    memcpy(ptr, &location.z, sizeof(location.z));
    ptr += sizeof(location.z);

    memcpy(ptr, &axonCount, sizeof(axonCount));
    ptr += sizeof(axonCount);

    memcpy(ptr, &dendriteCount, sizeof(dendriteCount));
    ptr += sizeof(dendriteCount);

    for (auto &aId : axons)
    {
        memcpy(ptr, &aId, sizeof(aId));
        ptr += sizeof(aId);
    }
    for (auto &dId : dendrites)
    {
        memcpy(ptr, &dId, sizeof(dId));
        ptr += sizeof(dId);
    }

    Tuple* tuple = new Tuple();
    tuple->objectPtr = image;
    tuple->value = size;
    return tuple;
}

Neuron* Neuron::instantiate(long key, size_t len, void *data)
{
    (void)len;
    unsigned long defaultClusterId = ComponentType::ComponentTypeCluster;

    long axonCount = 0;
    long dendriteCount = 0;

    Neuron *neuron = new Neuron(defaultClusterId, 0 /*nucleusType*/);
    neuron->id = key;
    char *ptr = (char *)data;

    memcpy(&neuron->nucleusType, ptr, sizeof(neuron->nucleusType));
    ptr += sizeof(neuron->nucleusType);
    memcpy(&neuron->parentId, ptr, sizeof(neuron->parentId));
    ptr += sizeof(neuron->parentId);
    memcpy(&neuron->neuronType, ptr, sizeof(neuron->neuronType));
    ptr += sizeof(neuron->neuronType);
    memcpy(&neuron->threshold, ptr, sizeof(neuron->threshold));
    ptr += sizeof(neuron->threshold);
    memcpy(&neuron->membranePotential, ptr, sizeof(neuron->membranePotential));
    ptr += sizeof(neuron->membranePotential);
    memcpy(&neuron->neuronPolarity, ptr, sizeof(neuron->neuronPolarity));
    ptr += sizeof(neuron->neuronPolarity);
    memcpy(&neuron->location.x, ptr, sizeof(neuron->location.x));
    ptr += sizeof(neuron->location.x);
    memcpy(&neuron->location.y, ptr, sizeof(neuron->location.y));
    ptr += sizeof(neuron->location.y);
    memcpy(&neuron->location.z, ptr, sizeof(neuron->location.z));
    ptr += sizeof(neuron->location.z);
    memcpy(&axonCount, ptr, sizeof(axonCount));
    ptr += sizeof(axonCount);
    memcpy(&dendriteCount, ptr, sizeof(dendriteCount));
    ptr += sizeof(dendriteCount);

    for (int i = 0; i < axonCount; i++)
    {
        long aId;
        memcpy(&aId, ptr, sizeof(aId));
        ptr += sizeof(aId);
        neuron->axons.push_back(aId);
    }
    for (int i = 0; i < dendriteCount; i++)
    {
        long dId;
        memcpy(&dId, ptr, sizeof(dId));
        ptr += sizeof(dId);
        neuron->dendrites.push_back(dId);

        // Populate dendriteMap if needed
        Dendrite *dendrite = globalObject->dendriteDB.getComponent(dId);
        if (dendrite)
        {
            neuron->dendriteMap.insert(std::make_pair(dendrite->getPreSynapticNeuronId(), dId));
        }
    }

    return neuron;
}

void Neuron::initializeRandom(void)
{
    // Implementation optional
}

// -------------------------------------------------------------
// Connection-related
// -------------------------------------------------------------

void Neuron::connect(Neuron *preSynapticNeuron, Neuron *postSynapticNeuron, float polarity)
{
    if(preSynapticNeuron->isConnectedTo(postSynapticNeuron))
        return;

    Dendrite *dendrite = Dendrite::create(postSynapticNeuron, preSynapticNeuron,polarity);
    float thisDistance = computeDistance(preSynapticNeuron->location, postSynapticNeuron->location);
    dendrite->setDistance(thisDistance);

    preSynapticNeuron->dendriteMap.insert(std::make_pair(postSynapticNeuron->id, dendrite->id));

    size_t axonSize = preSynapticNeuron->axons.size();
    for (size_t axonsIndex = 0; axonsIndex < axonSize; axonsIndex++)
    {
        Axon *thisAxon = globalObject->axonDB.getComponent(preSynapticNeuron->axons[axonsIndex]);
        long synapseId = dendrite->getSynapseId();
        thisAxon->insertSynapse(synapseId);
        thisAxon->setDistance(thisDistance);

        Synapse *s = globalObject->synapseDB.getComponent(synapseId);
        s->setPosition(thisDistance);
    }
}

void Neuron::connectTo(Neuron *preSynapticNeuron, float polarity)
{
    // This neuron is postSynaptic, the argument is preSynaptic
    connect(preSynapticNeuron, this, polarity);
}

void Neuron::connectFrom(Neuron *postSynapticNeuron, float polarity)
{
    // This neuron is preSynaptic, the argument is postSynaptic
    connect(this, postSynapticNeuron, polarity);
}

void Neuron::receiveInputFrom(Neuron *targetNeuron, float polarity)
{
    // Another name for connect
    connect(targetNeuron, this, polarity);
}

bool Neuron::isConnectedTo(Neuron *neuron)
{
    Dendrite *dendrite = globalObject->findConnectingDendrite(this, neuron);
    return (dendrite != nullptr);
}

long Neuron::getCurrentTimestep(void)
{
    return globalObject->getCurrentTimestamp();
}

// For demonstration
long Neuron::getNucleusId(void)
{
    // Example logic
    // This depends on your existing data structures
    return 0; 
}

// -------------------------------------------------------------
// Firing logic with refractory period & adaptive threshold
// -------------------------------------------------------------
Range Neuron::fire(void)
{
    Range range;
    range.low  = 1;
    range.high = 1;

    long now = globalObject->getCurrentTimestamp();

    // 1) Check refractory period
    if ((now - lastfired) < REFACTORY_PERIOD) {
        // Still in refractory period; skip
        return range;
    }

    // 2) Check threshold
    if (membranePotential >= threshold)
    {
        // Actually fire
        lastfired = now;
        setFiring(true);
        recordSpike();

        // Increase threshold after spiking (adaptive)
        threshold += THRESHOLD_INCREMENT;
        threshold = std::clamp(threshold, MIN_THRESHOLD, MAX_THRESHOLD);

        // Log or do any output logic
        globalObject->lastFiredNeuron = this;

        // Fire axons
        size_t aSize = axons.size();
        long lowestOffset = 9999999;
        long highestOffset= -9999999;
        for (size_t i = 0; i < aSize; i++)
        {
            Axon *a = globalObject->axonDB.getComponent(axons[i]);
            Range offset = a->fire();
            if(lowestOffset > offset.low) 
                lowestOffset = offset.low;
            if(highestOffset < offset.high)
                highestOffset = offset.high;
        }
        range.low  = lowestOffset;
        range.high = highestOffset;

        // Reset membrane potential
        membranePotential = RESTING_POTENTIAL;

        // Optionally, apply local STDP to all incoming synapses
        applySTDPToIncomingSynapses();
    }
    else
    {
        // If we didn't fire, threshold decays back down slightly
        threshold -= THRESHOLD_DECAY;
        threshold = std::clamp(threshold, MIN_THRESHOLD, MAX_THRESHOLD);
    }

    return range;
}

// -------------------------------------------------------------
// Membrane potential management
// -------------------------------------------------------------
void Neuron::setMembranePotential(float inPotential)
{
    float newPotential = std::clamp(inPotential, MINIMUM_MEMBRANE_POTENTIAL, MAXIMUM_MEMBRANE_POTENTIAL);
    if (fabs(newPotential - membranePotential) > 1e-9)
    {
        membranePotential = newPotential;
        setDirty(true);
    }
}

void Neuron::leakMembranePotential()
{
    membranePotential = RESTING_POTENTIAL
        + (membranePotential - RESTING_POTENTIAL) * LEAK_FACTOR;
}

// -------------------------------------------------------------
// Integrate synaptic input (called from Synapse::receiveAP)
// -------------------------------------------------------------
void Neuron::integrateSynapticInput(float input, long synapseId)
{
    // Basic example: just add to current potential
    // Optionally incorporate a leak or weighting factor
    float newPotential = membranePotential + std::max(input, 0.0f);

    setMembranePotential(newPotential);
    // Decide if we want to spontaneously fire here or not.
    // Typically, we let the main update loop or a "step()" function call fire().
    // But you can do an immediate check if you prefer a purely event-based approach.
    // fire(); // If you want to check threshold immediately after each input
}

void Neuron::setFiring(bool value)
{
    if (firing != value)
    {
        // Optionally log
        if (globalObject->setLogFiring)
        {
            globalObject->logFiring(this, value);
        }
        firing = value;
        setDirty(true);
        if (value) {
            latch = true;
        }
    }
}

void Neuron::applySTDP(std::pair<std::vector<Neuron *> *, std::vector<Neuron *> *> *neurons, long learningInterval)
{
    std::vector<Neuron *> *preNeurons = neurons->first;
    std::vector<Neuron *> *postNeurons = neurons->second;

    // Use defined constants A_PLUS, A_MINUS, TAU_PLUS, TAU_MINUS
    double A_plus = A_PLUS;  
    double A_minus = A_MINUS; 
    double tau_plus = TAU_PLUS;             
    double tau_minus = TAU_MINUS;            

    auto adjustSynWeightLocal = [&](Synapse* synapse, double deltaT, double A, double tau, float polarity) {
        float weightChange = A * std::exp(-deltaT / tau) * polarity;
        float newWeight = synapse->getWeight();
        if(!std::isnan(weightChange) && !std::isinf(weightChange))
        {
            newWeight += weightChange;
        }
        float baseline = 0.01f;  
        newWeight = std::clamp(newWeight + baseline, MINIMUM_SYNAPSE_WEIGHT, MAXIMUM_SYNAPSE_WEIGHT);
        synapse->setWeight(newWeight);
    };

    // Long-Term Potentiation (LTP)
    for (Neuron* preNeuron : *preNeurons) {
        if (preNeuron->id != this->id) {
            Dendrite* preDendrite = globalObject->findConnectingDendrite(this, preNeuron);
            if (preDendrite) {
                Synapse* synapse = globalObject->synapseDB.getComponent(preDendrite->getSynapseId());
                long deltaT = this->lastfired - preNeuron->lastfired;
                if (deltaT > 0) { 
                    adjustSynWeightLocal(synapse, deltaT, A_plus, tau_plus, synapse->polarity);
                }
            }
        }
    }

    // Long-Term Depression (LTD)
    for (Neuron* postNeuron : *postNeurons) {
        if (postNeuron->id != this->id) {
            Dendrite* postDendrite = globalObject->findConnectingDendrite(this, postNeuron);
            if (postDendrite) {
                Synapse* synapse = globalObject->synapseDB.getComponent(postDendrite->getSynapseId());
                long deltaT = postNeuron->lastfired - this->lastfired;
                if (deltaT > 0) {
                    adjustSynWeightLocal(synapse, deltaT, A_minus, tau_minus, -synapse->polarity);
                }
            }
        }
    }

    // After STDP, apply synaptic scaling
    applySynapticScaling(SYNAPTIC_SCALING_FACTOR);

}


// -------------------------------------------------------------
// Simple STDP using local synapse trace or time-differences
// -------------------------------------------------------------
void Neuron::applySTDPToIncomingSynapses()
{
    // Example approach: for each dendrite/synapse, see if presyn fired recently.
    for (auto &dId : dendrites)
    {
        Dendrite *d = globalObject->dendriteDB.getComponent(dId);
        if(!d) continue;

        Synapse *s = globalObject->synapseDB.getComponent(d->getSynapseId());
        if(!s) continue;

        Neuron *preNeuron = globalObject->neuronDB.getComponent(d->getPreSynapticNeuronId());
        if(!preNeuron) continue;

        long deltaT = (long)(this->lastfired - preNeuron->lastfired);

        // If deltaT > 0 => presyn fired before postsyn => LTP
        // If deltaT < 0 => postsyn fired first => LTD

        // This is your existing formula or logic:
        if (deltaT > 0)
        {
            float weightChange = A_PLUS * std::exp(-std::fabs(deltaT) / TAU_PLUS) * s->getPolarity();
            float newW = s->getWeight() + weightChange + 0.01f; // example baseline
            newW = std::clamp(newW, MINIMUM_SYNAPSE_WEIGHT, MAXIMUM_SYNAPSE_WEIGHT);
            s->setWeight(newW);
        }
        else if (deltaT < 0)
        {
            float weightChange = A_MINUS * std::exp(-std::fabs(deltaT) / TAU_MINUS) * -s->getPolarity();
            float newW = s->getWeight() + weightChange;
            newW = std::clamp(newW, MINIMUM_SYNAPSE_WEIGHT, MAXIMUM_SYNAPSE_WEIGHT);
            s->setWeight(newW);
        }

        // Optionally incorporate synapse->trace:
        // e.g., newW += s->trace * LTP_factor; s->trace = 0.0f; ...
        s->decayTrace(); // if you want to continuously decay the trace
    }

    // Possibly apply synaptic scaling if needed
    applySynapticScaling(SYNAPTIC_SCALING_FACTOR);
}

void Neuron::applySynapticScaling(float scalingFactor)
{
    if (std::fabs(scalingFactor - 1.0f) < 1e-9f) {
        return; // no scaling needed
    }
    for (auto &dId : dendrites)
    {
        Dendrite *d = globalObject->dendriteDB.getComponent(dId);
        if (!d) continue;

        Synapse *s = globalObject->synapseDB.getComponent(d->getSynapseId());
        if (!s) continue;

        float newW = s->getWeight() * scalingFactor;
        newW = std::clamp(newW, MINIMUM_SYNAPSE_WEIGHT, MAXIMUM_SYNAPSE_WEIGHT);
        s->setWeight(newW);
    }
}

// -------------------------------------------------------------
// Rate-based homeostasis
// -------------------------------------------------------------
float Neuron::getEstimatedFiringRate()
{
    unsigned long now = globalObject->getCurrentTimestamp();
    float elapsed = (float)(now - lastUpdateStep + 1);
    float rate = recentSpikeCount / elapsed;

    // Decay recent spike count over time
    recentSpikeCount *= 0.9f;
    lastUpdateStep = now;

    return rate;
}

void Neuron::recordSpike()
{
    recentSpikeCount += 1.0f;
}

// -------------------------------------------------------------
// Misc. checks
// -------------------------------------------------------------
bool Neuron::isContainedIn(std::vector<long> neurons, Neuron *thisNeuron)
{
    for (auto &nid : neurons)
    {
        if (thisNeuron->id == nid) return true;
    }
    return false;
}

std::string Neuron::generateOutputFiringString(std::vector<long> neurons, Neuron *thisNeuron)
{
    std::string outString;
    for (auto &nid : neurons)
    {
        Neuron *n = globalObject->neuronDB.getComponent(nid);
        if (!n) {
            outString += "?";
            continue;
        }
        if (n->id == thisNeuron->id) {
            outString += "1";
        } else {
            outString += (n->isFiring() ? "X" : "0");
        }
    }
    return outString;
}

bool Neuron::isFiring(float delay) 
{
    if (delay == 0) {
        return firing;
    }
    else
    {
        long timediff = globalObject->getCurrentTimestamp() - lastfired;
        long diff = std::abs(timediff);
        if (delay > diff)
            return true;
        else
            return false;
    }
}


bool Neuron::isFromSensoryNucleus()
{
    // Example check
    return (this->nucleusType == /*SENSORY_NUCLEUS*/ 1);
}

bool Neuron::isAssociated(long synapseId)
{
    // See if synapseId belongs to one of this neuron's dendrites
    for (auto &dId : dendrites)
    {
        Dendrite *dend = globalObject->dendriteDB.getComponent(dId);
        if (!dend) continue;
        if (synapseId == dend->getSynapseId()) {
            return true;
        }
    }
    return false;
}

std::vector<long>* Neuron::getAxonConnectedSynapses(void)
{
    std::vector<long> *connectedSynapses = new std::vector<long>();
    for (auto &axId : axons)
    {
        Axon *a = globalObject->axonDB.getComponent(axId);
        if (!a) continue;
        std::vector<long> *synList = a->getSynapses();
        connectedSynapses->insert(connectedSynapses->end(), synList->begin(), synList->end());
    }
    return connectedSynapses;
}

float Neuron::computeDistance(Location3D pointA, Location3D pointB)
{
    return std::sqrt(
        std::pow(pointB.x - pointA.x, 2) +
        std::pow(pointB.y - pointA.y, 2) +
        std::pow(pointB.z - pointA.z, 2));
}

float Neuron::nextDistance(void)
{
    // If you want to increment distance each time you add a dendrite
    static float distanceValue = 10.0f;
    distanceValue += 5.0f; // example step
    return distanceValue;
}

std::string Neuron::getLocationOfNeuron(void)
{
    // Example placeholder
    return "UnknownLocation";
}

// -------------------------------------------------------------
// Example STDP helper
// -------------------------------------------------------------
void Neuron::applySynapticWeightDelta(Synapse *synapse, float deltaT, float A, float tau, float polarity)
{
    float weightChange = A * std::exp(-std::fabs(deltaT) / tau) * polarity;
    float newW = synapse->getWeight() + weightChange;
    newW = std::clamp(newW, MINIMUM_SYNAPSE_WEIGHT, MAXIMUM_SYNAPSE_WEIGHT);
    synapse->setWeight(newW);
}


// ============== Neuron.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <cmath>
#include <unordered_map>
#include "NNComponent.h"
#include "Axon.h"
#include "Dendrite.h"
#include "Synapse.h"
#include "ActionPotential.h"
#include "SpatialDetails.h"
#include "Cluster.h"
#include "Range.h"
#include "NeuronMorphology.h"

//#define EXCITATORY 1.0f
//#define INHIBITORY -1.0f

class Polarity {
public:    
    static constexpr float INHIBITORY_NEURON = -1.0f;
    static constexpr float EXCITATORY_NEURON = 0.0f;
};

constexpr float THRESHOLD_INCREMENT       = 0.2f;
constexpr float MIN_THRESHOLD             = 0.5f;
constexpr float MAX_THRESHOLD             = 3.0f;
constexpr float THRESHOLD_DECAY           = 0.01f;

class Neuron: public NNComponent
{
    Neuron(unsigned long parentId, int nucleusType);
    friend class boost::serialization::access;
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
    {
        ar & boost::serialization::base_object<NNComponent>(*this);

        for(unsigned int i=0;i<axons.size();i++)
        {
            ar & axons[i];
        }
        for(unsigned int i=0;i<dendrites.size();i++)
        {
            ar & dendrites[i];
        }
        ar & threshold;
        ar & membranePotential;
        ar & location.x;
        ar & location.y;
        ar & location.z;
        ar & lastfired;
        ar & firing;
    }

public:
    virtual ~Neuron(void);
    static Neuron* create(SpatialDetails details, NeuronType nType, unsigned long parentId, int nucleusType);
    static Neuron* recreate(void);
    void initializeRandom(void);
    bool isAssociated(long synapseId);
    void connect(Neuron *preSynapticNeuron, Neuron *postSynapticNeuron, float polarity);
    void connectTo(Neuron *targetNeuron, float polarity);
    void connectFrom(Neuron *sourceNeuron, float polarity);
    void receiveInputFrom(Neuron *targetNeuron, float polarity=Polarity::EXCITATORY_NEURON);
    bool isConnectedTo(Neuron *neuron);

    bool isContainedIn(std::vector<long> neurons, Neuron *neuron);
    std::string generateOutputFiringString(std::vector<long> neurons,Neuron *thisNeuron);
    float normalizeRate(float value, float minValue, float maxValue);
    float computeConductionVelocity(Dendrite* dendrite, long timeDifference);
    void adjustSynapticWeight(Synapse *synapse, float deltaT, float A, float tau, float polarity);
    void applySTDP(std::pair<std::vector<Neuron*>*, std::vector<Neuron*>* >*neurons, long learningInterval);
    Range fire(void);
    Tuple *getImage(void);
    static Neuron *instantiate(long key, size_t len, void *data);

    void integrateSynapticInput(float input, long synapseId);

        // STDP or learning
    void applySTDPToIncomingSynapses();

// STDP adjustments using parameters
    void applySynapticWeightDelta(Synapse *synapse, float deltaT, float A, float tau, float polarity);


    long getNucleusId(void);

    long getCurrentTimestep(void);

    bool containsDendrite(long did);

    bool isFiring(float delay = 0);
    inline bool hasFired(void) { return latch; };
    inline void resetLatch(void) { latch = false; };
    inline long getLastFired(void) { return lastfired; };
    inline void setLastFired(unsigned long value) { lastfired = value; setDirty(true); };
    inline std::vector<long> *getAxons(void) { return &axons; };
    inline std::vector<long> *getDendrites(void) { return &dendrites; };
    std::string getLocationOfNeuron(void);
    float nextDistance(void);
    inline float computeDistance(Location3D pointA, Location3D pointB); 

    void setFiring(bool value=true);

    std::vector<long> *getAxonConnectedSynapses(void);
    bool isFromSensoryNucleus(void);

    void toJSON(std::ofstream& outstream);

    // New methods for improved dynamics and homeostasis:
    void leakMembranePotential();  
    void applySynapticScaling(float scalingFactor);
    float getEstimatedFiringRate(); 
    void recordSpike(); 

    float recentSpikeCount; 
    unsigned long lastUpdateStep;

	float getMembranePotential(void) { return membranePotential; };
	void setMembranePotential(float inPotential);

public:	
    std::unordered_map<long, long> dendriteMap; 
    float threshold;
    unsigned long lastfired;
    bool firing;
    NeuronType neuronType;
    float neuronPolarity;
    bool latch;
    Location3D location;
    int nucleusType;

private:
    float membranePotential; // kept for backward compatibility

    void save(void);
    void commit(void);

    std::vector<long> axons;
    std::vector<long> dendrites;

    float distanceValue;
};



// ============== NeuronMorphology.cpp ==============

/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "NeuronMorphology.h"

NeuronMorphology::NeuronMorphology(NeuronType nType, int cSize, int cCount)
{
	type = nType;
	clusterSize = cSize;
	clusterCount = cCount;
}

NeuronMorphology::~NeuronMorphology(void)
{
}


// ============== NeuronMorphology.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

enum NeuronType { Pyramidal, Unipolar, Bipolar, Multipolar, Purkinje };

class NeuronMorphology
{
public:
	NeuronMorphology(NeuronType nType=NeuronType::Pyramidal, int cSize=100, int cCount=10);
	~NeuronMorphology(void);

	NeuronType type;
	int clusterSize;
	int clusterCount;
};


// ============== NeuronProcessor.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <boost/thread.hpp>
#include <iostream>
#include <string>
#include <cstring> // For strerror() and related functions
#include <sys/socket.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <errno.h>
#include "Global.h"

#include "NeuronProcessor.h"

extern boost::mutex timestep_mutex;


// Settable externs
extern long FIRING_WINDOW;
extern long PROPAGATION_DELAY_MICROSECONDS;
extern double DECAY_FACTOR;
extern long REFACTORY_PERIOD;
extern float WEIGHT_GRADATION;
extern float RATE_GRADATION;

NeuronProcessor::NeuronProcessor(void)
{
    keepRunning = true;
}

NeuronProcessor::~NeuronProcessor(void)
{
}

void NeuronProcessor::doWork(void)
{

    long start = globalObject->componentBase[ComponentTypeNeuron];
    long end = globalObject->componentCounter[ComponentTypeNeuron];
    unsigned long cts = (unsigned long)globalObject->getCurrentTimestamp();
    for(long x = start;x<end;x++)
    {
        Neuron *thisNeuron = globalObject->neuronDB.getComponent(x);
        if (thisNeuron != NULL)
        {
            if (thisNeuron->firing)
            { // If we are firing, check to see if refactory period is exceeded
                if (cts - thisNeuron->lastfired > FIRING_WINDOW)
                {
                    thisNeuron->setFiring(false);
                    thisNeuron->setMembranePotential(RESTING_POTENTIAL);
                }
            }
        }
    }
/*
   	if(globalObject->logEvents) 
	{	
		std::stringstream ss;
		ss << "Brain_step: timestep=" << globalObject->getCurrentTimestamp() << ", cycle=runLearning";
		globalObject->writeEventLog(ss.str().c_str());
	}
*/
	globalObject->runLearning();
/*
   	if(globalObject->logEvents) 
	{	
		std::stringstream ss;
		ss << "Brain_step: timestep=" << globalObject->getCurrentTimestamp() << ", cycle=runLearning_complete";
		globalObject->writeEventLog(ss.str().c_str());
	}
*/
    //    globalObject->cycleNeurons();
/*
   	if(globalObject->logEvents) 
	{	
		std::stringstream ss;
		ss << "Brain_step: timestep=" << globalObject->getCurrentTimestamp() << ", cycle=cycleNeurons_complete";
		globalObject->writeEventLog(ss.str().c_str());
	}
*/
}

int NeuronProcessor::waitThread(void)
{
    int ret = waitThreadWorker();
    return ret;
}

int NeuronProcessor::waitThreadWorker(void)
{

    pid_t tid = syscall(SYS_gettid);
    std::cout << "NeuronProcessor thread is " << tid << std::endl;

    while (keepRunning)
    {
        doWork();
    }
    return 0;
}
void NeuronProcessor::start(void)
{
    boost::thread t(&NeuronProcessor::waitThread, this);
    t.detach(); // Don't Wait for the new thread to finish execution
}

void NeuronProcessor::stop(void)
{
    keepRunning = false;
}


// ============== NeuronProcessor.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <algorithm> 
#include <functional> 
#include <cctype>
#include <locale>
#include <string>
#include <vector>


class NeuronProcessor
{
public:
	NeuronProcessor(void);
	~NeuronProcessor(void);
	int waitThread(void);
	int waitThreadWorker(void);
	void doWork(void);
	void start(void);
	void stop(void);

   	bool keepRunning;

};


// ============== Nucleus.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Nucleus.h"
#include "TR1Random.h"
#include "Global.h"

Nucleus::Nucleus(int nucleusType):
	NNComponent(ComponentTypeNucleus)
{
	//this->id = globalObject->nextComponent(ComponentTypeNucleus);
	this->nucleusType = nucleusType;
}

Nucleus::~Nucleus(void)
{
}
/*
std::string name;

	std::vector<long> columns;

	Location3D location;
	Size3D area;

	int nucleusType;
*/
void Nucleus::toJSON(std::ofstream& outstream)
{
	std::stringstream ss;
	LOGSTREAM(ss) << "Exporting nucleus..." << std::endl;
	globalObject->log(ss);

	std::string sep("");
	outstream << "        {  \"_type\": \"Nucleus\", \"_name\": \"" << name << "\", \"id\": " << id << ",  \"NucleusType\": " << nucleusType << ",  \"location\": [" << location.x << ", " << location.y << ", " << location.z << "], \"size\": [" << area.h << ", " << area.w << ", " << area.d << "], \"columns\": [" << std::endl;
	for (unsigned int i = 0; i < columns.size(); i++)
	{
		outstream << sep;
		sep = ",";
		Column* c = globalObject->columnDB.getComponent(columns[i]);
		c->toJSON(outstream);
	}
	outstream << "        ] } " << std::endl;

}


void Nucleus::save(void)
{
	globalObject->nucleusDB.save(this);
}

void Nucleus::commit(void)
{
	globalObject->nucleusDB.addToCache(this);
}



Nucleus *Nucleus::create(std::string name, SpatialDetails details, int nucleusType, bool setToDirty)
{
	Nucleus *n = new Nucleus(nucleusType);
	n->name = name;

	n->location = details.location;
	n->area = details.area;
	n->parentId=0;
	n->id = globalObject->nextComponent(ComponentTypeNucleus);

	globalObject->insert(n);
	if(setToDirty)
		n->setDirty();

	std::stringstream ss;
	LOGSTREAM(ss) << "  Nucleus " << n->name << " (" << n->id << ") created." << std::endl;
	globalObject->log(ss);
	return n;
}


void Nucleus::receiveInputFrom(Nucleus *nucleus, float sparsity, float polarity)
{
	size_t cSize1 = columns.size();
	size_t cSize2 = nucleus->columns.size();
	//size_t cMax = cSize1 * cSize2;
	//size_t cNumber = 0;
	std::stringstream ss;
	for(size_t i=0;i<cSize1;i++)
	{
		long c1id = columns[i];

		Column *col1 = globalObject->columnDB.getComponent(c1id);
		for(size_t j=0;j<cSize2;j++)
		{
			long c2id = nucleus->columns[j];

			Column *col2 = NULL;
			if(c1id == c2id) 
				col2 = col1;
			else
				col2 = globalObject->columnDB.getComponent(c2id);
//			size_t pct = (cNumber*100) / cMax;
//			LOGSTREAM(ss) << "      Column " << col1->id << " receiving input from " << col2->id << "... (" << cNumber++ << " of " << cMax << " - " << pct << "%) " << std::endl;
//			globalObject->log(ss);

			col1->receiveInputFrom(col2,sparsity,polarity);
		}
	}
}

long Nucleus::getStartNeuron(void)
{
	size_t cSize = columns.size();
	if(cSize==0)
		return 0;

	long cId = columns[0];
	Column *col = globalObject->columnDB.getComponent(cId);
	return col->getStartNeuron();
}

long Nucleus::getEndNeuron(void)
{
	size_t cSize = columns.size();
	if(cSize==0)
		return 0;

	long cId = columns[cSize-1];
	Column *col = globalObject->columnDB.getComponent(cId);
	return col->getEndNeuron();
}

Nucleus *Nucleus::instantiate(long key, size_t len, void *data)
{

	long columnCount = 0;
	Nucleus *nucleus = new Nucleus(0);
	nucleus->id = key;

	char *ptr = (char*)data;

	memcpy(&nucleus->parentId, ptr, sizeof(nucleus->parentId)); 	ptr += sizeof(nucleus->parentId);
	memcpy(&nucleus->location.x, ptr, sizeof(nucleus->location.x)); 	ptr += sizeof(nucleus->location.x);
	memcpy(&nucleus->location.y, ptr, sizeof(nucleus->location.y)); 	ptr += sizeof(nucleus->location.y);
	memcpy(&nucleus->location.z, ptr, sizeof(nucleus->location.z)); 	ptr += sizeof(nucleus->location.z);
	memcpy(&nucleus->area.h, ptr, sizeof(area.h)); 	ptr += sizeof(area.h);
	memcpy(&nucleus->area.w, ptr, sizeof(area.w)); 	ptr += sizeof(area.w);
	memcpy(&nucleus->area.d, ptr, sizeof(area.d)); 	ptr += sizeof(area.d);
	memcpy(&columnCount,ptr,sizeof(columnCount)); 	ptr+=sizeof(columnCount);

	for(size_t i=0;i<(size_t)columnCount;i++)
	{
		long cid = 0;
		memcpy(&cid,ptr,sizeof(cid));
		nucleus->columns.push_back(cid);
		ptr+=sizeof(cid);
	}

	char* end = (char*)data + len;
	size_t sz = (end - ptr) + 1; // compute size of string +1
	char* buff = (char*)globalObject->allocClearedMemory(sz);
	strncpy(buff, ptr, sz);
	std::string temp(buff);
	nucleus->name = temp;

//	printf("instantiate: Nucleus %i columnssize %i\n",(int)nucleus->id,(int)nucleus->columns.size());

	return nucleus;
}

Tuple *Nucleus::getImage(void)
{
/* -- persisted values
	u_int32_t columnCount;
	std::vector<long> columns;
*/
//	printf("GetImage: Nucleus %i columnssize %i\n",(int)this->id,(int)columns.size());

	long columnCount = columns.size();
	size_t namesize = name.length()+1;
	size_t size = sizeof(parentId) + sizeof(location.x) + sizeof(location.y) + sizeof(location.z) +
		sizeof(area.h) + sizeof(area.w) + sizeof(area.d) + sizeof(columnCount) + (columnCount * sizeof(long)) + namesize;
	
		
	char *image = globalObject->allocClearedMemory(size);
	char *ptr = (char*)image;

	memcpy(ptr, &parentId, sizeof(parentId)); ptr += sizeof(parentId);
	memcpy(ptr, &location.x, sizeof(location.x)); 	ptr += sizeof(location.x);
	memcpy(ptr, &location.y, sizeof(location.y)); 	ptr += sizeof(location.y);
	memcpy(ptr, &location.z, sizeof(location.z)); 	ptr += sizeof(location.z);
	memcpy(ptr, &area.h, sizeof(area.h)); 	ptr += sizeof(area.h);
	memcpy(ptr, &area.w, sizeof(area.w)); 	ptr += sizeof(area.w);
	memcpy(ptr, &area.d, sizeof(area.d)); 	ptr += sizeof(area.d);
	memcpy(ptr, &columnCount,sizeof(columnCount)); 	ptr+=sizeof(columnCount);

	for(size_t i=0;i<(size_t)columnCount;i++)
	{
		long k = columns[i];
		memcpy(ptr,&k,sizeof(k));
		ptr+=sizeof(k);
	}


	strncpy(ptr,name.c_str(),namesize);
	ptr += (namesize + 1);

	Tuple* tuple = new Tuple();
	tuple->objectPtr = image;
	tuple->value = size;

	return tuple;
}

void Nucleus::addColumns(size_t colCount, size_t layerCount, size_t clusterCount, size_t neuronCount)
{
	for(size_t i=0;i<colCount;i++) 
	{
		SpatialDetails sdr(this->location, this->area);
		sdr.randomizeLocation();
		Column *c = Column::create(sdr,layerCount, this->id);
		size_t lSize = c->layers.size();
		for(size_t k1=0;k1<lSize;k1++)
		{
			Layer *layer = globalObject->layerDB.getComponent(c->layers[k1]);
			for(size_t i5=0;i5<clusterCount;i5++) 
			{

				Cluster *cl = Cluster::create(sdr,this->id);
				cl->parentId = this->id;
				float offset = (float) ((abs(area.h) / layerCount) / 2);
				for(size_t i6=0;i6<neuronCount;i6++) 
				{
					float newX = sdr.location.x + ((float)(tr1random->generate(1, (int)abs(area.w))));
					float newY = sdr.location.y+(offset*(float)k1);
					float newZ = sdr.location.z + ((float)(tr1random->generate(1, (int)abs(area.d))));
					Location3D loc2(newX,newY,newZ);
					SpatialDetails sdd(loc2,this->area);
					Neuron *neur = Neuron::create(sdd, Pyramidal,cl->id, this->nucleusType);
					cl->getNeurons().push_back(neur->id);
					cl->setDirty();

//					std::cout << "Neuron (" << sdd.location.x << "," << sdd.location.y << "," << sdd.location.z << "), ";
//					std::cout << this->name << " (" << this->location.x << "," << this->location.y << "," << this->location.z << ") " << std::endl;
				}
				layer->clusters.push_back(cl->id);
				layer->setDirty();
			}
		}
		columns.push_back(c->id);
	}
	setDirty(true);
}


// ============== Nucleus.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include "NNComponent.h"
#include <map>
#include "Column.h"
#include "ColumnNeuronProfile.h"
#include "Location3D.h"
#include "Size3D.h"
#include "SpatialDetails.h"

// polarity - defined here because for some reason it can't see it in Global.h
#define EXCITATORY_SYNAPSE 1.0f
#define INHIBITORY_SYNAPSE -1.0f

class Nucleus: public NNComponent
{
	Nucleus(int nucleusType);
    friend class boost::serialization::access;
    // When the class Archive corresponds to an output archive, the
    // & operator is defined similar to <<.  Likewise, when the class Archive
    // is a type of input archive the & operator is defined similar to >>.
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
	{
		ar & boost::serialization::base_object<NNComponent>(*this);
		for(unsigned int i=0;i<columns.size();i++)
		{
			ar & columns[i];
		}
/*
		std::map<long,Column *>::iterator itColumn = columns.begin();
		for (itColumn=columns.begin(); itColumn!=columns.end(); ++itColumn)
		{
			ar & itColumn->second;
		}
*/
	}
public:
	virtual ~Nucleus(void);
	static Nucleus *create(std::string name, SpatialDetails details, int nucleusType= INTER_NUCLEUS, bool setToDirty=true);

	static Nucleus *instantiate(long key, size_t len, void *data);
	Tuple *getImage(void);

	void receiveInputFrom(Nucleus *nucleus, float sparsity=100.0f, float polarity=EXCITATORY_SYNAPSE);

	void addColumns(size_t colCount, size_t layerCount, size_t clusterCount, size_t neuronCount);

	void toJSON(std::ofstream& outstream);


	long getStartNeuron(void);
	long getEndNeuron(void);

	std::string name;

	std::vector<long> columns;

	Location3D location;
	Size3D area;

	int nucleusType;

private:
	void save(void);
	void commit(void);

};


// ============== ParseJSON.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <iostream>
#include <iomanip>
#include "Global.h"
#include "ParseJSON.h"
#include "TR1Random.h"
#include "nlohmann/json.hpp"

using json = nlohmann::json;

Brain* brainPtr = NULL;
Brain* ParseJSON::loadFromJSON(std::string dbPath, std::string modelName)
{

	tr1random = new TR1Random();
	globalObject->brainDB.begin();
	Brain *brain = Brain::create(false,"../../../database/","DetailTest");
    brainPtr = brain;

	// begin loading JSON
	std::string jsonfilename(std::string(globalObject->getDBPath()) +  globalObject->getModelName() + std::string("/") + "serialized.json");

    // define parser callback
    json::parser_callback_t cb = [](int depth, json::parse_event_t event, json& parsed)
    {
        (void)depth;
        // skip object elements with key "Thumbnail"
        // Start with Brain level object
        int level = 0;

        std::string lastKey;
        std::string lastValue;

        switch (event) {
        case json::parse_event_t::object_start:
            return false;
            break;
        case json::parse_event_t::key:
            lastKey = parsed;
            return false;
            break;
        case json::parse_event_t::value:
            lastValue = parsed;
            if (lastKey == "id" ) 
            {
                if (level == 0) // Brain Level
                {
                    std::string::size_type sz;   // alias of size_t

                    long li_dec = std::stol(lastValue, &sz);
                    brainPtr->id = li_dec;
                }
            }
            return false;
            break;
        case json::parse_event_t::array_start:
            return false;
            break;
        case json::parse_event_t::array_end:
            return false;
            break;
        case json::parse_event_t::object_end:
            return false;
            break;
        default: 
            return true;
        }

    };

    // parse (with callback) and serialize JSON
    json j_filtered = json::parse(jsonfilename, cb);
    std::cout << std::setw(4) << j_filtered << std::endl;

	return brain;
}


// ============== ParseJSON.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include "Brain.h"

class ParseJSON
{
	Brain* loadFromJSON(std::string dbPath, std::string modelName);
};



// ============== Process.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "Global.h"
#include "Process.h"

// Settable externs
extern long FIRING_WINDOW;
extern long PROPAGATION_DELAY_MICROSECONDS;
extern double DECAY_FACTOR;
extern long REFACTORY_PERIOD;
extern float WEIGHT_GRADATION;
extern float RATE_GRADATION;


Process::Process(ComponentType type): 
	NNComponent(type)
{
}

Process::~Process(void)
{
}

float Process::getRate(void)
{
	return rate;
}

void Process::setRate(float value, bool calc) 
{ 
	return; // Just ignore rate modification for now

	if(!calc)
	{
		rate = value;
		return;
	}
	
	float oldrate = rate;
	if(rate != value) 
	{
		boost::mutex::scoped_lock  amx(process_mutex);

		rateUpdateCounter++;

		//		std::cout << "Synapse::setWeight Synapse: " << id << " adjusting weight from " << weight << " to " << value << std::endl;

		float diff = rate - value;
		//dampen the actual value so that the weight changes more slowly over time 
		// calculate weightFactor, which should initially be a value of 1, followed by 0.5, followed by 0.333 etc

		// set rateFactor to 1 to remove any rate gradation from occurring
		float rateFactor = 1.0f; // (RATE_GRADATION / rateUpdateCounter); //  / RATE_GRADATION;
		// take the difference in value and weight it based on weightFactor
		float delta = diff * rateFactor;

		float adjustedRate = rate + delta; // calc the adjusted weight 

		//std::cout << "Process " << this->id << " rate chg from " << this->rate << " to " << value << std::endl;

		if(adjustedRate > MAXIMUM_DENDRITE_RATE)
		{
			rate = MAXIMUM_DENDRITE_RATE;
			 // std::cout << "Rate Error: " << rate << std::endl;
		} else if(adjustedRate < -MAXIMUM_DENDRITE_RATE) 
		{
			rate = -MAXIMUM_DENDRITE_RATE;
		}
		else 
		{
			rate = adjustedRate;
		}
		setDirty(true); 

//  log upstream rather than here becuasue it has more info (eg pre or post)
		if(globalObject->logEvents) 
		{
			long thisId = 0;
			std::stringstream ss;
			if(this->id >= globalObject->componentBase[ComponentTypeAxon] && this->id < globalObject->componentBase[ComponentTypeDendrite])
			{ // axon
				Axon *a = (Axon *)this;
				thisId = a->id;
				ss << "axon__change_rate_change: component=" << thisId << ", oldrate=" << oldrate << ", newrate=" << rate << ", neuron=" << a->neuronId;
			}
			else
			{ // dendrite
				Dendrite *d = (Dendrite *)this;
				thisId = d->id;

				std::stringstream ss;
				ss << "dendrite_change_rate_change: component=" << thisId << ", oldrate=" << oldrate << ", newrate=" << rate << ", presynapticneuron=" << d->getPreSynapticNeuronId() << ", postsynapticneuron=" << d->getPostSynapticNeuronId();

			}
			globalObject->writeEventLog(ss.str().c_str());
		}
	}
}

// ============== Process.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <boost/thread.hpp>
#include <boost/asio.hpp>
#include <boost/asio/post.hpp>
#include <boost/asio/thread_pool.hpp>

#include "NNComponent.h"

class Process: public NNComponent
{
public:
	Process(ComponentType type=ComponentTypeUnknown);
	virtual ~Process(void);
	inline float getDistance(void) { return distance; };
	inline void setDistance(float value) { 
		if (value < 0) {
			value = 0.1f;  // Kludge to prevent negaive index
		}
		distance = value; 
		setDirty(true); 
	};
	float getRate(void);
	 void setRate(float value, bool calc=true); 

	float rateUpdateCounter;

private:
	float distance = 0;
	float rate = 0;

	boost::mutex process_mutex;

};


// ============== Range.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
class Range
{
public:
	long low;
	long high;
};



// ============== Region.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <time.h>

#include "Region.h"
#include "TR1Random.h"
#include "Global.h"

Region::Region(void):
	NNComponent(ComponentTypeRegion)
{
}
 
Region::~Region(void)
{
}
/*
	std::string name;

	std::vector<long> nuclei;

	Location3D location;
	Size3D area;

*/
void Region::toJSON(std::ofstream& outstream)
{
	std::stringstream ss;
	LOGSTREAM(ss) << "Exporting region..." << std::endl;
	globalObject->log(ss);

	std::string sep("");
	outstream << "    { \"_type\": \"Region\", \"_name\": \"" << name << "\", \"id\": " << id << ", \"location\": [" << location.x  << ", " << location.y << ", " << location.z << "], \"size\": [" << area.h << ", " << area.w << ", " << area.d << "],  \"nuclei\": [ " << std::endl;
	long nucsz = this->nuclei.size();
	for (unsigned int i = 0; i < nucsz; i++)
	{
		outstream << sep;
		sep = ",";
		Nucleus* n = globalObject->nucleusDB.getComponent(nuclei[i]);
		n->toJSON(outstream);
	}
	outstream << "    ] } " << std::endl;

}



void Region::save(void)
{
	globalObject->regionDB.save(this);
}

void Region::commit(void)
{
	globalObject->regionDB.addToCache(this);
}


Region *Region::create(std::string name, SpatialDetails details, bool setToDirty)
{
	Region *reg = new Region();
	reg->name = name;
	reg->id = globalObject->nextComponent(ComponentTypeRegion);
	reg->location = details.location;
	reg->area= details.area;

	globalObject->insert(reg);
	if(setToDirty)
		reg->setDirty();

	std::stringstream ss;
	LOGSTREAM(ss) << "Region " << reg->name << " (" << reg->id << ") created." << std::endl;
	globalObject->log(ss);
	return reg;
}


void Region::receiveInputFrom(Region *region, float sparsity, float polarity)
{
	std::stringstream ss;
	size_t nSize = nuclei.size();
	size_t nSize2 = region->nuclei.size();
	size_t nMax = nSize * nSize2;
	size_t nCount = 0;

	LOGSTREAM(ss) << "   Input region (" << this->name << ") containing  " << nSize << " nuclei, from region (" << region->name << ") containing " << nSize2 << " nuclei .." << std::endl;
	globalObject->log(ss);

	for(size_t i=0;i<nSize;i++)
	{
		Nucleus *nuc1 = globalObject->nucleusDB.getComponent(nuclei[i]);
		for(size_t j=0;j<nSize2;j++)
		{
			Nucleus *nuc2 = globalObject->nucleusDB.getComponent(region->nuclei[j]);

			size_t pct = (nCount++)*100/nMax;
//			std::cout << "   recieveInputFrom Nucleus " << nuc1->id << " to " << nuc2->id << "..." << std::endl;
			LOGSTREAM(ss) << "   Connecting receiving Nucleus " << nuc1->name << " [" << nuc1->id << "] to output nucleus " << nuc2->name << " [" << nuc2->id << "] (" << nCount << " of " << nMax << " - " << pct << "%) .." << std::endl;
			globalObject->log(ss);

			nuc1->receiveInputFrom(nuc2,sparsity, polarity);
		}
	}
}
/*
void Region::removeDeadAPs(void)
{
	globalObject->removeDeadAPs();
}
*/

long Region::getStartNeuron(void)
{
	size_t nSize = nuclei.size();
	if(nSize==0)
		return 0;

	long nucId = nuclei[0];
	Nucleus *nuc = globalObject->nucleusDB.getComponent(nucId);
	return nuc->getStartNeuron();
}

long Region::getEndNeuron(void)
{
	size_t nSize = nuclei.size();
	if(nSize==0)
		return 0;

	long nucId = nuclei[nSize-1];
	Nucleus *nuc = globalObject->nucleusDB.getComponent(nucId);
	return nuc->getEndNeuron();
}

Region *Region::instantiate(long key, size_t len, void *data)
{
// 	u_int32_t size = sizeof(float)+sizeof(float)+sizeof(long)+sizeof(long);


	std::stringstream ss;
	long nucleiCount = 0;

	Region *region = new Region();
	region->id = key;

	char *ptr = (char*)data;

	memcpy(&region->location.x, ptr, sizeof(location.x)); 	ptr += sizeof(location.x);
	memcpy(&region->location.y, ptr, sizeof(location.y)); 	ptr += sizeof(location.y);
	memcpy(&region->location.z, ptr, sizeof(location.z)); 	ptr += sizeof(location.z);
	memcpy(&region->area.h, ptr, sizeof(area.h)); 	ptr += sizeof(area.h);
	memcpy(&region->area.w, ptr, sizeof(area.w)); 	ptr += sizeof(area.w);
	memcpy(&region->area.d, ptr, sizeof(area.d)); 	ptr += sizeof(area.d);
	memcpy(&nucleiCount, ptr, sizeof(nucleiCount)); 	ptr +=sizeof(nucleiCount);

	for(size_t i=0;i<(size_t)nucleiCount;i++)
	{
		long nid = 0;
		memcpy(&nid,ptr,sizeof(nid));
		region->nuclei.push_back(nid);
		ptr+=sizeof(nid);
	}

	char* end = (char *)data + len;
	size_t sz = (end - ptr)+1; // compute size of string +1
	char* buff = (char *)globalObject->allocClearedMemory(sz);
	strncpy(buff,ptr,sz);
	std::string temp(buff);
	region->name = temp;

//	LOGSTREAM(ss) << "Region instantiated with  " << nucleiCount << " nuclei " << std::endl;
//	globalObject->log(ss);

	return region;
}

Tuple *Region::getImage(void)
{
/* -- persisted values
	u_int32_t nucleiCount;
	std::vector<long> nuclei;
*/
//	printf("GetImage: Region %i nucleisize %i\n",(int)this->id,(int)nuclei.size());

	long nucleiCount = nuclei.size();
	size_t namesize = name.length()+1;
	size_t size = sizeof(location.x) + sizeof(location.y) + sizeof(location.z) + sizeof(area.h) + sizeof(area.w) + sizeof(area.d) + sizeof(nucleiCount) + (nucleiCount * sizeof(long)) + namesize;
		
	char *image = globalObject->allocClearedMemory(size);
	char *ptr = (char*)image;

	memcpy(ptr, &location.x, sizeof(location.x)); 	ptr += sizeof(location.x);
	memcpy(ptr, &location.y, sizeof(location.y)); 	ptr += sizeof(location.y);
	memcpy(ptr, &location.z, sizeof(location.z)); 	ptr += sizeof(location.z);
	memcpy(ptr, &area.h, sizeof(area.h)); 	ptr += sizeof(area.h);
	memcpy(ptr, &area.w, sizeof(area.w)); 	ptr += sizeof(area.w);
	memcpy(ptr, &area.d, sizeof(area.d)); 	ptr += sizeof(area.d);
	memcpy(ptr,&nucleiCount,sizeof(nucleiCount)); 	ptr+=sizeof(nucleiCount);

	for(size_t i=0;i<(size_t)nucleiCount;i++)
	{
		long k = nuclei[i];
		memcpy(ptr,&k,sizeof(k));
		ptr+=sizeof(k);
	}
	strncpy(ptr,name.c_str(),namesize);
	ptr += (namesize+1);

	Tuple* tuple = new Tuple();
	tuple->objectPtr = image;
	tuple->value = size;

	return tuple;
}

void Region::add(Nucleus *nucleus)
{
	nuclei.push_back(nucleus->id);
	setDirty(true);
}

size_t Region::getNeuronCount()
{
	size_t neuronCount = 0;
	for(long nucId : nuclei)
	{
		Nucleus *nucleus = globalObject->nucleusDB.getComponent(nucId);
		neuronCount += (size_t)(nucleus->getEndNeuron() - nucleus->getStartNeuron());

	}
	return neuronCount;
}

// ============== Region.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include "NNComponent.h"
#include <map>
#include "Location3D.h"
#include "Size3D.h"
#include "SpatialDetails.h"
#include "Nucleus.h"



// polarity - defined here because for some reason it can't see it in Global.h
#define EXCITATORY 1.0f
#define INHIBITORY -1.0f

class Region: public NNComponent
{
	Region(void);
    friend class boost::serialization::access;
    // When the class Archive corresponds to an output archive, the
    // & operator is defined similar to <<.  Likewise, when the class Archive
    // is a type of input archive the & operator is defined similar to >>.
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
	{
		ar & boost::serialization::base_object<NNComponent>(*this);
		for(unsigned int i=0;i<nuclei.size();i++)
		{
			ar & nuclei[i];
		}
//		std::map<long,Nucleus *>::iterator itNucleus = nuclei.begin();
		/*
		for (std::map<long,Nucleus *>::iterator itNucleus=nuclei.begin(); itNucleus!=nuclei.end(); ++itNucleus)
		{
			ar & itNucleus->second;
		}
*/
	}

public:
	virtual ~Region(void);
	static Region* create(std::string name, SpatialDetails details, bool setToDirty = true);

	static Region *instantiate(long key, size_t len, void *data);
	Tuple *getImage(void);


	void receiveInputFrom(Region *region, float sparsity=100.0f, float polarity=EXCITATORY_SYNAPSE);

	void add(Nucleus *nucleus);

	void toJSON(std::ofstream& outstream);

	long getStartNeuron(void);
	long getEndNeuron(void);

	size_t getNeuronCount();


	std::string name;

	std::vector<long> nuclei;

	Location3D location;
	Size3D area;
private: 
	void save(void);
	void commit(void);

};


// ============== SNNEngine.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

// SNNEngine.cpp : Defines the entry point for the console application.
//

// Define the BrainDemo code for this run
#include "stdafx.h"
#include <stdlib.h>     
#include <stdio.h>
#include <unistd.h>
#include <map>
#include <iostream>
#include <boost/thread.hpp>
#include <boost/filesystem.hpp>
// #define the two following only in one source file prior to the #includes for Global and TR1Random
#define noexternglobal 1
#define noexterntr1random 1
#include "SNNEngine.h"
#include "Global.h"
#include "TR1Random.h"
#include "SNNVisualizer.h"
Global *globalObject;				// Global object
TR1Random *tr1random;		// TR1 Random object
SNNVisualizer *snnVisualizer;
Brain *brain;
bool keepRunning = true;
bool stillRunning = true;

//


#include "Brain.h"
#include "DetailTest.h"
#include "BrainDemoTiny.h"
#include "BrainUnitTest.h"

#include "ComponentCollection.h"

// The variables below can be changed on the fly via the SETVALUE rest interface command
// example JSON format is { "command": "SETVALUE", "name": "FIRING_WINDOW", "value": 10 }

// set initial FIRING WINDOW to slightly longer than refactory period
long FIRING_WINDOW = 10;

long PROPAGATION_DELAY_MICROSECONDS = 10;

double DECAY_FACTOR = 0.01;

long REFACTORY_PERIOD = 20;

// WEIGHT_GRADATION is used to slow the rate of change for weight over time (defined by n updates)
float WEIGHT_GRADATION = 100000.0f;

// RATE_GRADATION is used to slow the rate of change for rate over time (defined by n updates)
float RATE_GRADATION = 100000.0f;



inline bool exists(const std::string& name) {
	//    ifstream f(name.c_str());
	//	bool doesExist = f.good(); 

	boost::filesystem::path myfile(name);
	bool doesExist = boost::filesystem::exists(myfile);
	return doesExist;
}

void mainRoutine(void)
{

    pid_t tid = syscall(SYS_gettid);
    std::cout << "SNNEngine.mainRoutine thread is " << tid << std::endl;

	std::stringstream ss;
/*	
	bool rebuildFromScratch = false;
	bool rebuildFromJSON = false;
	std::string syncfilename(std::string(globalObject->getDBPath()) +  globalObject->getModelName() + std::string("/") + "syncpoint.txt");
	std::string jsonfilename(std::string(globalObject->getDBPath()) +  globalObject->getModelName() + std::string("/") + "serialized.json");

	rebuildFromScratch = !exists(syncfilename);
	//rebuildFromJSON = exists(jsonfilename);
	rebuildFromJSON = false;
	if (rebuildFromJSON) {
		brain = MODEL_IMPLEMENTATION_CLASS::createFromJSON();
	}
	else {
		brain = MODEL_IMPLEMENTATION_CLASS::create(rebuildFromScratch);
	}
*/
	LOGSTREAM(ss) << "Starting background threads..." << std::endl;
	globalObject->log(ss);

	brain->startServer();
	brain->startNeuronProcessing();
	brain->startTimerProcessing();

	bool showStatus = false;
	//	while(globalObject->getCurrentTimestamp()<10000)

	globalObject->startRealTime = boost::posix_time::microsec_clock::local_time();
	
	while (keepRunning)
	{

//		brain->step();
//		MODEL_IMPLEMENTATION_CLASS::step(brain);

		std::string msg = globalObject->getMessage();
		if (!msg.empty())
		{
			/// begin processing messages
			if (msg == "flush") {
				LOGSTREAM(ss) << "Beginning flush..." << std::endl;
					globalObject->log(ss);
					globalObject->flush();
					LOGSTREAM(ss) << "Flush complete..." << std::endl;
					globalObject->log(ss);
			}
			if (msg == "help") {
				printf("report, longreport, export, exit, shutdown, logfiring, nologfiring, time, showstatus, timesync, excite nnn \n");
			}

			if (msg == "report") {
				brain->report();
			}
			if (msg == "longreport") {
				brain->longReport();
			}
			if (msg == "export") {
				brain->exportJSON();
			}
			if (msg == "exit") {
				keepRunning = false;
			}
			if (msg == "shutdown") {
				keepRunning = false;
			}
			if (msg == "logfiring") {
				globalObject->setLogFiring = true;
				LOGSTREAM(ss) << "Fire logging ON..." << std::endl;
				globalObject->log(ss);
			}
			if (msg == "nologfiring") {
				globalObject->setLogFiring = false;
				LOGSTREAM(ss) << "Fire logging OFF..." << std::endl;
				globalObject->log(ss);
			}
			if (msg == "time" ) {
				// show time
				boost::posix_time::ptime nowTime = boost::posix_time::microsec_clock::local_time();
				boost::posix_time::time_duration msdiff = nowTime - globalObject->startRealTime;
				long ct = globalObject->getCurrentTimestamp();
				long elapse = (long)msdiff.total_milliseconds() - brain->timeAdjust;
				float rate = (float)elapse / (float)ct;
				printf("timeslices %ld, elaspsed ms %ld, rate %f \n", ct, elapse, rate);
			}
			if (msg == "showstatus") {
				showStatus = !showStatus;
			}
			if (msg == "timesync") {
				boost::posix_time::ptime nowTime = boost::posix_time::microsec_clock::local_time();
				boost::posix_time::time_duration msdiff = nowTime - globalObject->startRealTime;
				long elapse = (long)msdiff.total_milliseconds();
				brain->timeAdjust = elapse - globalObject->getCurrentTimestamp();
				printf("timeAdjust set to %ld \n", brain->timeAdjust);
			}
			if (msg.substr(0,7) == "excite ") {
    			size_t spacePos = msg.find(' ');
    			if (spacePos == std::string::npos) {
        			std::cerr << "Invalid input format. Expected: \"keyword parameter\"" << std::endl;
    			} else {
					std::string parameterStr = msg.substr(spacePos + 1);
    				try {
        				// Convert the parameter string to an integer
        				int num = std::stoi(parameterStr);
						brain->excite(num);
	    			} catch (const std::invalid_argument& e) {
    	    			std::cerr << "Error converting parameter to int: " << e.what() << std::endl;
    				}
				}
			}
		}

		if (showStatus) {
			unsigned long ts = globalObject->getCurrentTimestamp();
			int intervalOffsetValue = ts % MAX_TIMEINTERVAL_BUFFER_SIZE;
			std::cout << "mainroutine Locking teVector_mutex[" << intervalOffsetValue << "]" << std::endl;
			boost::mutex::scoped_lock amx(*(globalObject->teVector_mutex[intervalOffsetValue]));
			std::vector<TimedEvent *> *teVector = &globalObject->timeIntervalEvents[intervalOffsetValue];
			int aps = teVector[intervalOffsetValue].size();;
			//int aps = (int)globalObject->timedEventSize();
			printf("%ld - [%d]. - %d\r", ts, intervalOffsetValue, aps);
			std::cout << "mainroutine UnLocking teVector_mutex[" << intervalOffsetValue << "]" << std::endl;
		}

	}



	LOGSTREAM(ss) << "Shutdown detected during simulation at timestep " << globalObject->getCurrentTimestamp() << "..." << std::endl;
	globalObject->log(ss);

	brain->stopNeuronProcessing();

	brain->stopServer();

	brain->shutdown();

	LOGSTREAM(ss) << "Background thread ended..." << std::endl;
	globalObject->log(ss);

	stillRunning = false;

}


//int main(int argc, char *argv[])
void SNNEngine::initialize(std::string dbPath, std::string modelName)
{
	std::stringstream ss;

	globalObject = new Global(dbPath,modelName);


	LOGSTREAM(ss) << "Begin execution..." << std::endl;
	globalObject->log(ss);

	bool rebuildFromJSON = false;
	globalObject->setModelName(modelName);
	globalObject->setDBPath(dbPath);
	std::string jsonfilename(dbPath +  modelName + std::string("/") + "serialized.json");

	std::string syncfilename(dbPath +  modelName + std::string("/") + "syncpoint.txt");
	bool rebuildFromScratch = !exists(syncfilename);

	//rebuildFromJSON = exists(jsonfilename);
	rebuildFromJSON = false;
	if (rebuildFromJSON) {
		brain = MODEL_IMPLEMENTATION_CLASS::createFromJSON();
		globalObject->readCounters();
	}
	else {
		brain = MODEL_IMPLEMENTATION_CLASS::create(rebuildFromScratch);
	}

	globalObject->writeCounters();

}

void SNNEngine::startEngine(void)
{
	std::stringstream ss;


	boost::thread t(&mainRoutine);


	std::locale loc;
	std::string command("");
	bool exit = false;

	LOGSTREAM(ss) << "Command line ready for input (x to terminate)..." << std::endl;
	globalObject->log(ss);

	SNNVisualizer *sv = new SNNVisualizer();
	sv->thisBrain = brain;

	LOGSTREAM(ss) << "Starting SNNVisualizer thread..." << std::endl;
	globalObject->log(ss);

	globalObject->brain->startSNNVisualizer();


	while (!exit)
	{
		//cin >> command;
		std::getline(std::cin, command);

		ss.str(""); ss.clear();
		LOGSTREAM(ss) << command << " command presented." << std::endl;
		globalObject->log(ss);


		ss.str(""); ss.clear();
		for (std::string::size_type i = 0; i<command.length(); ++i)
			ss << std::tolower(command[i], loc);
		command = ss.str();
		ss.str(""); ss.clear();
		LOGSTREAM(ss) << "Command [" << command << "] accepted..." << std::endl;
		globalObject->log(ss);

		if (command == "exit" || command == "shutdown")
		{

			ss.str(""); ss.clear();
			LOGSTREAM(ss) << command << " command accepted." << std::endl;
			globalObject->log(ss);

			globalObject->putMessage(command);

			while (stillRunning) {
    			usleep(5000); // usleep takes time in microseconds
			}

			ss.str(""); ss.clear();
			LOGSTREAM(ss) << command << " command processing Complete." << std::endl;
			globalObject->log(ss);
/*
			try {
				globalObject->closeFireLog();
			} catch(...) {}
			try {
				globalObject->closeDebugLog();
			} catch(...) {}
*/
			keepRunning = false;
			exit = true;
		}
		else
			if (command == "help")
			{
				globalObject->putMessage("help");
			}
			else if (command == "report")
			{
				globalObject->putMessage("report");
			}
			else if (command == "export")
			{
				globalObject->putMessage("export");
			}
			else if (command == "longreport")
			{
				globalObject->putMessage("longreport");
			}
			else if (command == "flush")
			{
				globalObject->putMessage("flush");
			}
			else if (command == "showstatus")
			{
				globalObject->putMessage("showstatus");
			}
			else if (command == "time")
			{
				globalObject->putMessage("time");
			}
			else if (command == "timesync")
			{
				globalObject->putMessage("timesync");
			}
			else if (command == "logfiring")
			{
				globalObject->putMessage("logfiring");
			}
			else if (command == "nologfiring")
			{
				globalObject->putMessage("nologfiring");
			}
			else if (command.substr(0,7) == "excite ")
			{
				globalObject->putMessage(command);
			}
			else
			{
				ss.str(""); ss.clear();
				LOGSTREAM(ss) << "Command not recognized." << std::endl;
				globalObject->log(ss);
			}
	}

	LOGSTREAM(ss) << "Termination requested..." << std::endl;
	globalObject->log(ss);

	// Ask thread to stop
	t.interrupt();

	// Join - wait when thread actually exits
	t.join();

	LOGSTREAM(ss) << "Main: thread ended..." << std::endl;
	globalObject->log(ss);

	return;
}



// ============== SNNEngine.h ==============
#include <string>

class SNNEngine {
public:    
    void initialize(std::string dbPath, std::string modelName);
    void startEngine(void);
};

// ============== SNNVisualizer.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <cmath>  // Include this at the top of your file
#include "Global.h"
#include "SNNVisualizer.h"

extern SNNVisualizer *snnVisualizer;

int windowWidth = 1920;
int windowHeight = 1080;

// Lighting properties
GLfloat lightPosition[] = { 1.0f, 1.0f, 1.0f, 0.0f };
GLfloat lightAmbient[] = { 0.2f, 0.2f, 0.2f, 1.0f };
GLfloat lightDiffuse[] = { 0.8f, 0.8f, 0.8f, 1.0f };
GLfloat lightSpecular[] = { 1.0f, 1.0f, 1.0f, 1.0f };

// Material properties for neurons
GLfloat matAmbient[] = { 0.2f, 0.3f, 0.8f, 1.0f };
GLfloat matDiffuse[] = { 0.2f, 0.3f, 0.8f, 1.0f };
GLfloat matSpecular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat matShininess[] = { 50.0f };

//static float centerX, centerY, centerZ;
static float lookAtX, lookAtY, lookAtZ;
static float cameraPosX, cameraPosY, cameraPosZ;  // Camera position
float cameraZoom = 10.0f;  // Initial distance of the camera from the scene

cv::VideoWriter videoWriter;
bool isCapturing = false;
bool showDendrites = false;
int videoSuffix = 0;

// Forward declaration
class VisNeuron;

// Synapse class represents a connection point between an axon and a dendrite
class VisSynapse {
public:
    long id;
    VisNeuron* from;  // Source neuron providing input via axon
    VisNeuron* to;    // Target neuron receiving input via dendrite

    VisSynapse(VisNeuron* from, VisNeuron* to) : from(from), to(to) {}
};

// Neuron class representing a neuron with axon and dendrites
class VisNeuron {
public:
    long id;
    float x, y, z;                  // Position in 3D space
    bool isFiring;                  // Whether the neuron is firing
    float rnotfiring,gnotfiring,bnotfiring;
    float rfiring,gfiring,bfiring;
    std::map<long, VisSynapse*> dendrites;  // Incoming connections (dendrites)

    VisNeuron(float x, float y, float z) : x(x), y(y), z(z), isFiring(false) {
        rfiring=1.0;
        gfiring=0.0;
        bfiring=0.0;

        rnotfiring=0.0;
        gnotfiring=1.0;
        bnotfiring=0.0;
    }

    // Fire the neuron
    void fire() {
        isFiring = true;
    }

    // Stop firing
    void stopFiring() {
        isFiring = false;
    }

    // Draw the neuron as a sphere with an axon line extending outward
    void drawNeuron() {
        // Draw the neuron body


        glPushMatrix();
        glTranslatef(x, y, z);  // Position the neuron
        //glColor3f(neuron->r, neuron->g, neuron->b);     // Set color (using neuron properties)
        glColor3f(isFiring ? rfiring : rnotfiring, isFiring ? gfiring : gnotfiring, isFiring ? bfiring : bnotfiring);  // Red if firing, green otherwise
        //glColor3f(0.8, 0.8, 0.8);    // grey  // Set color (using neuron properties)
        glutSolidSphere(0.01, 20, 20);  // Render the neuron as a solid 3D sphere
        glPopMatrix();

        if(showDendrites) {
            // Draw axon as a green line extending from the neuron
            glBegin(GL_LINES);
            glColor3f(isFiring ? rfiring : rnotfiring, isFiring ? gfiring : gnotfiring, isFiring ? bfiring : bnotfiring);  // Red if firing, green otherwise
            glVertex3f(x, y, z);
            glVertex3f(x + 0.1, y, z);  // Extend axon to a small distance
            glEnd();
        }
    }

    // Draw dendrites (incoming synapses) as yellow lines to the neuron
    void drawDendrites() {
        glColor3f(1.0, 0.0, 0.0);  // Red for active dendrites
        for (const auto& pair : dendrites) {
            VisSynapse *synapse = pair.second;
            if(synapse->to->isFiring && synapse->from->isFiring)
            {
                glBegin(GL_LINES);
                glVertex3f(synapse->from->x + 0.1, synapse->from->y, synapse->from->z);  // Axon end of the source neuron
                glVertex3f(x, y, z);  // Target neuron's position
                glEnd();
            }
        }
    }
};

// visbrain class representing the entire neural network
class VisBrain {
public:
    std::map<long,VisNeuron *> neurons;
    std::map<long,VisSynapse*> synapses;

    // Add a neuron to the visbrain
    void addNeuron(VisNeuron* neuron) {
        if(neuron==nullptr) {
            std::cout << "Bad neuron";
        } 
        else
        {
            neurons[neuron->id] = neuron; // .insert(std::make_pair(neuron->id,neuron));

        }
    }


    // Connect two neurons with a synapse from the axon of one to the dendrite of another
    void connect(VisNeuron* from, VisNeuron* to, long synapseId) {
        VisSynapse* synapse = new VisSynapse(from, to);
        if(from!=nullptr && to != nullptr) 
        {
            synapse->id = synapseId;
            from->isFiring = true;  // Example firing state
            to->dendrites[synapse->id] = synapse; // .push_back(synapse);  // Add to target neuron's dendrites
            synapses[synapse->id] = synapse; // .push_back(synapse);       // Store in visbrain's synapses
        }
    }

    // Update the state of neurons (for example, firing)
    void update() {
        // Randomly simulate firing (to be replaced by actual logic)
        for (const auto& pair : neurons) {
            VisNeuron *neuron = pair.second;
            Neuron *n = globalObject->neuronDB.getComponent(neuron->id);
            neuron->isFiring = n->isFiring();
//        for (VisNeuron* neuron : neurons) {
// dont do anything right now
//            neuron->isFiring = (rand() % 2 == 0);
        }
    }

    // Compute bounding box of all neurons for initial view calculations
    void computeBoundingBox(float &minX, float &maxX, float &minY, float &maxY, float &minZ, float &maxZ) {
        if (neurons.empty()) return;
        
        for (const auto& pair : neurons) {
            VisNeuron *neuron = pair.second;
            minX = maxX = neuron->x;
            minY = maxY = neuron->y;
            minZ = maxZ = neuron->z;
            break;
        }

        for (const auto &pair : neurons)
        {
            if (pair.second != nullptr)
            {
                VisNeuron *neuron = pair.second;
                //        for (VisNeuron* neuron : neurons) {
                if (neuron->x < minX)
                    minX = neuron->x;
                if (neuron->x > maxX)
                    maxX = neuron->x;
                if (neuron->y < minY)
                    minY = neuron->y;
                if (neuron->y > maxY)
                    maxY = neuron->y;
                if (neuron->z < minZ)
                    minZ = neuron->z;
                if (neuron->z > maxZ)
                    maxZ = neuron->z;
            }
        }
    }
};

void SNNVisualizer::initVideoWriter() {
        // Close any previous video writer
    if (videoWriter.isOpened()) {
        videoWriter.release();
    }
    // Define the codec and create a VideoWriter object
    std::stringstream ss;
    ss << ++videoSuffix;
    std::string videofilename = std::string(globalObject->getDBPath()) +  globalObject->getModelName() + "/output_" + ss.str() +".avi";
    videoWriter.open(videofilename, cv::VideoWriter::fourcc('M', 'J', 'P', 'G'), 30, cv::Size(windowWidth, windowHeight));
    if (!videoWriter.isOpened()) {
        std::cerr << "Failed to open video writer" << std::endl;
        exit(1);
    }
}

void SNNVisualizer::captureFrame() {

    if(!isCapturing || !videoWriter.isOpened()) {
        return;
    }

    // Allocate a buffer to store the frame data
    int maxbufferX =1920;
    int maxbufferY =1080;
    std::vector<unsigned char> buffer(maxbufferX * maxbufferY * 3);

    // Read the pixels from the frame buffer
    glReadPixels(0, 0, windowWidth, windowHeight, GL_BGR, GL_UNSIGNED_BYTE, buffer.data());


    // Convert buffer to an OpenCV Mat, flipping vertically for OpenCV format
    cv::Mat frame(windowHeight, windowWidth, CV_8UC3, buffer.data());
    cv::flip(frame, frame, 0);  // Flip the frame vertically

    // Write the frame to the video file
    videoWriter.write(frame);
}

void SNNVisualizer::reshape(int width, int height) {
    // Update the global window dimensions
    windowWidth = width;
    windowHeight = height;

    // Reset the viewport and projection to match the new window size
    glViewport(0, 0, width, height);
    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();
    gluPerspective(45.0, (double)width / height, 0.1, 100.0);
    glMatrixMode(GL_MODELVIEW);

    // Reinitialize the video writer with the new dimensions
    if(isCapturing) {
        initVideoWriter();
    }
}


void SNNVisualizer::keyboard(unsigned char key, int x, int y)
{
    if(key=='v' || key=='V') {
        isCapturing = !isCapturing;

        if(isCapturing) {
            initVideoWriter();
            std::stringstream ss;
            ss << videoSuffix;
            std::cout << "Video Capture output_" << ss.str() << " started" << std::endl;
        } else {
            std::stringstream ss;
            ss << videoSuffix;
            std::cout << "Video Capture output_" << ss.str() << " Stopped" << std::endl;
            videoWriter.release();
        }
    } 
    else  if(key=='d' || key=='D') {  // D = display dendrites toggle
        showDendrites = !showDendrites;

    }
}

VisBrain visbrain;


void SNNVisualizer::doWork(void)
{
    int argc = 1;
    char parm[] = "TEST";
    char **argv = nullptr;
	startVisualizer(argc, argv);

}

int SNNVisualizer::waitThread(void)
{
    int ret = waitThreadWorker();
    return ret;
}

int SNNVisualizer::waitThreadWorker(void)
{

    pid_t tid = syscall(SYS_gettid);
    std::cout << "SNNVisualizer thread is " << tid << std::endl;

    doWork();
   
    return 0;
}

void SNNVisualizer::start(void)
{
    boost::thread t(&SNNVisualizer::waitThread, this);
    t.detach(); // Don't Wait for the new thread to finish execution
}

void SNNVisualizer::stop(void)
{
    keepRunning = false;
    firstPass = true;
}



SNNVisualizer::SNNVisualizer(void) {
// Global visbrain object
    //centerX = 0.0f, centerY = 0.0f, centerZ = 10.0f;
    lookAtX = 0.0f, lookAtY = 0.0f, lookAtZ = 0.0f;
    cameraPosX = 0.0f, cameraPosY = 0.0f, cameraPosZ = 10.0f;  // Camera position
    snnVisualizer = this;

}

SNNVisualizer::~SNNVisualizer(void) {
}

// Function to display text on the screen
void renderText(float x, float y, const std::string &text) {
    glRasterPos2f(x, y);  // Set text position in the 2D coordinate space
    for (char c : text) {
        // Use a smaller font for text rendering
        glutBitmapCharacter(GLUT_BITMAP_HELVETICA_10, c);
    }
}

std::vector<std::string> SNNVisualizer::split(std::string str, char delim)
{
    std::vector<std::string> tokens;
    std::string token;

    for(char ch : str) {
        if(ch == delim) {
            if(!token.empty()) {
                tokens.push_back(token);
                token.clear();
            }
        } else {
            token += ch;
        }
    }

    if(!token.empty()) {
        tokens.push_back(token);
    }

    return tokens;

}

// OpenGL display function
void SNNVisualizer::display(void) {
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
    glLoadIdentity();

// Set up camera position and orientation
    // Apply zoom and rotation transformations
    gluLookAt(cameraPosX, cameraPosY, cameraZoom,  // Camera position
              lookAtX, lookAtY, lookAtZ,           // Look-at point
              0.0f, 1.0f, 0.0f);                   // Up direction
    //gluLookAt(snnVisualizer->centerX, snnVisualizer->centerY, snnVisualizer->zoom, snnVisualizer->centerX, snnVisualizer->centerY, snnVisualizer->centerZ, 0.0, 1.0, 0.0);
    glRotatef(snnVisualizer->rotationX, 1.0f, 0.0f, 0.0f);
    glRotatef(snnVisualizer->rotationY, 0.0f, 1.0f, 0.0f);
    
    // Draw all neurons and their connections
    
    for (const auto& pair : visbrain.neurons) {
        if(pair.second!=nullptr)
        {
            VisNeuron *neuron = pair.second;
            Neuron* realNeuron = globalObject->neuronDB.getComponent(neuron->id); 
            neuron->drawNeuron();
            if(showDendrites) {
                neuron->drawDendrites();
            }
        }
    }


    // Switch to orthographic projection for 2D overlay (text)
    glMatrixMode(GL_PROJECTION);
    glPushMatrix();
    glLoadIdentity();
    gluOrtho2D(0, 800, 0, 600);  // Set orthographic projection matching window size
    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();

    // Convert camera coordinates to string
    std::ostringstream oss;
    oss << globalObject->getCurrentTimestamp() << ": ";
    oss << "Camera Position: (" << cameraPosX << ", " << cameraPosY << ", " << cameraPosZ << ")";
    oss << "  LookAt: (" << lookAtX << ", " << lookAtY << ", " << lookAtZ << ") Zoom: (" << cameraZoom << ") ";
    for(long regionId : globalObject->brain->regions)
    {
        Region *region = globalObject->regionDB.getComponent(regionId);
        oss << "  Region: " << region->name << " (" << region->getNeuronCount() << ") ";
    }
    if(isCapturing)
        oss << " Video Recording on";
    else        
        oss << " Video Recording off";
 
    // Display text in upper right corner
    glColor3f(1.0f, 1.0f, 1.0f);  // White text color
    // 570 is our starting point
    float startingYCoord = 570;
    float height = 12; // height for GLUT_BITMAP_HELVETICA_10 + 2 for space

    renderText(0, startingYCoord, oss.str());

    startingYCoord = startingYCoord - 30 ; // startingYCoord - height

    displayImage(0, startingYCoord, globalObject->lastBuffer);



    startingYCoord = startingYCoord - 30 ; // startingYCoord - 28+2

    std::ostringstream oss2;

    oss2 << "ApCount: " << globalObject->getTotalEvents();
    
    float ycoord = startingYCoord - height; // startingYCoord - height
    renderText(0, ycoord, oss2.str());

    
/******************************** */
    for (const auto& pair : visbrain.neurons) {
        // 700000000 - 700000009
        long thisNeuronId = pair.first;

        if(thisNeuronId >= 700000000 && thisNeuronId <= 700000009)
        { 
            Neuron *neuron = globalObject->neuronDB.getComponent(thisNeuronId);
            float potential = neuron->getMembranePotential();
            float threshold = neuron->threshold;

            oss2.str("");
            oss2 << neuron->id << " : " << potential << " : " << threshold;

            ycoord -= height; // startingYCoord - height
            renderText(0, ycoord, oss2.str());
        }
    }

    // Restore perspective projection
    glMatrixMode(GL_PROJECTION);
    glPopMatrix();
    glMatrixMode(GL_MODELVIEW);

    glutSwapBuffers();

    captureFrame();

    snnVisualizer->firstPass = false;

}

//////////////////////////////////////////////////////
void SNNVisualizer::displayImage(GLint x, GLint y, uint8_t *data) {
    //glClear(GL_COLOR_BUFFER_BIT);

    unsigned char myBuffer[28*28];
    unsigned char rotated[28*28];

    for(int i=0;i<28;i++) {
        for(int j=0;j<28;j++) {
            myBuffer[j*28+i] = data[i*28+j];
        }
    }

    // rotate 270 degrees clockwise
    for (int i = 0; i < 28; ++i) {
        for (int j = 0; j < 28; ++j) {
            rotated[(27 - j)*28+i] = myBuffer[i*28+j];
        }
    }
    
    // Set up the pixel storage mode
    glPixelStorei(GL_UNPACK_ALIGNMENT, 1);
    
    // Draw the grayscale image data at the center
    glRasterPos2i(x, y);  // Set position 
    glDrawPixels(28, 28, GL_LUMINANCE, GL_UNSIGNED_BYTE, rotated);
    
    glFlush();
}

/*
void SNNVisualizer::display() {
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
    glLoadIdentity();

    // Set the camera position
    gluLookAt(0.0, 0.0, 10.0,  // Eye position
              0.0, 0.0, 0.0,   // Look-at position
              0.0, 1.0, 0.0);  // Up vector


// Render neurons as 3D spheres
//    for (const auto& neuron : neurons) {
    for (const auto& pair : visbrain.neurons) {
        VisNeuron *neuron = pair.second;
        glPushMatrix();

        glTranslatef(neuron->x, neuron->y, neuron->z);  // Position the neuron
        //glColor3f(neuron->r, neuron->g, neuron->b);     // Set color (using neuron properties)
        glColor3f(0.8, 0.8, 0.8);    // grey  // Set color (using neuron properties)

        glutSolidSphere(0.2, 20, 20);  // Render the neuron as a solid 3D sphere

        glPopMatrix();
    }

    glutSwapBuffers();
}
*/

// OpenGL idle function to update the neural network and refresh display
void SNNVisualizer::idle(void) {
    visbrain.update();
    glutPostRedisplay();
}

// Mouse button callback
void SNNVisualizer::mouseButton(int button, int state, int x, int y) {
    // Handle mouse button presses for left and right buttons
    if (button == GLUT_LEFT_BUTTON) {
        if (state == GLUT_DOWN) {
            snnVisualizer->leftButtonDown = true;
            snnVisualizer->lastMouseX = x;
            snnVisualizer->lastMouseY = y;
        } else {
            snnVisualizer->leftButtonDown = false;
        }
    } else if (button == GLUT_RIGHT_BUTTON) {
        if (state == GLUT_DOWN) {
            snnVisualizer->rightButtonDown = true;
            snnVisualizer->lastMouseX = x;
            snnVisualizer->lastMouseY = y;
        } else {
            snnVisualizer->rightButtonDown = false;
        }
    }

    // Use mouse wheel for zoom functionality
    if (button == 3) {          // Scroll up (zoom in)
        cameraZoom -= 0.05f;     // Decrease the zoom distance
        if (cameraZoom < -100.0f)  // Set minimum zoom limit
            cameraZoom = -100.0f;
        glutPostRedisplay();
    } else if (button == 4) {   // Scroll down (zoom out)
        cameraZoom += 0.05f;     // Increase the zoom distance
        if (cameraZoom > 100.0f) // Set maximum zoom limit
            cameraZoom = 100.0f;
        glutPostRedisplay();
    }
}


void SNNVisualizer::mouseMotion(int x, int y) {
    // Calculate the change in mouse position
    float dx = x - snnVisualizer->lastMouseX;
    float dy = y - snnVisualizer->lastMouseY;

    if (snnVisualizer->leftButtonDown) {
        // Orbit around the lookAt point
        float orbitSpeed = 0.1f;  // Adjust speed of orbiting
        snnVisualizer->rotationX += dy * orbitSpeed;
        snnVisualizer->rotationY += dx * orbitSpeed;

        // Convert rotationX and rotationY from degrees to radians
        float rotationXRad = snnVisualizer->rotationX * M_PI / 180.0f;
        float rotationYRad = snnVisualizer->rotationY * M_PI / 180.0f;

        // Calculate the new camera position in spherical coordinates
        float radius = cameraZoom;  // Distance from camera to lookAt point
        float camX = lookAtX + radius * cos(rotationYRad) * cos(rotationXRad);
        float camY = lookAtY + radius * sin(rotationXRad);
        float camZ = lookAtZ + radius * sin(rotationYRad) * cos(rotationXRad);

        cameraPosX = camX;
        cameraPosY = camY;
        cameraPosZ = camZ;
    }

    if (snnVisualizer->rightButtonDown) {
        // Pan the view by moving the lookAt point
        float panSpeed = 0.01f;  // Adjust pan speed
        lookAtX -= dx * panSpeed;
        lookAtY += dy * panSpeed;
        
        // Update the camera position to reflect the new lookAt point
        cameraPosX -= dx * panSpeed;
        cameraPosY += dy * panSpeed;
    }

    // Update last mouse position
    snnVisualizer->lastMouseX = x;
    snnVisualizer->lastMouseY = y;

    // Redraw the scene
    glutPostRedisplay();
}


void SNNVisualizer::initGL() {
    glEnable(GL_DEPTH_TEST);              // Enable depth testing for 3D
    glClearColor(0.0f, 0.0f, 0.0f, 1.0f); // Set background color

    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();
    gluPerspective(45.0, 1.33, 0.1, 100.0);  // 45° field of view, aspect ratio 4:3, near and far planes
    glMatrixMode(GL_MODELVIEW);

    setupLighting();  // Initialize lighting configuration
}

void SNNVisualizer::setupLighting() {
    glEnable(GL_LIGHTING);      // Enable lighting
    glEnable(GL_LIGHT0);        // Enable light source 0

    GLfloat ambientLight[] = { 0.2f, 0.2f, 0.2f, 1.0f };
    GLfloat diffuseLight[] = { 0.8f, 0.8f, 0.8f, 1.0f };
    GLfloat specularLight[] = { 1.0f, 1.0f, 1.0f, 1.0f };
    GLfloat lightPosition[] = { 2.0f, 5.0f, 5.0f, 1.0f };

    glLightfv(GL_LIGHT0, GL_AMBIENT, ambientLight);
    glLightfv(GL_LIGHT0, GL_DIFFUSE, diffuseLight);
    glLightfv(GL_LIGHT0, GL_SPECULAR, specularLight);
    glLightfv(GL_LIGHT0, GL_POSITION, lightPosition);

    glEnable(GL_COLOR_MATERIAL);  // Allows object colors to reflect light
    glColorMaterial(GL_FRONT, GL_AMBIENT_AND_DIFFUSE);
}


// OpenGL initialization function
void SNNVisualizer::initOpenGL(void) {
    glClearColor(0.0, 0.0, 0.0, 1.0);  // Black background
    glEnable(GL_DEPTH_TEST);           // Enable depth testing
}

// Function to compute the initial zoom and center the neurons
void SNNVisualizer::computeInitialView(void) {
    float minX, maxX, minY, maxY, minZ, maxZ;
    visbrain.computeBoundingBox(minX, maxX, minY, maxY, minZ, maxZ);

    cameraPosX = (minX + maxX) / 2.0f;
    cameraPosY = (minY + maxY) / 2.0f;
    cameraPosZ = (minZ + maxZ) / 2.0f;

    float maxDistance = std::max(std::max(maxX - minX, maxY - minY), maxZ - minZ);
    zoom = -2.0f * maxDistance;  // Adjust the zoom based on the neuron spread

    //////// initial
    cameraPosX = 2.29974;initVideoWriter();  // Initialize the video writer
    lookAtX = -0.19;
    lookAtY = -1.06;
    lookAtZ = 0;


    zoom = 4.1998;
}

// Main function
int SNNVisualizer::startVisualizer(int argc, char **argv) {


    glutInit(&argc, argv);
    glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGB | GLUT_DEPTH);
    glutInitWindowSize(windowWidth, windowHeight);
    glutCreateWindow("Neural Network Visualization");

    //initOpenGL();
    initGL();

    initVideoWriter();  // Initialize the video writer

    int neuronCount = 0;
    float scaleFactor = 2.0f / 10000.0f;
    for(size_t iRegIx =0; iRegIx < thisBrain->regions.size(); iRegIx++)
    {
        long regionId = thisBrain->regions[iRegIx];
        Region *reg = globalObject->regionDB.getComponent(regionId);
        for (size_t iNuc = 0; iNuc < reg->nuclei.size(); iNuc++)
        {
            long nucleusId = reg->nuclei[iNuc];
            Nucleus *nucleus = globalObject->nucleusDB.getComponent(nucleusId);
            for (size_t iCol = 0; iCol < nucleus->columns.size(); iCol++)
            {
                long columnId = nucleus->columns[iCol];
                Column *column = globalObject->columnDB.getComponent(columnId);
                for (size_t iLay = 0; iLay < column->layers.size(); iLay++)
                {
                    long layerId = column->layers[iLay];
                    Layer *layer = globalObject->layerDB.getComponent(layerId);
                    for (size_t iClu = 0; iClu < layer->clusters.size(); iClu++)
                    {
                        long clusterId = layer->clusters[iClu];
                        Cluster *cluster = globalObject->clusterDB.getComponent(clusterId);
                        for (size_t iNeu = 0; iNeu < cluster->neurons.size(); iNeu++)
                        {
                            long neuronId = cluster->neurons[iNeu];
                            Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);

                            float x = neuron->location.x * scaleFactor;
                            float y = neuron->location.y * scaleFactor;
                            float z = neuron->location.z * scaleFactor;
                            VisNeuron* vn = new VisNeuron(x,y,z);
                            vn->id = neuron->id;
                            if(iRegIx==0) {
                                vn->rfiring = 1.0;
                                vn->gfiring = 0.0;
                                vn->bfiring = 0.0;
                                vn->rnotfiring = 0.0;
                                vn->gnotfiring = 1.0;
                                vn->bnotfiring = 0.0;
                            } else if(iRegIx==1) {
                                vn->rfiring = 1.0;
                                vn->gfiring = 0.0;
                                vn->bfiring = 0.0;
                                vn->rnotfiring = 0.0;
                                vn->gnotfiring = 1.0;
                                vn->bnotfiring = 0.5;
                            } else {
                                vn->rfiring = 1.0;
                                vn->gfiring = 0.0;
                                vn->bfiring = 0.0;
                                vn->rnotfiring = 0.0;
                                vn->gnotfiring = 1.0;
                                vn->bnotfiring = 1.0;
                            }
/*
                            //
                            if(iRegIx==1 && iNeu==0 && iClu==0) {
                                vn->rnotfiring = 1.0;
                                vn->gnotfiring = 1.0;
                                vn->bnotfiring = 1.0;
                            }

                            if(iRegIx==1 && iNeu==0 && iClu==1) {
                                vn->rnotfiring = 0.0;
                                vn->gnotfiring = 0.0;
                                vn->bnotfiring = 1.0;
                            }
*/
                            visbrain.addNeuron(vn);
                            neuronCount++;
                        }
                    }
                }
            }
        }
    }

    for (const auto &pair : visbrain.neurons)
    {
        if (pair.second != nullptr)
        {
            VisNeuron *fromNeuron = pair.second;
            Neuron *neuron = globalObject->neuronDB.getComponent(fromNeuron->id);
            std::vector<long> *dendriteIds = neuron->getDendrites();
            for (size_t iy = 0; iy < dendriteIds->size(); iy++)
            {
                long dendriteId = (*dendriteIds)[iy];
                Dendrite *dendrite = globalObject->dendriteDB.getComponent(dendriteId);
                long connectedToNeuron = dendrite->getPreSynapticNeuronId();

                VisNeuron *toNeuron = visbrain.neurons[connectedToNeuron];
                visbrain.connect(fromNeuron, toNeuron, dendrite->getSynapseId());
            }
        }
    }

    std::cout << "Number of neurons to visualize: " << neuronCount << std::endl;

    computeInitialView();

    glutDisplayFunc(display);
    glutIdleFunc(idle);             // Idle function to update the state of neurons
    glutMouseFunc(mouseButton);     // Mouse button callback
    glutMotionFunc(mouseMotion);    // Mouse motion callback
    glutReshapeFunc(reshape);       // reshape  callback
    glutKeyboardFunc(keyboard);    // keyboard callback

    gluLookAt(cameraPosX, cameraPosY, cameraPosZ,  // Camera position
              lookAtX, lookAtY, lookAtZ,           // Look-at point
              0.0f, 1.0f, 0.0f);                   // Up direction


    glutMainLoop();

    videoWriter.release();  // Release the video writer when done
}


// ============== SNNVisualizer.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <GL/glut.h>
#include <opencv2/opencv.hpp> 
#include <vector>
#include <iostream>

class Brain; // forward declaration

class SNNVisualizer {

public:

    // Variables for controlling the scene
    float rotationX = 0.0f;
    float rotationY = 0.0f;
    float zoom = -5.0f;
    int lastMouseX, lastMouseY;
    bool leftButtonDown = false;
    bool rightButtonDown = false;

    SNNVisualizer(void);
    ~SNNVisualizer(void);

	int waitThread(void);
	int waitThreadWorker(void);
	void doWork(void);
	void start(void);
	void stop(void);

   	bool keepRunning;
    bool firstPass = true;


    static void display(void);
    static void idle(void);
    static void mouseButton(int button, int state, int x, int y);
    static void mouseMotion(int x, int y);
    static void displayImage(GLint x, GLint y, uint8_t *data);
    static void initVideoWriter(void);
    static void captureFrame(void); 
    static void reshape(int width, int height);
    static void keyboard(unsigned char key, int x, int y);
    static std::vector<std::string> split(std::string str, char delim);

    void initGL(void);
    void setupLighting(void);
    void initOpenGL(void);
    void computeInitialView(void);
    int startVisualizer(int argc, char **argv);
    Brain* thisBrain = nullptr;

       
};




// ============== Serialize.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <fstream>

// include headers that implement a archive in simple text format
#include <boost/archive/text_oarchive.hpp>
#include <boost/archive/text_iarchive.hpp>

#include "NNComponent.h"
#include "Axon.h"
#include "Neuron.h"
#include "Synapse.h"
#include "ActionPotential.h"

//BOOST_SERIALIZATION_ASSUME_ABSTRACT(NNComponent)
/*
std::ostream & operator<<(std::ostream &os, const NNComponent &nnc)
{
	return os << "\ncomponentType=" << nnc.componentType << ",componentId=" << nnc.id;
}
*/
/*
std::ostream & operator<<(std::ostream &os, const Axon &ax)
{
	os << "\nneuron = " << ax.neuron->id;
	return os;
}

std::ostream & operator<<(std::ostream &os, const Synapse &synapse)
{
	os << "\nsynapse = " << synapse.id;
	return os;
}

std::ostream & operator<<(std::ostream &os, const ActionPotential &ap)
{
	os << "\nactionpotential = " << ap.id;
	return os;
}
*/

// ============== Server.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <boost/thread.hpp>
#include <iostream>
#include <string>
#include <cstring> // For strerror() and related functions
#include <sys/socket.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <errno.h>
#include "Global.h"
#include "Server.h"

#include "nlohmann/json.hpp"

#define DEFAULT_BUFLEN 32768
#define DEFAULT_PORT "8123"


int Server::waitThread(void)
{
	int ret = waitThreadWorker();
	return ret;
}

int Server::waitThreadWorker(void)
{
    int ListenSocket = -1;
    int ClientSocket = -1;
    struct sockaddr_in serverAddress = {};
    ssize_t iResult, iSendResult;
    char recvbuf[DEFAULT_BUFLEN];
    size_t recvbuflen = DEFAULT_BUFLEN;
    //char sendbuf[DEFAULT_BUFLEN];
    //size_t sendbuflen = DEFAULT_BUFLEN;
    
    std::stringstream ss;
    
    ListenSocket = socket(AF_INET, SOCK_STREAM, 0);
    if (ListenSocket == -1) {
        LOGSTREAM(ss) << "socket failed with error: " << strerror(errno) << "\n" << std::endl;
        globalObject->log(ss);
        return 1;
    }

    serverAddress.sin_family = AF_INET;
    serverAddress.sin_addr.s_addr = INADDR_ANY;
    serverAddress.sin_port = htons(atoi(DEFAULT_PORT));

    if (bind(ListenSocket, (struct sockaddr*)&serverAddress, sizeof(serverAddress)) == -1) {
        LOGSTREAM(ss) << "bind failed with error: " << strerror(errno) << "\n" << std::endl;
        globalObject->log(ss);
        close(ListenSocket);
        return 1;
    }

    if (listen(ListenSocket, SOMAXCONN) == -1) {
        LOGSTREAM(ss) << "listen failed with error: " << strerror(errno) << "\n" << std::endl;
        globalObject->log(ss);
        close(ListenSocket);
        return 1;
    }

    ClientSocket = accept(ListenSocket, NULL, NULL);
    if (ClientSocket == -1) {
        LOGSTREAM(ss) << "accept failed with error: " << strerror(errno) << "\n" << std::endl;
        globalObject->log(ss);
        close(ListenSocket);
        return 1;
    }

    close(ListenSocket);

    if(keepRunning)
        boost::thread t(&Server::waitThread, this);

    do {
        memset(recvbuf, 0, recvbuflen);
        iResult = recv(ClientSocket, recvbuf, recvbuflen - 1, 0);
        
        if (iResult > 0) {
            std::string resultString = parseAndRespond(recvbuf, iResult);
            ssize_t bytesToSend = resultString.size();
            iSendResult = send(ClientSocket, resultString.c_str(), bytesToSend, 0);
            
            if (iSendResult == -1) {
                LOGSTREAM(ss) << "send failed with error: " << strerror(errno) << "\n" << std::endl;
                globalObject->log(ss);
                close(ClientSocket);
                return 1;
            }
        }
        else if (iResult == 0) {
            // Connection closed by client
        }
        else {
            LOGSTREAM(ss) << "recv failed with error: " << strerror(errno) << "\n" << std::endl;
            globalObject->log(ss);
            close(ClientSocket);
            return 1;
        }
    } while (iResult > 0);

    close(ClientSocket);
    return 0;
}

Server::Server(void)
{
    keepRunning = true;
}

Server::~Server(void)
{
}

void Server::start(void)
{
    boost::thread t(&Server::waitThread,this);
}

void Server::stop(void)
{
    keepRunning = false;
}

// DHorak 7/31/2018 Recommend replacing with XML message passing structure - JSON or XML (or both) web services
std::string Server::parseAndRespond(char *buffer, int length)
{
	return parseAndRespondText(buffer, length);
}

// Parse, process and reply using JSON
std::string Server::parseAndRespondJSON(char *buffer, int length)
{
    // Get the buffer into a string object
    std::string b(buffer, length);

    // Parse the string into a JSON object
    nlohmann::json cmdObject = nlohmann::json::parse(b);

    // ... Your code to process the cmdObject and generate a response ...

    return "";
}

// Parse, process and reply using XML
std::string Server::parseAndRespondXML(char *buffer, int length)
{
	(void)buffer;
	(void)length;
	return "";
}

std::string Server::parseAndRespondText(char *buffer, int length)
{
	(void)length;
	std::stringstream ss;
	// command parser
	// format of recognized messages is 
	// COMMAND ARG[,ARG][,ARG]
	// WHERE COMMAND is:
	//	GETNEURONS nucleus,layer
	//	SETACTIVATION neuron1[,neuron2]
	//	GETACTIVATION neuron1[,neuron2]
	//	GETACTIVENEURONS nucleus,layer
	//	REPORT dummy
	// 
	// 
	char *space = strchr(buffer,' ');
	if(space==NULL) {
		std::string resultString = "ERROR001: Invalid command format";
		LOGSTREAM(ss) << resultString << std::endl;
		globalObject->log(ss);
		return resultString;
	} else {
		__int64 length = space - buffer;
		char *tempbuffer = (char *)globalObject->allocClearedMemory(length+1);
		strncpy(tempbuffer,buffer,length);
		std::string command(tempbuffer);
		globalObject->freeMemory(tempbuffer);
		trim(command);

//		LOGSTREAM(ss) << "Command: " << command << " received." << std::endl;
//		globalObject->log(ss);

		// Depending on command, parse the arguments
		if(command == "GETNEURONS") {
			LOGSTREAM(ss) << "GETNEURONS Command recognized: " << std::endl;
			globalObject->log(ss);
			// get the region and nucleus names
			std::string returnString("NEURONS=");
			std::string returnStringSeparator;
			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len+1);
			strncpy(workbuffer,bufStart,len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);
			size_t commapos = workString.find(",");
			if (commapos==std::string::npos) 
			{
				returnString = "ERROR004: GETNEURONS parameters missing. ";
				LOGSTREAM(ss) << returnString << std::endl;
				globalObject->log(ss);
				return returnString;
			}
			std::string lookupNucleusName = workString.substr(0,commapos);
			std::string lookupLayer = workString.substr(commapos+1);

			long layerNumber = (long) atoi(lookupLayer.c_str());

			LOGSTREAM(ss) << "GETNEURONS parameters are nucleus [" << lookupNucleusName << "] and layer [" << lookupLayer << "] " << std::endl;
			globalObject->log(ss);

			// Get the nucleus
			for (globalObject->nucleusDB.begin(); globalObject->nucleusDB.more(); globalObject->nucleusDB.next())
			{
				Nucleus *nuc = globalObject->nucleusDB.getValue();
				if(nuc->name == lookupNucleusName) 
				{
					LOGSTREAM(ss) << "GETNEURONS nucleus [" << lookupNucleusName << "] found" << std::endl;
					globalObject->log(ss);

					// Interate through all neurons in this nucleus
					size_t cSize = nuc->columns.size();
					LOGSTREAM(ss) << "GETNEURONS nucleus [" << lookupNucleusName << "] contains " << cSize << " columns " << std::endl;
					globalObject->log(ss);
					for (unsigned int i=0;i<cSize;i++)
					{
						long c = nuc->columns[i];
						Column *column = globalObject->columnDB.getComponent(c);
						//long colSize = (long)column->layers.size();
//						LOGSTREAM(ss) << "column [" << c << "] contains " << colSize << " layers " << std::endl;
//						globalObject->log(ss);

						long layerId = column->layers[layerNumber-1];
						Layer *layer = globalObject->layerDB.getComponent(layerId);


						unsigned int lcSize = (unsigned int) layer->clusters.size();
//						LOGSTREAM(ss) << "layer [" << layerId << "] contains " << lcSize << " clusters " << std::endl;
//						globalObject->log(ss);
						for (unsigned int j=0;j<lcSize;j++)
						{
							long clusterId = layer->clusters[j];
							Cluster *cluster = globalObject->clusterDB.getComponent(clusterId);
							unsigned int nSize = (unsigned int) cluster->getNeurons().size();
//							LOGSTREAM(ss) << "cluster [" << clusterId << "] contains " << nSize << " neurons " << std::endl;
//							globalObject->log(ss);
							for (unsigned int k=0;k<nSize;k++)
							{
								long neuronId = cluster->getNeurons()[k];
								// Got the neuronId
								// Convert neuronId and append it to return string
								std::stringstream ns;
								ns << neuronId;
								std::string neuronIdString = ns.str();
								returnString += returnStringSeparator+neuronIdString;
								returnStringSeparator = ","; // Set returnStringSeparator for next time
							}
						}
					}
//					LOGSTREAM(ss) << "Sending Response [" << returnString << "], " << returnString.size() << " bytes." << std::endl;
					LOGSTREAM(ss) << "Sending Response of " << returnString.size() << " bytes." << std::endl;
					globalObject->log(ss);
//					strncpy(sendbuf,returnString.c_str(),sendbuflength);
					return returnString;
				}
			}
			LOGSTREAM(ss) << "ERROR005: Nucleus " << lookupNucleusName << " not found: " << std::endl;
			globalObject->log(ss);
			returnString = "ERROR005: Nucleus ";
			returnString += lookupNucleusName+" not found";
			return returnString;
		} else if(command == "SETACTIVATION") {
			LOGSTREAM(ss) << "SETACTIVATION Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
			globalObject->log(ss);

			std::string returnString;

			// parameter string consists of list of neurons to activate (spike).
			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len+1);
			strncpy(workbuffer,bufStart,len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);

			std::vector<long> neuronList;
			split(workString,neuronList); // split command delimited workString and return vector of neuronIds (longs)
			//
			// Let's lock the timestamps during our activiation function
			boost::mutex::scoped_lock  amx(globalObject->timestep_mutex);
			for(unsigned int ix=0;ix<neuronList.size();ix++) 
			{
				long neuronId = neuronList[ix];
				Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);

				if(globalObject->logEvents) 
				{
					ss << "server_parseandrespondtext_SETACTIVATION: neuron=" << neuronId;
					globalObject->writeEventLog(ss.str().c_str());
				}
				neuron->fire();
			}

			returnString = "SETACTIVATION Command complete";
			return returnString;
		} else if(command == "GETACTIVATION") {
			LOGSTREAM(ss) << "GETACTIVATION Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
			globalObject->log(ss);

			std::string returnString;

			// parameter string consists of list of neurons to get activation status.
			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len+1);
			strncpy(workbuffer,bufStart,len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);

			returnString = "";
			std::vector<long> neuronList;
			split(workString,neuronList); // split command delimited workString and return vector of neuronIds (longs)

//			LOGSTREAM(ss) << "GETACTIVATION neuronlist contains  [" << neuronList.size() << "] neurons" << std::endl;
//			globalObject->log(ss);
			for(unsigned int ix=0;ix<neuronList.size();ix++) 
			{
				long neuronId = neuronList[ix];
//				LOGSTREAM(ss) << "GETACTIVATION get status of neuron [" << neuronId << "]" << std::endl;
//				globalObject->log(ss);
				Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
//				if(neuron->isFiring())
				if(neuron->hasFired())
				{
					neuron->resetLatch();
					returnString += "1";
				} else {
					returnString += "0";
				}
			}

			LOGSTREAM(ss) << "GETACTIVATION return string [" << returnString << "] at timestep " << globalObject->getCurrentTimestamp() << "." << std::endl;
			globalObject->log(ss);

			return returnString;
		} else if(command == "GETACTIVENEURONS") {
			LOGSTREAM(ss) << "GETACTIVENEURONS Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
			globalObject->log(ss);
			// get the region and nucleus names
			std::string returnString("NEURONS=");
			std::string returnStringSeparator;
			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len+1);
			strncpy(workbuffer,bufStart,len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);
			size_t commapos = workString.find(",");
			if (commapos==std::string::npos) 
			{
				returnString = "ERROR014: GETACTIVENEURONS parameters missing. ";
				LOGSTREAM(ss) << returnString << std::endl;
				globalObject->log(ss);
				return returnString;
			}
			std::string lookupNucleusName = workString.substr(0,commapos);
			std::string lookupLayer = workString.substr(commapos+1);

			long layerNumber = (long) atoi(lookupLayer.c_str());

			LOGSTREAM(ss) << "GETACTIVENEURONS parameters are nucleus [" << lookupNucleusName << "] and layer [" << lookupLayer << "] " << std::endl;
			globalObject->log(ss);

			// Get the nucleus
			for (globalObject->nucleusDB.begin(); globalObject->nucleusDB.more(); globalObject->nucleusDB.next())
			{
				Nucleus *nuc = globalObject->nucleusDB.getValue();
				if(nuc->name == lookupNucleusName) 
				{
					LOGSTREAM(ss) << "GETACTIVENEURONS nucleus [" << lookupNucleusName << "] found" << std::endl;
					globalObject->log(ss);

					// Interate through all neurons in this nucleus
					unsigned int cSize = (unsigned int) nuc->columns.size();
					LOGSTREAM(ss) << "GETACTIVENEURONS nucleus [" << lookupNucleusName << "] contains " << cSize << " columns " << std::endl;
					globalObject->log(ss);
					for (unsigned int i=0;i<cSize;i++)
					{
						long c = nuc->columns[i];
						Column *column = globalObject->columnDB.getComponent(c);
						//long colSize = (long) column->layers.size();
//						LOGSTREAM(ss) << "column [" << c << "] contains " << colSize << " layers " << std::endl;
//						globalObject->log(ss);

						long layerId = column->layers[layerNumber-1];
						Layer *layer = globalObject->layerDB.getComponent(layerId);


						unsigned int lcSize = (unsigned int) layer->clusters.size();
//						LOGSTREAM(ss) << "layer [" << layerId << "] contains " << lcSize << " clusters " << std::endl;
//						globalObject->log(ss);
						for (unsigned int j=0;j<lcSize;j++)
						{
							long clusterId = layer->clusters[j];
							Cluster *cluster = globalObject->clusterDB.getComponent(clusterId);
							unsigned int nSize = (unsigned int) cluster->getNeurons().size();
//							LOGSTREAM(ss) << "cluster [" << clusterId << "] contains " << nSize << " neurons " << std::endl;
//							globalObject->log(ss);
							for (unsigned int k=0;k<nSize;k++)
							{
								long neuronId = cluster->getNeurons()[k];
								// Got the neuronId
								// Convert neuronId and append it to return string
								// See if this neuron is active
								Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
//								if(neuron->isFiring())  // Only include this neuron if it is currently firing
								if(neuron->hasFired())  // Only include this neuron if it is currently firing
								{
									std::stringstream ns;
									ns << neuronId;
									std::string neuronIdString = ns.str();
									returnString += returnStringSeparator+neuronIdString;
									returnStringSeparator = ","; // Set returnStringSeparator for next time
									neuron->resetLatch();
								}
							}
						}
					}
//					LOGSTREAM(ss) << "Sending Response [" << returnString << "], " << returnString.size() << " bytes." << std::endl;
					LOGSTREAM(ss) << "Sending Response of " << returnString.size() << " bytes at timestep " << globalObject->getCurrentTimestamp() << "." << std::endl;
					globalObject->log(ss);
//					strncpy(sendbuf,returnString.c_str(),sendbuflength);
					return returnString;
				}
			}
			LOGSTREAM(ss) << "ERROR015: Nucleus " << lookupNucleusName << " not found: " << std::endl;
			globalObject->log(ss);
			returnString = "ERROR015: Nucleus ";
			returnString += lookupNucleusName+" not found";
			return returnString;
		} else if(command == "SETACTIVATIONPATTERN") {
//			LOGSTREAM(ss) << "SETACTIVATIONPATTERN Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
//			globalObject->log(ss);

			std::string returnString;

			// parameter string consists of list of neurons to activate (spike).
			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len+1);
			strncpy(workbuffer,bufStart,len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);

			std::string nucleus;
			int columns;
			int rows;

			std::vector<long> neurons;
			unsigned char *data = parseSetActivationPattern(workString,&nucleus, &columns, &rows, &neurons);

			size_t totalSize = columns * rows;

//			LOGSTREAM(ss) << "SETACTIVATIONPATTERN total rows*columns " << totalSize << ", of " << neurons.size() << " neurons " << std::endl;
//			globalObject->log(ss);

			for(size_t i=0;i<totalSize;i++)
			{
				if(i<neurons.size()) 
				{
					if(data[i]=='\1') 
					{
						long neuronId = neurons[i];

						Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
						if(neuron!=NULL) {
							if(globalObject->logEvents) 
							{
								ss << "server_parseandrespondtext_SETACTIVATIONPATTERN: neuron=" << neuronId;
								globalObject->writeEventLog(ss.str().c_str());
							}
							//neuron->fire();
							neuron->setMembranePotential(3.0);
						}
					} 
				}
			}

			returnString = "SETACTIVATIONPATTERN Command complete";
			return returnString;
		}
		else if (command == "GETACTIVATIONPATTERN") {
//			LOGSTREAM(ss) << "GETACTIVATIONPATTERN Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
//			globalObject->log(ss);

			std::string returnString("");

			// parameter string consists of list of neurons to activate (spike).
			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len + 1);
			strncpy(workbuffer, bufStart, len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);

			std::string nucleus(workString);

			std::vector<long> neurons = getNeurons(nucleus,6); // Layer 6 = output

			size_t totalSize = neurons.size();

			//			LOGSTREAM(ss) << "SETACTIVATIONPATTERN total rows*columns " << totalSize << ", of " << neurons.size() << " neurons " << std::endl;
			//			globalObject->log(ss);

			for (size_t i = 0; i<totalSize; i++)
			{
				long neuronId = neurons[i];
				Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
				if (neuron != NULL) {
					if (neuron->isFiring()) {
						returnString += "1";
					} else {
						returnString += "0";
					}
				} else {
						returnString += "0";
				}
			}

//			returnString = "SETACTIVATIONPATTERN Command complete";
			return returnString;
		} else if(command == "STARTATOMIC") { // STARTATOMIC command requires an argument (TRUE or FALSE)...
			LOGSTREAM(ss) << "STARTATOMIC Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
			globalObject->log(ss);

			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len+1);
			strncpy(workbuffer,bufStart,len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);

			std::string startAtomicParameter = workString; // STARTATOMIC parameter - TRUE OR FALSE 

			if(startAtomicParameter=="TRUE") 
			{
				LOGSTREAM(ss) << "STARTATOMIC 'true' option processed. " << std::endl;
				globalObject->log(ss);
			}
			else 
			{
				LOGSTREAM(ss) << "STARTATOMIC 'false' option processed. " << std::endl;
				globalObject->log(ss);
			}


			// STARTATOMIC functionality is not currently implemented - it is intended to pause the simulation until an ENDATOMIC command is received

			// get the region and nucleus names
			std::string returnString = "OK";

			return returnString;
		}
		else if (command == "FLUSH") { // FLUSH command requires no argument
		LOGSTREAM(ss) << "FLUSH Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
		globalObject->log(ss);

		globalObject->flush(); // flush all databases - persist all Databases to disc

		// get the region and nucleus names
		std::string returnString = "OK";

		return returnString;
		} else if(command == "REPORT") { // REPORT command requires a dummy argument which is ignored...
			LOGSTREAM(ss) << "REPORT Command recognized at timestep " << globalObject->getCurrentTimestamp() << ": " << std::endl;
			globalObject->log(ss);

			char *bufStart = space;
			size_t len = strlen(bufStart);
			char *workbuffer = (char *)globalObject->allocClearedMemory(len+1);
			strncpy(workbuffer,bufStart,len);
			std::string workString(workbuffer);
			globalObject->freeMemory(workbuffer);
			trim(workString);

			std::string reportParameter = workString; // Report parameter - currently ignored - could be used as report type in future implementations

			// get the region and nucleus names
			std::string returnString;
			Brain *brain = globalObject->brainDB.getValue();
			returnString = brain->getReport();

			return returnString;
		} else {
			LOGSTREAM(ss) << "Unrecognized command [" << command << "]" << std::endl;
			globalObject->log(ss);
			std::string returnString = "ERROR002: Unrecognized command";
			return returnString;
		}

	}

}

void Server::split(std::string workString,std::vector<long> &neuronList)
{
	// parse comma delimted string, convert each token to a long and add to neuronList
//	std::stringstream ss;

	std::string delimitedString;
	delimitedString = workString + ","; // Add final terminator
	size_t offset = 0;
	size_t pos = delimitedString.find(",",offset);
	while(pos != std::string::npos)
	{
		std::string strNeuronID;
		strNeuronID = delimitedString.substr(offset,pos-offset);
		trim(strNeuronID);
		if(strNeuronID.length()>0) 
		{
			long id = atol(strNeuronID.c_str());
			neuronList.push_back(id);

//			LOGSTREAM(ss) << " split neuron [" << id << "] added to returned vector " << std::endl;
//			globalObject->log(ss);
		}
		offset = pos + 1; // skip comma
		pos = delimitedString.find(",",offset);
//		LOGSTREAM(ss) << " pos [" << pos << "], offset [" << offset << "] " << std::endl;
//		globalObject->log(ss);
	}

}

unsigned char *Server::parseSetActivationPattern(std::string workString,std::string *nucleus, int *columns, int *rows, std::vector<long> *neurons)
{
	// parse comma delimted string, convert each token to a long and add to neuronList
	std::stringstream ss;

	std::string delimitedString;
	delimitedString = workString + ","; // Add final terminator
	size_t offset = 0;
	size_t pos = delimitedString.find(",",offset);
	std::vector<std::string> tokens;
	while(pos != std::string::npos)
	{
		std::string token;
		token = delimitedString.substr(offset,pos-offset);
		trim(token);
		tokens.push_back(token);
		offset = pos + 1; // skip comma
		pos = delimitedString.find(",",offset);
	}
	if(tokens.size()<4) 
	{
			LOGSTREAM(ss) << " parseSetActivationPattern unable to parse string [" << workString << "]. Only " << tokens.size() << " tokens found (4 required)." << std::endl;
			globalObject->log(ss);
			return NULL;
	}
	std::string nuc(tokens[0]);
	*nucleus = nuc;

	*columns = atoi(tokens[1].c_str());
	*rows = atoi(tokens[2].c_str());
	size_t totalSize = (*rows)*(*columns);
	unsigned char *data = (unsigned char *)globalObject->allocClearedMemory((int)totalSize);
	setActivationBytes((unsigned char *)tokens[3].c_str(), data, totalSize);
	std::vector<long> rneurons = getNeurons(nuc,4); // input layer
	*neurons = rneurons;
	return data;
}

std::vector<long> Server::getNeurons(std::string lookupNucleusName, int layerNumber) 
{
	std::stringstream ss;

	std::vector<long> neurons;

//	LOGSTREAM(ss) << "Server::getNeurons parameters are nucleus [" << lookupNucleusName << "] and layer [" << layerNumber << "] " << std::endl;
//	globalObject->log(ss);

	// Get the nucleus
//	for (globalObject->nucleusDB.begin(); globalObject->nucleusDB.more(); globalObject->nucleusDB.next())
//	{
//		Nucleus *nuc = globalObject->nucleusDB.getValue();
	long startNuclei = globalObject->componentBase[ComponentTypeNucleus];
	long endNuclei = globalObject->componentCounter[ComponentTypeNucleus];
//	for (globalObject->nucleusDB.begin(); globalObject->nucleusDB.more(); globalObject->nucleusDB.next())
	for(long nucIndex = startNuclei;nucIndex<endNuclei;nucIndex++)
	{
		Nucleus *nuc = globalObject->nucleusDB.getComponent(nucIndex);
		if(nuc->name == lookupNucleusName) 
		{
//			LOGSTREAM(ss) << "Server::getNeurons nucleus [" << lookupNucleusName << "] found" << std::endl;
//			globalObject->log(ss);

			// Interate through all neurons in this nucleus
			size_t cSize = nuc->columns.size();
//			LOGSTREAM(ss) << "Server::getNeurons nucleus [" << lookupNucleusName << "] contains " << cSize << " columns " << std::endl;
//			globalObject->log(ss);
			for (unsigned int i=0;i<cSize;i++)
			{
				long c = nuc->columns[i];
				Column *column = globalObject->columnDB.getComponent(c);
				//long colSize = (long) column->layers.size();
//				LOGSTREAM(ss) << "column [" << c << "] contains " << colSize << " layers " << std::endl;
//				globalObject->log(ss);

				long layerId = column->layers[layerNumber];
				Layer *layer = globalObject->layerDB.getComponent(layerId);


				size_t lcSize = layer->clusters.size();
//				LOGSTREAM(ss) << "layer [" << layerId << "] contains " << lcSize << " clusters " << std::endl;
//				globalObject->log(ss);
				for (unsigned int j=0;j<lcSize;j++)
				{
					long clusterId = layer->clusters[j];
					Cluster *cluster = globalObject->clusterDB.getComponent(clusterId);
					size_t nSize = cluster->getNeurons().size();
//					LOGSTREAM(ss) << "cluster [" << clusterId << "] contains " << nSize << " neurons " << std::endl;
//					globalObject->log(ss);
					for (unsigned int k=0;k<nSize;k++)
					{
						long neuronId = cluster->getNeurons()[k];
						// Got the neuronId
						neurons.push_back(neuronId);
					}
				}
			}
			return neurons;
		}
	}

//	LOGSTREAM(ss) << "Server::getNeurons " << neurons.size() << " neurons returned " << std::endl;
//	globalObject->log(ss);
	return neurons;
}

std::vector<long> Server::getNeurons(std::string lookupNucleusName, LayerType layerType) 
{
	std::stringstream ss;

	std::vector<long> neurons;



//	LOGSTREAM(ss) << "Server::getNeurons parameters are nucleus [" << lookupNucleusName << "] and layer [" << layerNumber << "] " << std::endl;
//	globalObject->log(ss);

	// Get the nucleus
	long startNuclei = globalObject->componentBase[ComponentTypeNucleus];
	long endNuclei = globalObject->componentCounter[ComponentTypeNucleus];
//	for (globalObject->nucleusDB.begin(); globalObject->nucleusDB.more(); globalObject->nucleusDB.next())
	for(long nucIndex = startNuclei;nucIndex<endNuclei;nucIndex++)
	{
		Nucleus *nuc = globalObject->nucleusDB.getComponent(nucIndex);
		if(nuc->name == lookupNucleusName) 
		{
			long c = nuc->columns[0];
			Column *column = globalObject->columnDB.getComponent(c);
			if(layerType==LayerType::input)
				return getNeurons(lookupNucleusName,column->inputLayer - 1);
			else 
				return getNeurons(lookupNucleusName,column->outputLayer - 1);
		}
	}
	return getNeurons(lookupNucleusName,0); // default to input layer
}


unsigned char Server::getActivationStatus(long neuronId) 
{
	Neuron *neuron = globalObject->neuronDB.getComponent(neuronId);
	if(neuron->hasFired())  // Only include this neuron if it is currently firing
		return '\1';
	else
		return '\0';
}

void Server::setActivationBytes(unsigned char *bitstring, unsigned char *data, size_t length)
{
	for(size_t i=0;i<length;i++) 
	{
		if(bitstring[i]=='1')
			data[i] = '\1';
		else
			data[i] = '\0';
	}
}


// ============== Server.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <algorithm> 
#include <functional> 
#include <cctype>
#include <locale>
#include <string>
#include <vector>


#include <cpprest/http_client.h>
#include <cpprest/filestream.h>

class Server
{
public:

	Server(void);
	~Server(void);
	void start(void);
	void stop(void);
	int waitThread(void);
	int waitThreadWorker(void);
	std::string parseAndRespond(char *buffer,int length);
	std::string parseAndRespondJSON(char *buffer, int length);
	std::string parseAndRespondXML(char *buffer, int length);
	std::string parseAndRespondText(char *buffer, int length);
	void split(std::string workString,std::vector<long> &neuronList);
	unsigned char *parseSetActivationPattern(std::string workString,std::string *nucleus, int *columns, int *rows, std::vector<long> *neurons);
	static std::vector<long> getNeurons(std::string lookupNucleusName, LayerType layerType);
	static std::vector<long> getNeurons(std::string lookupNucleusName, int layerNumber);
	void setActivationBytes(unsigned char *bitstring, unsigned char *data, size_t length);
	unsigned char getActivationStatus(long neuronId);

	bool keepRunning;
	//
	// Utility methods

	// trim from start (in place)
	static inline void ltrim(std::string &s) {
		s.erase(s.begin(), std::find_if(s.begin(), s.end(), std::not_fn(static_cast<int(*)(int)>(std::isspace))));
//            std::not1(std::ptr_fun<int, int>(std::isspace))));
	}

	// trim from end (in place)
	static inline void rtrim(std::string &s) {
		s.erase(std::find_if(s.rbegin(), s.rend(), std::not_fn(static_cast<int(*)(int)>(std::isspace))).base(), s.end());
//            std::not1(std::ptr_fun<int, int>(std::isspace))).base(), s.end());
	}

	// trim from both ends (in place)
	static inline void trim(std::string &s) {
		ltrim(s);
		rtrim(s);
	}

	// trim from start (copying)
	static inline std::string ltrimmed(std::string s) {
		ltrim(s);
		return s;
	}

	// trim from end (copying)
	static inline std::string rtrimmed(std::string s) {
		rtrim(s);
		return s;
	}

	// trim from both ends (copying)
	static inline std::string trimmed(std::string s) {
		trim(s);
		return s;
	}
};


// ============== SimpleNN.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

// SimpleNN.cpp : Defines the entry point for the console application.
//

int mainx(int argc, char* argv[])
{
	(void)argc;
	(void)argv;
	return 0;
}



// ============== Size3D.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
class Size3D
{
public:
	Size3D(float h, float w, float d) { this->h = h; this->w = w; this->d = d; };

	Size3D(void) { this->h = 0; this->w = 0; this->d = 0; };

	void operator = (const Size3D& L) {
		h = L.h;
		w = L.w;
		d = L.d;
	}

	float h;
	float w;
	float d;
};



// ============== SpatialDetails.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "TR1Random.h"
#include "SpatialDetails.h"


void SpatialDetails::randomizeLocation() {
	// TODO:
	// using the area as the dimensions geneate a random location somewhere within those dimensions
	// convert the dimensions into integers required by the randomizer, by multiplying by 1000, giving us 1/1000 resolution
	location.x += ((float)(tr1random->generate(1, (int)abs(area.w))));
	location.y += ((float)(tr1random->generate(1, (int)abs(area.h))));
	location.z += ((float)(tr1random->generate(1, (int)abs(area.d))));

}

// ============== SpatialDetails.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include "Location3D.h"
#include "Size3D.h"

class SpatialDetails
{
public:
	//SpatialDetails(void) {} // default constructor
	SpatialDetails(const Location3D& location, const Size3D& area) {
		this->location = location;
		this->area = area;
	};

	SpatialDetails(float x, float y, float z, float h, float w, float d) {
		Location3D loc(x, y, z);
		Size3D sz(h, w, d);
		this->location = loc;
		this->area = sz;
	};

	void randomizeLocation(void);

	Location3D location;
	Size3D area;

};



// ============== Synapse.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

/* Synapse.cpp */

#include "Synapse.h"
#include "Global.h"         // TODO: Adjust to your environment
#include "TR1Random.h"
#include "Dendrite.h"
#include "Neuron.h"
#include "ActionPotential.h"
#include "Axon.h"
#include <sstream>
#include <cmath>
#include <limits>
#include <cstring>
#include <algorithm>

extern long FIRING_WINDOW;               // Example external
extern float WEIGHT_GRADATION;           // Example external
extern float RATE_GRADATION;             // Example external
//extern float RESTING_POTENTIAL;          // Example external

// Example clamp function for older C++ (if not using C++17)
template <typename T>
T clampValue(T v, T lo, T hi) {
    return std::max(lo, std::min(v, hi));
}

Synapse::Synapse(Dendrite *dendrite) : NNComponent(ComponentTypeSynapse)
{
    weight = 0.1f;
    polarity = EXCITATORY_SYNAPSE;  // default polarity
    weightUpdateCounter = 0;
    trace = 0.0f;
    traceDecay = 0.95f;
    traceIncrement = 0.05f;
    position = (float)tr1random->generate(1, 100);
    setOwningDendriteId(dendrite->id);
    dendrite->setDirty();
}

Synapse::Synapse() : NNComponent(ComponentTypeSynapse)
{
    weight = 0.1f;
    polarity = EXCITATORY_SYNAPSE;  // default polarity
    weightUpdateCounter = 0;
    trace = 0.0f;
    traceDecay = 0.95f;
    traceIncrement = 0.05f;
    position = (float)tr1random->generate(1, 100);
    setOwningDendriteId(0);
}

Synapse::~Synapse(void)
{
}

void Synapse::toJSON(std::ofstream &outstream)
{
    outstream << " { \"_type\": \"Synapse\", "
              << "\"id\": " << id
              << ", \"owningDendriteId\": " << owningDendriteId
              << ", \"weight\": " << weight
              << ", \"position\": " << position
              << ", \"polarity\": " << polarity
              << " } " << std::endl;
}

void Synapse::save(void)
{
    globalObject->synapseDB.save(this);
}

void Synapse::commit(void)
{
    globalObject->synapseDB.addToCache(this);
}

Synapse *Synapse::create(Dendrite *dendrite, float polar)
{
    Synapse *s = new Synapse(dendrite);
    s->id = globalObject->nextComponent(ComponentTypeSynapse);
    s->position = dendrite->getDistance();
    s->postSynapticNeuronId = dendrite->getPreSynapticNeuronId();
    s->polarity = polar;
    globalObject->insert(s);
    return s;
}

float Synapse::mapRange(float value, float inputMin, float inputMax, float outputMin, float outputMax)
{
    return outputMin + ((value - inputMin) / (inputMax - inputMin)) * (outputMax - outputMin);
}

// -------------------------------------------------------------
// Trace-based STDP methods
// -------------------------------------------------------------
void Synapse::incrementTrace() {
    this->trace += this->traceIncrement;
    if (this->trace > 1.0f) {
        this->trace = 1.0f;
    }
}

void Synapse::decayTrace() {
    this->trace *= this->traceDecay;
}

// -------------------------------------------------------------
// Compute the effective weighted input from presynaptic spikes
// -------------------------------------------------------------
float Synapse::computeWeightedSpike(Neuron *postNeuron)
{
    // Summation logic similar to the original sumweightsWithSpikePropagation.
    // For demonstration, we replicate the approach of scanning *all* dendrites
    // of the postNeuron. Adjust as needed.

    float totalWeight = 0.0f;
    float selectedCount = 0.0f;

    // Potentially track min/max for advanced mapping, if you still want that
    float minWeight = std::numeric_limits<float>::max();
    float maxWeight = std::numeric_limits<float>::lowest();

    std::vector<long> *dendrites = postNeuron->getDendrites();
    for (auto &dId : *dendrites)
    {
        Dendrite *d = globalObject->dendriteDB.getComponent(dId);
        if (!d) continue;

        long preSynId = d->getPreSynapticNeuronId();
        Neuron *preNeuron = globalObject->neuronDB.getComponent(preSynId);
        if (!preNeuron) continue;

        unsigned long lastFired = preNeuron->lastfired;
        if (lastFired == 0) continue;

        float timeDiff = (float)(globalObject->getCurrentTimestamp() - lastFired);
        if (timeDiff < FIRING_WINDOW)
        {
            // get the synapse from the dendrite
            Synapse *syn = globalObject->synapseDB.getComponent(d->getSynapseId());
            if (!syn) continue;

            float attenuation = std::exp(-timeDiff / FIRING_WINDOW);
            float weightedSpike = syn->getWeight() * attenuation;

            minWeight = std::min(minWeight, weightedSpike);
            maxWeight = std::max(maxWeight, weightedSpike);

            totalWeight += weightedSpike;
            selectedCount += 1.0f;
        }
    }

    if (selectedCount > 0.0f)
    {
        float normalizedWeight = totalWeight / selectedCount;

        // Optional further mapping or scaling:
        float scaledInput = normalizedWeight; 
        // e.g. scale to a range, etc.
        // scaledInput = mapRange(normalizedWeight, minWeight, maxWeight, 0.0f, RESTING_POTENTIAL);

        return scaledInput;
    }
    else
    {
        return 0.0f;
    }
}

// -------------------------------------------------------------
// Main entry point for an incoming spike
// -------------------------------------------------------------
void Synapse::receiveAP(ActionPotential *ap)
{
    // 1) Increment local STDP trace (presynaptic event).
    incrementTrace();

    // 2) Compute the weighted input from presynaptic activity
    Dendrite *dendrite = getOwningDendrite();
    if(!dendrite) return;

    long postNeuronId = dendrite->getPostSynapticNeuronId();
    Neuron *postNeuron = globalObject->neuronDB.getComponent(postNeuronId);
    if(!postNeuron) return;

    float weightedInput = computeWeightedSpike(postNeuron);

    // 3) Pass this input to the post-synaptic neuron
    postNeuron->integrateSynapticInput(weightedInput, this->id);

    // We DO NOT trigger the neuron's fire() here.
    // The neuron decides on its own when to fire.
}

// -------------------------------------------------------------
// Serialization / Deserialization
// -------------------------------------------------------------
Tuple* Synapse::getImage(void)
{
    size_t size = sizeof(owningDendriteId) +
                  sizeof(postSynapticNeuronId) +
                  sizeof(weight) +
                  sizeof(polarity) +
                  sizeof(weightUpdateCounter) +
                  sizeof(position);

    char *image = globalObject->allocClearedMemory(size);
    char *ptr = (char *)image;

    memcpy(ptr, &owningDendriteId, sizeof(owningDendriteId));
    ptr += sizeof(owningDendriteId);

    memcpy(ptr, &postSynapticNeuronId, sizeof(postSynapticNeuronId));
    ptr += sizeof(postSynapticNeuronId);

    memcpy(ptr, &weight, sizeof(weight));
    ptr += sizeof(weight);

    memcpy(ptr, &polarity, sizeof(polarity));
    ptr += sizeof(polarity);

    memcpy(ptr, &weightUpdateCounter, sizeof(weightUpdateCounter));
    ptr += sizeof(weightUpdateCounter);

    memcpy(ptr, &position, sizeof(position));
    ptr += sizeof(position);

    Tuple *tuple = new Tuple();
    tuple->objectPtr = image;
    tuple->value = size;

    return tuple;
}

Synapse* Synapse::instantiate(long key, size_t len, void *data)
{
    (void)len;
    Synapse *synapse = new Synapse();
    synapse->id = key;
    char *ptr = (char *)data;

    memcpy(&synapse->owningDendriteId, ptr, sizeof(synapse->owningDendriteId));
    ptr += sizeof(synapse->owningDendriteId);

    memcpy(&synapse->postSynapticNeuronId, ptr, sizeof(synapse->postSynapticNeuronId));
    ptr += sizeof(synapse->postSynapticNeuronId);

    memcpy(&synapse->weight, ptr, sizeof(synapse->weight));
    ptr += sizeof(synapse->weight);

    memcpy(&synapse->polarity, ptr, sizeof(synapse->polarity));
    ptr += sizeof(synapse->polarity);

    memcpy(&synapse->weightUpdateCounter, ptr, sizeof(synapse->weightUpdateCounter));
    ptr += sizeof(synapse->weightUpdateCounter);

    memcpy(&synapse->position, ptr, sizeof(synapse->position));
    ptr += sizeof(synapse->position);

    return synapse;
}

Dendrite* Synapse::getOwningDendrite(void)
{
    return globalObject->dendriteDB.getComponent(owningDendriteId);
}

// -------------------------------------------------------------
// Set weight with clamping and optional logging
// -------------------------------------------------------------
void Synapse::setWeight(float inValue)
{
    std::lock_guard<std::mutex> lock(synapse_mutex);
    float newWeight = clampValue(inValue, MINIMUM_SYNAPSE_WEIGHT, MAXIMUM_SYNAPSE_WEIGHT);

    if (std::fabs(newWeight - weight) > 1e-9)
    {
        float oldWeight = weight;
        weight = newWeight;
        weightUpdateCounter++;
        setDirty(true);

        // Optional logging:
        if(globalObject->logEvents)
        {
            std::stringstream ss;
            Dendrite *d = getOwningDendrite();
            if(d)
            {
                ss << "synapse_weight_change: synapse=" << this->id
                   << ", dendrite=" << this->owningDendriteId
                   << ", old=" << oldWeight
                   << ", new=" << weight
                   << ", presynapticNeuron=" << d->getPreSynapticNeuronId()
                   << ", postsynapticNeuron=" << d->getPostSynapticNeuronId();
            }
            else
            {
                ss << "synapse_weight_change: synapse=" << this->id
                   << ", old=" << oldWeight << ", new=" << weight;
            }
            globalObject->writeEventLog(ss.str().c_str());
        }
    }
}


// ============== Synapse.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <boost/thread.hpp>
#include <boost/asio.hpp>
#include <boost/asio/post.hpp>
#include <boost/asio/thread_pool.hpp>

#include "NNComponent.h"
#include "ActionPotential.h"
#include "Dendrite.h"
#include "FloatTuple.h"

class Synapse: public NNComponent
{
    friend class boost::serialization::access;
    template<class Archive>
    void serialize(Archive & ar, const size_t version)
    {
        ar & boost::serialization::base_object<NNComponent>(*this);
        ar & owningDendriteId;
        ar & weight;
        ar & position;
    }

public:
    virtual ~Synapse(void);
    static Synapse *create(Dendrite *dendrite, float polar);
    void receiveAP(ActionPotential *ap);
    Tuple *getImage(void);
    static Synapse *instantiate(long key, size_t len, void *data);

    Dendrite *getOwningDendrite(void);
    inline long getOwningDendriteId(void) { return owningDendriteId; };
    inline void setOwningDendriteId(long newId) { 
        owningDendriteId = newId; 
        setDirty(true); 
    };

    inline float getWeight(void) { return weight; };
    void setWeight(float value);
    inline float getPosition(void) { return position; };
    inline void setPosition(float value) { position=value; setDirty(true); };

    float getPolarity() const { return polarity; }

    void toJSON(std::ofstream& outstream);
    //FloatTuple sumweightsWithSpikePropagation(Neuron *neuron);

        // Renamed from sumweightsWithSpikePropagation to computeWeightedSpike
    // Returns the effective weighted input from all presynaptic activity
    float computeWeightedSpike(Neuron *postNeuron);

    float mapRange(float value, float inputMin = 0, float inputMax = 100000, float outputMin = -65.0, float outputMax = 65.0);

    void incrementTrace();
    void decayTrace();

    unsigned long postSynapticNeuronId;
    float polarity;

    float trace;  
    float traceDecay; 
    float traceIncrement; 

private:
    Synapse(Dendrite* dendrite);
    Synapse(void);

    void save(void);
    void commit(void);

    unsigned long owningDendriteId;
    float weight;
    float position;

    float weightUpdateCounter;

//    boost::mutex synapse_mutex; 
        // Thread safety
    std::mutex synapse_mutex;

};


// ============== TR1Random.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "TR1Random.h"
#include "time.h"

#include <boost/random/uniform_int_distribution.hpp>

TR1Random::TR1Random(void)
{
	gen.seed((boost::uint32_t)time(NULL));
}

TR1Random::~TR1Random(void)
{
}

int TR1Random::generate(int rangeMin,int rangeMax)
{
	boost::random::uniform_int_distribution<> dist(rangeMin, rangeMax);
    return dist(gen);
}

// ============== TR1Random.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include <boost/random/mersenne_twister.hpp>

class TR1Random
{
public:
	TR1Random(void);
	~TR1Random(void);
	boost::random::mt19937 gen;
	int generate(int rangeMin,int rangeMax);
};

#ifndef noexterntr1random
#define noexterntr1random 1
extern TR1Random *tr1random;
#endif

// ============== TimedEvent.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include "TimedEvent.h"
#include "Global.h"

TimedEvent::TimedEvent(long timeSlice):
	NNComponent(ComponentTypeTimedEvent)
{
	slice = timeSlice;
	ap = NULL;
	id = globalObject->nextComponent(ComponentTypeTimedEvent);
	globalObject->incrementTimedEventsCounter();
}

TimedEvent::~TimedEvent(void)
{
	if(ap!=NULL)
		delete ap;
	//std::cout << "destructing timed event " << id << std::endl;
	globalObject->decrementTimedEventsCounter();
}

TimedEvent *TimedEvent::create(long timeSlice, Process *p, long synapseId)
{

	TimedEvent *te = new TimedEvent(timeSlice);
	te->ap = ActionPotential::create(p);
	te->synapseId = synapseId;
	globalObject->insert(te,timeSlice);
	return te;
}


// ============== TimedEvent.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
#include "NNComponent.h"
#include "ActionPotential.h"
#include "Synapse.h"

class TimedEvent: public NNComponent
{
private:
	TimedEvent(long timeSlice);

public:
	virtual ~TimedEvent(void);
	static TimedEvent* create(long timeSlice, Process *p, long synapseId);
	ActionPotential *ap;
	long synapseId;
	long slice;
};


// ============== TimerProcessor.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#include <boost/thread.hpp>
#include <iostream>
#include <string>
#include <cstring> // For strerror() and related functions
#include <sys/socket.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <errno.h>
#include "Global.h"

#include "NeuronProcessor.h"

extern boost::mutex timestep_mutex;


// Settable externs
extern long FIRING_WINDOW;
extern long PROPAGATION_DELAY_MICROSECONDS;
extern double DECAY_FACTOR;
extern long REFACTORY_PERIOD;
extern float WEIGHT_GRADATION;
extern float RATE_GRADATION;

TimerProcessor::TimerProcessor(void)
{
    keepRunning = true;
}

TimerProcessor::~TimerProcessor(void)
{
}

void TimerProcessor::doWork(void)
{

//	globalObject->increment();
	globalObject->step();


//	startRealTime = boost::posix_time::microsec_clock::local_time();
    boost::posix_time::ptime thisTime = boost::posix_time::microsec_clock::local_time();
    boost::posix_time::time_duration duration = thisTime - globalObject->startRealTime;

	long milliseconds = duration.total_milliseconds(); // + timeAdjust;
	long waittime = (globalObject->getCurrentTimestamp()  - milliseconds);  

	if(globalObject->getCurrentTimestamp() > milliseconds) 
	{
		//printf("wait %ld\n", waittime);
		if (waittime > STALL_OVERHEAD) {
/*
			if(globalObject->logEvents) 
			{	
				std::stringstream ss;
				ss << "Brain_step: waittime=" << waittime;
				globalObject->writeEventLog(ss.str().c_str());
			}
*/
			boost::this_thread::sleep(boost::posix_time::milliseconds(waittime));
/*
			if(globalObject->logEvents) 
			{	
				std::stringstream ss;
				ss << "Brain_step: waiting complete";
				globalObject->writeEventLog(ss.str().c_str());
			}
*/
		}
	}


}

int TimerProcessor::waitThread(void)
{
    int ret = waitThreadWorker();
    return ret;
}

int TimerProcessor::waitThreadWorker(void)
{

    pid_t tid = syscall(SYS_gettid);
    std::cout << "TimerProcessor thread is " << tid << std::endl;

    while (keepRunning)
    {
        doWork();
    }
    return 0;
}
void TimerProcessor::start(void)
{
    boost::thread t(&TimerProcessor::waitThread, this);
    t.detach(); // Don't Wait for the new thread to finish execution
}

void TimerProcessor::stop(void)
{
    keepRunning = false;
}


// ============== TimerProcessor.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

#include <algorithm> 
#include <functional> 
#include <cctype>
#include <locale>
#include <string>
#include <vector>


class TimerProcessor
{
public:
	TimerProcessor(void);
	~TimerProcessor(void);
	int waitThread(void);
	int waitThreadWorker(void);
	void doWork(void);
	void start(void);
	void stop(void);

   	bool keepRunning;

};


// ============== Tuple.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once
class Tuple
{
public:
	char * objectPtr;
	size_t value;
};



// ============== stdafx.cpp ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

// stdafx.cpp : source file that includes just the standard includes
// SimpleNN.pch will be the pre-compiled header
// stdafx.obj will contain the pre-compiled type information

#include "stdafx.h"

// TODO: reference any additional headers you need in STDAFX.H
// and not in this file


// ============== stdafx.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

// stdafx.h : include file for standard system include files,
// or project specific include files that are used frequently, but
// are changed infrequently
//

#pragma once

//#include "targetver.h"

#include <stdio.h>
//#include <tchar.h>



// TODO: reference additional headers your program requires here


// ============== targetver.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

#pragma once

// The following macros define the minimum required platform.  The minimum required platform
// is the earliest version of Windows, Internet Explorer etc. that has the necessary features to run 
// your application.  The macros work by enabling all features available on platform versions up to and 
// including the version specified.

// Modify the following defines if you have to target a platform prior to the ones specified below.
// Refer to MSDN for the latest info on corresponding values for different platforms.
#ifndef _WIN32_WINNT            // Specifies that the minimum required platform is Windows Vista.
#define _WIN32_WINNT 0x0600     // Change this to the appropriate value to target other versions of Windows.
#endif



// ============== uri.h ==============
/*
 * Proprietary License
 * 
 * Copyright (c) 2024-2025 Dean S Horak
 * All rights reserved.
 * 
 * This software is the confidential and proprietary information of Dean S Horak ("Proprietary Information").
 * You shall not disclose such Proprietary Information and shall use it only in accordance with the terms
 * of the license agreement you entered into with Dean S Horak.
 * 
 * Redistribution and use in source and binary forms, with or without modification, are not permitted
 * without express written permission from Dean S Horak.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 * THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * If you have any questions about this license, please contact Your Name at dean.horak@gmail.com.
 */

// Define object that can be used to represent a Unique Resource Identifier
// which is useful for parsing and request handling

#ifndef URI_H_
#define URI_H_

#include <algorithm>
#include <cctype>
#include <string>
#include <utility>
#include <cstdint>

namespace simple_http_server {

// A Uri object will contain a valid scheme (for example: HTTP), host,
// port, and the actual URI path
class Uri {
 public:
  Uri() = default;
  explicit Uri(const std::string& path) : path_(path) { SetPathToLowercase(); }
  ~Uri() = default;

  inline bool operator<(const Uri& other) const { return path_ < other.path_; }
  inline bool operator==(const Uri& other) const {
    return path_ == other.path_;
  }

  void SetPath(const std::string& path) {
    path_ = std::move(path);
    SetPathToLowercase();
  }

  std::string scheme() const { return scheme_; }
  std::string host() const { return host_; }
  std::uint16_t port() const { return port_; }
  std::string path() const { return path_; }

 private:
  // Only the path is supported for now
  std::string path_;
  std::string scheme_;
  std::string host_;
  std::uint16_t port_;

  void SetPathToLowercase() {
    std::transform(path_.begin(), path_.end(), path_.begin(),
                   [](char c) { return tolower(c); });
  }
};

}  // namespace simple_http_server

#endif  // URI_H_


